{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b85fb45",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f1e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date/time handling\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310a5de",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Using exact model dictionary from step2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d891842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 8 models\n"
     ]
    }
   ],
   "source": [
    "# Model dictionary with exact hyperparameters from step2.ipynb\n",
    "model_dict = {\n",
    "    \"Linear Classifier (Logistic Regression)\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", class_weight='balanced', probability=True),\n",
    "    \"RBF SVM\": SVC(kernel='rbf', class_weight='balanced', probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(model_dict)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6369d1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90ec95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28849 rows\n",
      "Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'hostname', 'date', 'ping_jitter', 'ping_latency', 'ping_low', 'ping_high', 'day', 'predictions', 'basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_data = pd.read_csv(\"clean_labeled.csv\")\n",
    "print(f\"Loaded {len(clean_data)} rows\")\n",
    "print(f\"Columns: {list(clean_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f84895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hosts with basic_ema_anomaly: 38\n",
      "Hosts with dspot_anomaly: 24\n",
      "Hosts with tuned_dspot_anomaly: 32\n",
      "Total hosts with ANY anomaly: 38\n",
      "\n",
      "Filtered to 28394 rows from 38 hosts\n"
     ]
    }
   ],
   "source": [
    "# Filter to hosts that have at least one anomaly in ANY detection method\n",
    "hosts_with_basic_anomaly = clean_data[clean_data['basic_ema_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_dspot_anomaly = clean_data[clean_data['dspot_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_tuned_dspot_anomaly = clean_data[clean_data['tuned_dspot_anomaly'] == True]['hostname'].unique()\n",
    "\n",
    "# Union of all hosts with anomalies\n",
    "hosts_with_any_anomaly = set(hosts_with_basic_anomaly) | set(hosts_with_dspot_anomaly) | set(hosts_with_tuned_dspot_anomaly)\n",
    "\n",
    "print(f\"Hosts with basic_ema_anomaly: {len(hosts_with_basic_anomaly)}\")\n",
    "print(f\"Hosts with dspot_anomaly: {len(hosts_with_dspot_anomaly)}\")\n",
    "print(f\"Hosts with tuned_dspot_anomaly: {len(hosts_with_tuned_dspot_anomaly)}\")\n",
    "print(f\"Total hosts with ANY anomaly: {len(hosts_with_any_anomaly)}\")\n",
    "\n",
    "# Filter dataframe to only these hosts\n",
    "df = clean_data[clean_data['hostname'].isin(hosts_with_any_anomaly)].copy()\n",
    "print(f\"\\nFiltered to {len(df)} rows from {len(hosts_with_any_anomaly)} hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e26cd1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a8f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 16068 rows\n",
      "Test set: 12326 rows\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Split into train and test\n",
    "start_a = pd.Timestamp(\"2025-04-16\")\n",
    "end_a   = pd.Timestamp(\"2025-06-20\")\n",
    "\n",
    "start_b = pd.Timestamp(\"2025-07-01\")\n",
    "end_b   = pd.Timestamp(\"2025-08-01\")\n",
    "\n",
    "mask_a = (df[\"date\"] >= start_a) & (df[\"date\"] <= end_a)\n",
    "mask_b = (df[\"date\"] >= start_b) & (df[\"date\"] <= end_b)\n",
    "\n",
    "train = df[mask_a].copy()\n",
    "test = df[mask_b].copy()\n",
    "\n",
    "print(f\"Train set: {len(train)} rows\")\n",
    "print(f\"Test set: {len(test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d429b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Functions\n",
    "\n",
    "Modified to accept a `label_col` parameter to specify which anomaly column to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e34dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_lookback_features(lookback_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create lookback features for a window of data.\n",
    "    \n",
    "    Args:\n",
    "        lookback_df: DataFrame with historical data\n",
    "        label_col: Column name to use as labels (e.g., 'basic_ema_anomaly', 'dspot_anomaly')\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    lookback_df = lookback_df.reset_index(drop=True)\n",
    "\n",
    "    has_anomalies = lookback_df[label_col].any()\n",
    "    has_normal = (~lookback_df[label_col]).any()\n",
    "    \n",
    "    lookback_features = {\n",
    "        'anomaly_count': lookback_df[label_col].sum(),\n",
    "        'anomaly_rate': lookback_df[label_col].mean(),\n",
    "        'recent_anomaly_count': lookback_df[label_col].tail(3).sum(),\n",
    "        'datapoints_since_anomaly': ((len(lookback_df) - 1 - lookback_df[lookback_df[label_col] == True].index[-1]) if has_anomalies else -1),\n",
    "        'has_anomaly_history': float(has_anomalies),\n",
    "        'latency_during_anomalies': (lookback_df[lookback_df[label_col] == True][latency_to_use].mean() if has_anomalies else -1),\n",
    "        'latency_during_normal': (lookback_df[lookback_df[label_col] == False][latency_to_use].mean() if has_normal else -1),\n",
    "        'recent_latency_mean': lookback_df[latency_to_use].tail(3).mean(),\n",
    "        'baseline_latency_mean': lookback_df[latency_to_use].head(5).mean(),\n",
    "        'recent_vs_baseline': (lookback_df[latency_to_use].tail(3).mean() / lookback_df[latency_to_use].head(5).mean() if lookback_df[latency_to_use].head(5).mean() > 0 else 1.0),\n",
    "        'recent_latency_max': lookback_df[latency_to_use].tail(3).max(),\n",
    "        'latency_trend': (lookback_df[latency_to_use].iloc[-1] - lookback_df[latency_to_use].iloc[0]) / len(lookback_df),\n",
    "        'anomaly_clustering': lookback_df[label_col].rolling(3).sum().max() if len(lookback_df) >= 3 else 0,\n",
    "        'missing_points': lookback_df[latency_to_use].isna().sum(),\n",
    "        'completeness': 1 - lookback_df[latency_to_use].isna().mean()\n",
    "    }\n",
    "    return lookback_features\n",
    "\n",
    "\n",
    "def get_feature_df(og_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create a feature dataframe with lookback windows.\n",
    "    \n",
    "    Args:\n",
    "        og_df: Original dataframe sorted by date\n",
    "        label_col: Column name to use as labels\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    initial = create_lookback_features(og_df.iloc[0:10], label_col=label_col, latency_to_use=latency_to_use)\n",
    "    featured_df = pd.DataFrame(columns=list(initial.keys()) + ['label', 'date', 'hostname'])\n",
    "    TOL = pd.Timedelta(minutes=2)\n",
    "\n",
    "    for i, row in og_df.iloc[9:].iterrows():\n",
    "        end_time = og_df.loc[i, 'date']\n",
    "        start_time = end_time - pd.Timedelta(hours=30)\n",
    "        lookback_df = og_df[(og_df['date'] >= start_time + TOL) & (og_df['date'] < end_time - TOL)].copy()\n",
    "        if len(lookback_df) == 0:\n",
    "            continue\n",
    "        lookback_features = create_lookback_features(lookback_df, label_col=label_col, latency_to_use=latency_to_use)\n",
    "        label = og_df.loc[i, label_col]\n",
    "        hostname = og_df.loc[i, 'hostname']\n",
    "        row = {**lookback_features, 'label': label, 'date': end_time, 'hostname': hostname}\n",
    "        featured_df.loc[len(featured_df)] = row\n",
    "\n",
    "    return featured_df\n",
    "\n",
    "\n",
    "def transform_single_df_to_features(df, cur_hostname, label_col='predictions'):\n",
    "    \"\"\"\n",
    "    Transform a single device's data to features.\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataframe\n",
    "        cur_hostname: Hostname to filter by\n",
    "        label_col: Column name to use as labels\n",
    "    \"\"\"\n",
    "    host_isolated = df[df['hostname'] == cur_hostname]\n",
    "    host_isolated = host_isolated.sort_values(by='date', ascending=True)\n",
    "    return get_feature_df(host_isolated, label_col=label_col, latency_to_use='ping_latency')\n",
    "\n",
    "\n",
    "print(\"Feature engineering functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daceac9",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Functions\n",
    "\n",
    "Includes new threshold-based metrics:\n",
    "- **FPR at 90% Recall**: What false positive rate is needed to catch 90% of anomalies\n",
    "- **Recall at 10% FPR**: What percentage of anomalies are caught with 10% false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380eb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_threshold_metrics(y_test, y_proba):\n",
    "    \"\"\"\n",
    "    Calculate threshold-based metrics:\n",
    "    - FPR at 90% Recall: What FPR is needed to catch 90% of anomalies\n",
    "    - Recall at 10% FPR: What recall is achieved at 10% FPR\n",
    "    \n",
    "    Args:\n",
    "        y_test: True labels\n",
    "        y_proba: Predicted probabilities for positive class\n",
    "    \n",
    "    Returns:\n",
    "        fpr_at_90_recall: FPR when recall is 90%\n",
    "        recall_at_10_fpr: Recall when FPR is 10%\n",
    "    \"\"\"\n",
    "    # Sort by probability descending\n",
    "    sorted_indices = np.argsort(-y_proba)\n",
    "    y_test_sorted = y_test.iloc[sorted_indices].values if hasattr(y_test, 'iloc') else y_test[sorted_indices]\n",
    "    \n",
    "    total_positives = y_test_sorted.sum()\n",
    "    total_negatives = len(y_test_sorted) - total_positives\n",
    "    \n",
    "    # Edge case: no anomalies\n",
    "    if total_positives == 0:\n",
    "        return -1, -1\n",
    "    \n",
    "    # Calculate cumulative metrics\n",
    "    cumulative_tp = np.cumsum(y_test_sorted)\n",
    "    cumulative_fp = np.cumsum(1 - y_test_sorted)\n",
    "    \n",
    "    # Calculate recall and FPR at each threshold\n",
    "    recalls = cumulative_tp / total_positives\n",
    "    fprs = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)\n",
    "    \n",
    "    # FPR at 90% Recall\n",
    "    target_recall = 0.90\n",
    "    idx_90_recall = np.where(recalls >= target_recall)[0]\n",
    "    if len(idx_90_recall) > 0:\n",
    "        fpr_at_90_recall = fprs[idx_90_recall[0]]\n",
    "    else:\n",
    "        fpr_at_90_recall = 1.0  # Would need 100% FPR to reach 90% recall\n",
    "    \n",
    "    # Recall at 10% FPR\n",
    "    target_fpr = 0.10\n",
    "    idx_10_fpr = np.where(fprs <= target_fpr)[0]\n",
    "    if len(idx_10_fpr) > 0:\n",
    "        recall_at_10_fpr = recalls[idx_10_fpr[-1]]  # Last index where FPR <= 10%\n",
    "    else:\n",
    "        recall_at_10_fpr = 0.0  # Can't achieve any recall at 10% FPR\n",
    "    \n",
    "    return fpr_at_90_recall, recall_at_10_fpr\n",
    "\n",
    "\n",
    "def evaluate_model_per_device(X_train, y_train, X_test, y_test, hostname):\n",
    "    \"\"\"\n",
    "    Train all models and evaluate on test set for a single device.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training features and labels\n",
    "        X_test, y_test: Test features and labels\n",
    "        hostname: Device hostname\n",
    "    \n",
    "    Returns:\n",
    "        List of result dictionaries for each model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, clf in model_dict.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "            has_proba = True\n",
    "        except:\n",
    "            y_proba = None\n",
    "            has_proba = False\n",
    "        \n",
    "        # Standard metrics\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1_anomaly = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        roc_auc = -1\n",
    "        fpr_at_90_recall = -1\n",
    "        recall_at_10_fpr = -1\n",
    "        \n",
    "        if has_proba:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            fpr_at_90_recall, recall_at_10_fpr = calculate_threshold_metrics(y_test, y_proba)\n",
    "\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'hostname': hostname,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_anomaly,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr_at_90_recall': fpr_at_90_recall,\n",
    "            'recall_at_10_fpr': recall_at_10_fpr,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            'caught_anomalies': tp,\n",
    "            'missed_anomalies': fn,\n",
    "            'false_alarms': fp,\n",
    "            'total_test_samples': len(y_test),\n",
    "            'total_anomalies': y_test.sum()\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Model evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f7456",
   "metadata": {},
   "source": [
    "## 6. Main Evaluation Loop\n",
    "\n",
    "Iterate over all three anomaly detection methods and evaluate per-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d44c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 37\n",
      "Hosts with anomalies in test: 35\n",
      "Hosts with anomalies in BOTH train and test: 34\n",
      "\n",
      "\n",
      "[1/34] Host: 0f42441\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.838 | FPR@90%R: 0.980 | R@10%FPR: 0.273\n",
      "  Nearest Neighbors                             | Acc: 0.925 | FPR@90%R: 0.383 | R@10%FPR: 0.636\n",
      "  Linear SVM                                    | Acc: 0.838 | FPR@90%R: 0.980 | R@10%FPR: 0.273\n",
      "  RBF SVM                                       | Acc: 0.794 | FPR@90%R: 0.483 | R@10%FPR: 0.273\n",
      "  Decision Tree                                 | Acc: 0.844 | FPR@90%R: 0.973 | R@10%FPR: 0.091\n",
      "  Random Forest                                 | Acc: 0.900 | FPR@90%R: 0.940 | R@10%FPR: 0.273\n",
      "  AdaBoost                                      | Acc: 0.875 | FPR@90%R: 0.987 | R@10%FPR: 0.182\n",
      "  Naive Bayes                                   | Acc: 0.863 | FPR@90%R: 0.470 | R@10%FPR: 0.636\n",
      "\n",
      "[2/34] Host: 38b6bf0\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.304 | FPR@90%R: 0.887 | R@10%FPR: 0.026\n",
      "  Nearest Neighbors                             | Acc: 0.830 | FPR@90%R: 0.879 | R@10%FPR: 0.132\n",
      "  Linear SVM                                    | Acc: 0.299 | FPR@90%R: 0.879 | R@10%FPR: 0.026\n",
      "  RBF SVM                                       | Acc: 0.287 | FPR@90%R: 0.945 | R@10%FPR: 0.053\n",
      "  Decision Tree                                 | Acc: 0.411 | FPR@90%R: 0.904 | R@10%FPR: 0.132\n",
      "  Random Forest                                 | Acc: 0.890 | FPR@90%R: 0.978 | R@10%FPR: 0.105\n",
      "  AdaBoost                                      | Acc: 0.878 | FPR@90%R: 0.813 | R@10%FPR: 0.132\n",
      "  Naive Bayes                                   | Acc: 0.743 | FPR@90%R: 0.909 | R@10%FPR: 0.053\n",
      "\n",
      "[3/34] Host: b340432\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.412 | FPR@90%R: 0.922 | R@10%FPR: 0.052\n",
      "  Nearest Neighbors                             | Acc: 0.756 | FPR@90%R: 0.916 | R@10%FPR: 0.052\n",
      "  Linear SVM                                    | Acc: 0.244 | FPR@90%R: 0.948 | R@10%FPR: 0.083\n",
      "  RBF SVM                                       | Acc: 0.244 | FPR@90%R: 0.955 | R@10%FPR: 0.115\n",
      "  Decision Tree                                 | Acc: 0.415 | FPR@90%R: 0.909 | R@10%FPR: 0.135\n",
      "  Random Forest                                 | Acc: 0.763 | FPR@90%R: 0.955 | R@10%FPR: 0.062\n",
      "  AdaBoost                                      | Acc: 0.756 | FPR@90%R: 0.935 | R@10%FPR: 0.115\n",
      "  Naive Bayes                                   | Acc: 0.516 | FPR@90%R: 0.951 | R@10%FPR: 0.167\n",
      "\n",
      "[4/34] Host: c073f39\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.715 | FPR@90%R: 0.901 | R@10%FPR: 0.125\n",
      "  Nearest Neighbors                             | Acc: 0.861 | FPR@90%R: 0.856 | R@10%FPR: 0.125\n",
      "  Linear SVM                                    | Acc: 0.690 | FPR@90%R: 0.955 | R@10%FPR: 0.146\n",
      "  RBF SVM                                       | Acc: 0.675 | FPR@90%R: 0.772 | R@10%FPR: 0.167\n",
      "  Decision Tree                                 | Acc: 0.727 | FPR@90%R: 0.961 | R@10%FPR: 0.104\n",
      "  Random Forest                                 | Acc: 0.878 | FPR@90%R: 0.803 | R@10%FPR: 0.125\n",
      "  AdaBoost                                      | Acc: 0.861 | FPR@90%R: 0.820 | R@10%FPR: 0.208\n",
      "  Naive Bayes                                   | Acc: 0.801 | FPR@90%R: 0.856 | R@10%FPR: 0.250\n",
      "\n",
      "[5/34] Host: 592a43c\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.827 | FPR@90%R: 0.722 | R@10%FPR: 0.167\n",
      "  Nearest Neighbors                             | Acc: 0.952 | FPR@90%R: 0.795 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.789 | FPR@90%R: 0.767 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.776 | FPR@90%R: 0.986 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.929 | FPR@90%R: 0.903 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.980 | FPR@90%R: 0.767 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.966 | FPR@90%R: 0.837 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.823 | FPR@90%R: 0.667 | R@10%FPR: 0.000\n",
      "\n",
      "[6/34] Host: 43e847f\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.478 | FPR@90%R: 0.980 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.899 | FPR@90%R: 0.896 | R@10%FPR: 0.080\n",
      "  Linear SVM                                    | Acc: 0.504 | FPR@90%R: 0.980 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.380 | FPR@90%R: 0.805 | R@10%FPR: 0.120\n",
      "  Decision Tree                                 | Acc: 0.699 | FPR@90%R: 0.873 | R@10%FPR: 0.040\n",
      "  Random Forest                                 | Acc: 0.909 | FPR@90%R: 0.932 | R@10%FPR: 0.040\n",
      "  AdaBoost                                      | Acc: 0.848 | FPR@90%R: 0.940 | R@10%FPR: 0.040\n",
      "  Naive Bayes                                   | Acc: 0.768 | FPR@90%R: 0.841 | R@10%FPR: 0.080\n",
      "\n",
      "[7/34] Host: dede9dc\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.469 | FPR@90%R: 0.595 | R@10%FPR: 0.076\n",
      "  Nearest Neighbors                             | Acc: 0.784 | FPR@90%R: 0.742 | R@10%FPR: 0.030\n",
      "  Linear SVM                                    | Acc: 0.431 | FPR@90%R: 0.913 | R@10%FPR: 0.015\n",
      "  RBF SVM                                       | Acc: 0.426 | FPR@90%R: 0.664 | R@10%FPR: 0.030\n",
      "  Decision Tree                                 | Acc: 0.699 | FPR@90%R: 0.727 | R@10%FPR: 0.045\n",
      "  Random Forest                                 | Acc: 0.835 | FPR@90%R: 0.760 | R@10%FPR: 0.015\n",
      "  AdaBoost                                      | Acc: 0.832 | FPR@90%R: 0.964 | R@10%FPR: 0.136\n",
      "  Naive Bayes                                   | Acc: 0.170 | FPR@90%R: 0.583 | R@10%FPR: 0.258\n",
      "\n",
      "[8/34] Host: b407ebe\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.497 | FPR@90%R: 0.925 | R@10%FPR: 0.101\n",
      "  Nearest Neighbors                             | Acc: 0.778 | FPR@90%R: 0.868 | R@10%FPR: 0.145\n",
      "  Linear SVM                                    | Acc: 0.454 | FPR@90%R: 0.903 | R@10%FPR: 0.087\n",
      "  RBF SVM                                       | Acc: 0.216 | FPR@90%R: 0.928 | R@10%FPR: 0.145\n",
      "  Decision Tree                                 | Acc: 0.345 | FPR@90%R: 0.903 | R@10%FPR: 0.130\n",
      "  Random Forest                                 | Acc: 0.784 | FPR@90%R: 0.947 | R@10%FPR: 0.188\n",
      "  AdaBoost                                      | Acc: 0.760 | FPR@90%R: 0.887 | R@10%FPR: 0.145\n",
      "  Naive Bayes                                   | Acc: 0.575 | FPR@90%R: 0.909 | R@10%FPR: 0.188\n",
      "\n",
      "[9/34] Host: f8f4b44\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.400 | FPR@90%R: 0.938 | R@10%FPR: 0.147\n",
      "  Nearest Neighbors                             | Acc: 0.732 | FPR@90%R: 0.864 | R@10%FPR: 0.126\n",
      "  Linear SVM                                    | Acc: 0.246 | FPR@90%R: 0.903 | R@10%FPR: 0.168\n",
      "  RBF SVM                                       | Acc: 0.246 | FPR@90%R: 0.912 | R@10%FPR: 0.095\n",
      "  Decision Tree                                 | Acc: 0.367 | FPR@90%R: 0.906 | R@10%FPR: 0.211\n",
      "  Random Forest                                 | Acc: 0.759 | FPR@90%R: 0.899 | R@10%FPR: 0.095\n",
      "  AdaBoost                                      | Acc: 0.752 | FPR@90%R: 0.955 | R@10%FPR: 0.074\n",
      "  Naive Bayes                                   | Acc: 0.578 | FPR@90%R: 0.942 | R@10%FPR: 0.137\n",
      "\n",
      "[10/34] Host: b5c8445\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.852 | FPR@90%R: 0.139 | R@10%FPR: 0.400\n",
      "  Nearest Neighbors                             | Acc: 0.880 | FPR@90%R: 0.514 | R@10%FPR: 0.600\n",
      "  Linear SVM                                    | Acc: 0.874 | FPR@90%R: 0.954 | R@10%FPR: 0.200\n",
      "  RBF SVM                                       | Acc: 0.787 | FPR@90%R: 0.994 | R@10%FPR: 0.500\n",
      "  Decision Tree                                 | Acc: 0.945 | FPR@90%R: 0.850 | R@10%FPR: 0.300\n",
      "  Random Forest                                 | Acc: 0.891 | FPR@90%R: 0.191 | R@10%FPR: 0.400\n",
      "  AdaBoost                                      | Acc: 0.940 | FPR@90%R: 0.566 | R@10%FPR: 0.800\n",
      "  Naive Bayes                                   | Acc: 0.918 | FPR@90%R: 0.971 | R@10%FPR: 0.500\n",
      "\n",
      "[11/34] Host: 9840de6\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.726 | FPR@90%R: 0.752 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.940 | FPR@90%R: 0.959 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.626 | FPR@90%R: 0.850 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.626 | FPR@90%R: 0.835 | R@10%FPR: 0.091\n",
      "  Decision Tree                                 | Acc: 0.814 | FPR@90%R: 0.819 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.972 | FPR@90%R: 0.992 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.967 | FPR@90%R: 0.845 | R@10%FPR: 0.091\n",
      "  Naive Bayes                                   | Acc: 0.975 | FPR@90%R: 0.953 | R@10%FPR: 0.091\n",
      "\n",
      "[12/34] Host: d493afd\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.621 | FPR@90%R: 0.975 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.959 | FPR@90%R: 0.710 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.396 | FPR@90%R: 0.975 | R@10%FPR: 0.143\n",
      "  RBF SVM                                       | Acc: 0.775 | FPR@90%R: 1.000 | R@10%FPR: 0.143\n",
      "  Decision Tree                                 | Acc: 0.840 | FPR@90%R: 0.784 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.953 | FPR@90%R: 1.000 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.941 | FPR@90%R: 0.969 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.817 | FPR@90%R: 0.988 | R@10%FPR: 0.571\n",
      "\n",
      "[13/34] Host: 2620a05\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.440 | FPR@90%R: 0.664 | R@10%FPR: 0.121\n",
      "  Nearest Neighbors                             | Acc: 0.748 | FPR@90%R: 0.923 | R@10%FPR: 0.045\n",
      "  Linear SVM                                    | Acc: 0.454 | FPR@90%R: 0.714 | R@10%FPR: 0.091\n",
      "  RBF SVM                                       | Acc: 0.341 | FPR@90%R: 0.687 | R@10%FPR: 0.091\n",
      "  Decision Tree                                 | Acc: 0.452 | FPR@90%R: 0.900 | R@10%FPR: 0.045\n",
      "  Random Forest                                 | Acc: 0.835 | FPR@90%R: 0.755 | R@10%FPR: 0.152\n",
      "  AdaBoost                                      | Acc: 0.593 | FPR@90%R: 0.788 | R@10%FPR: 0.136\n",
      "  Naive Bayes                                   | Acc: 0.684 | FPR@90%R: 0.761 | R@10%FPR: 0.121\n",
      "\n",
      "[14/34] Host: a2e0486\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.402 | FPR@90%R: 0.836 | R@10%FPR: 0.078\n",
      "  Nearest Neighbors                             | Acc: 0.842 | FPR@90%R: 0.895 | R@10%FPR: 0.039\n",
      "  Linear SVM                                    | Acc: 0.432 | FPR@90%R: 0.873 | R@10%FPR: 0.098\n",
      "  RBF SVM                                       | Acc: 0.212 | FPR@90%R: 0.890 | R@10%FPR: 0.059\n",
      "  Decision Tree                                 | Acc: 0.516 | FPR@90%R: 0.893 | R@10%FPR: 0.078\n",
      "  Random Forest                                 | Acc: 0.874 | FPR@90%R: 0.969 | R@10%FPR: 0.098\n",
      "  AdaBoost                                      | Acc: 0.820 | FPR@90%R: 0.850 | R@10%FPR: 0.078\n",
      "  Naive Bayes                                   | Acc: 0.691 | FPR@90%R: 0.907 | R@10%FPR: 0.098\n",
      "\n",
      "[15/34] Host: b2c53ee\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.730 | FPR@90%R: 0.548 | R@10%FPR: 0.250\n",
      "  Nearest Neighbors                             | Acc: 0.882 | FPR@90%R: 0.891 | R@10%FPR: 0.125\n",
      "  Linear SVM                                    | Acc: 0.672 | FPR@90%R: 0.669 | R@10%FPR: 0.250\n",
      "  RBF SVM                                       | Acc: 0.554 | FPR@90%R: 0.519 | R@10%FPR: 0.200\n",
      "  Decision Tree                                 | Acc: 0.499 | FPR@90%R: 0.883 | R@10%FPR: 0.050\n",
      "  Random Forest                                 | Acc: 0.895 | FPR@90%R: 0.798 | R@10%FPR: 0.125\n",
      "  AdaBoost                                      | Acc: 0.866 | FPR@90%R: 0.727 | R@10%FPR: 0.100\n",
      "  Naive Bayes                                   | Acc: 0.790 | FPR@90%R: 0.545 | R@10%FPR: 0.375\n",
      "\n",
      "[16/34] Host: 33fe84e\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.643 | FPR@90%R: 0.973 | R@10%FPR: 0.067\n",
      "  Nearest Neighbors                             | Acc: 0.903 | FPR@90%R: 0.909 | R@10%FPR: 0.067\n",
      "  Linear SVM                                    | Acc: 0.727 | FPR@90%R: 0.834 | R@10%FPR: 0.200\n",
      "  RBF SVM                                       | Acc: 0.710 | FPR@90%R: 0.901 | R@10%FPR: 0.067\n",
      "  Decision Tree                                 | Acc: 0.705 | FPR@90%R: 0.882 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.923 | FPR@90%R: 0.810 | R@10%FPR: 0.100\n",
      "  AdaBoost                                      | Acc: 0.921 | FPR@90%R: 0.885 | R@10%FPR: 0.067\n",
      "  Naive Bayes                                   | Acc: 0.926 | FPR@90%R: 0.933 | R@10%FPR: 0.100\n",
      "\n",
      "[17/34] Host: 24a22bf\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.631 | FPR@90%R: 0.549 | R@10%FPR: 0.327\n",
      "  Nearest Neighbors                             | Acc: 0.817 | FPR@90%R: 0.628 | R@10%FPR: 0.245\n",
      "  Linear SVM                                    | Acc: 0.616 | FPR@90%R: 0.580 | R@10%FPR: 0.327\n",
      "  RBF SVM                                       | Acc: 0.619 | FPR@90%R: 0.628 | R@10%FPR: 0.265\n",
      "  Decision Tree                                 | Acc: 0.738 | FPR@90%R: 0.839 | R@10%FPR: 0.327\n",
      "  Random Forest                                 | Acc: 0.861 | FPR@90%R: 0.713 | R@10%FPR: 0.245\n",
      "  AdaBoost                                      | Acc: 0.767 | FPR@90%R: 0.811 | R@10%FPR: 0.204\n",
      "  Naive Bayes                                   | Acc: 0.651 | FPR@90%R: 0.606 | R@10%FPR: 0.306\n",
      "\n",
      "[18/34] Host: ed86ea2\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.843 | FPR@90%R: 0.951 | R@10%FPR: 0.409\n",
      "  Nearest Neighbors                             | Acc: 0.882 | FPR@90%R: 0.962 | R@10%FPR: 0.500\n",
      "  Linear SVM                                    | Acc: 0.838 | FPR@90%R: 0.923 | R@10%FPR: 0.318\n",
      "  RBF SVM                                       | Acc: 0.730 | FPR@90%R: 0.291 | R@10%FPR: 0.364\n",
      "  Decision Tree                                 | Acc: 0.882 | FPR@90%R: 0.929 | R@10%FPR: 0.045\n",
      "  Random Forest                                 | Acc: 0.892 | FPR@90%R: 0.846 | R@10%FPR: 0.500\n",
      "  AdaBoost                                      | Acc: 0.863 | FPR@90%R: 0.962 | R@10%FPR: 0.091\n",
      "  Naive Bayes                                   | Acc: 0.853 | FPR@90%R: 0.962 | R@10%FPR: 0.364\n",
      "\n",
      "[19/34] Host: 63598f8\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.531 | FPR@90%R: 0.764 | R@10%FPR: 0.180\n",
      "  Nearest Neighbors                             | Acc: 0.650 | FPR@90%R: 0.836 | R@10%FPR: 0.080\n",
      "  Linear SVM                                    | Acc: 0.481 | FPR@90%R: 0.764 | R@10%FPR: 0.200\n",
      "  RBF SVM                                       | Acc: 0.450 | FPR@90%R: 0.691 | R@10%FPR: 0.240\n",
      "  Decision Tree                                 | Acc: 0.637 | FPR@90%R: 0.800 | R@10%FPR: 0.040\n",
      "  Random Forest                                 | Acc: 0.688 | FPR@90%R: 0.636 | R@10%FPR: 0.020\n",
      "  AdaBoost                                      | Acc: 0.688 | FPR@90%R: 0.864 | R@10%FPR: 0.100\n",
      "  Naive Bayes                                   | Acc: 0.600 | FPR@90%R: 0.764 | R@10%FPR: 0.240\n",
      "\n",
      "[20/34] Host: 6ca8355\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.564 | FPR@90%R: 0.802 | R@10%FPR: 0.125\n",
      "  Nearest Neighbors                             | Acc: 0.874 | FPR@90%R: 0.952 | R@10%FPR: 0.083\n",
      "  Linear SVM                                    | Acc: 0.496 | FPR@90%R: 0.861 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.494 | FPR@90%R: 0.828 | R@10%FPR: 0.250\n",
      "  Decision Tree                                 | Acc: 0.738 | FPR@90%R: 0.855 | R@10%FPR: 0.042\n",
      "  Random Forest                                 | Acc: 0.940 | FPR@90%R: 0.777 | R@10%FPR: 0.042\n",
      "  AdaBoost                                      | Acc: 0.809 | FPR@90%R: 0.898 | R@10%FPR: 0.042\n",
      "  Naive Bayes                                   | Acc: 0.695 | FPR@90%R: 0.676 | R@10%FPR: 0.250\n",
      "\n",
      "[21/34] Host: 9ab8252\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.742 | FPR@90%R: 0.917 | R@10%FPR: 0.117\n",
      "  Nearest Neighbors                             | Acc: 0.809 | FPR@90%R: 0.942 | R@10%FPR: 0.039\n",
      "  Linear SVM                                    | Acc: 0.615 | FPR@90%R: 0.929 | R@10%FPR: 0.078\n",
      "  RBF SVM                                       | Acc: 0.809 | FPR@90%R: 0.942 | R@10%FPR: 0.078\n",
      "  Decision Tree                                 | Acc: 0.623 | FPR@90%R: 0.862 | R@10%FPR: 0.143\n",
      "  Random Forest                                 | Acc: 0.809 | FPR@90%R: 0.834 | R@10%FPR: 0.078\n",
      "  AdaBoost                                      | Acc: 0.799 | FPR@90%R: 0.804 | R@10%FPR: 0.130\n",
      "  Naive Bayes                                   | Acc: 0.697 | FPR@90%R: 0.828 | R@10%FPR: 0.078\n",
      "\n",
      "[22/34] Host: da6d469\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.953 | FPR@90%R: 0.905 | R@10%FPR: 0.167\n",
      "  Nearest Neighbors                             | Acc: 0.868 | FPR@90%R: 0.712 | R@10%FPR: 0.250\n",
      "  Linear SVM                                    | Acc: 0.691 | FPR@90%R: 0.856 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.696 | FPR@90%R: 0.910 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.773 | FPR@90%R: 0.674 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.970 | FPR@90%R: 0.907 | R@10%FPR: 0.167\n",
      "  AdaBoost                                      | Acc: 0.833 | FPR@90%R: 0.877 | R@10%FPR: 0.250\n",
      "  Naive Bayes                                   | Acc: 0.945 | FPR@90%R: 0.943 | R@10%FPR: 0.000\n",
      "\n",
      "[23/34] Host: 7f6d63d\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.370 | FPR@90%R: 0.840 | R@10%FPR: 0.156\n",
      "  Nearest Neighbors                             | Acc: 0.725 | FPR@90%R: 0.942 | R@10%FPR: 0.044\n",
      "  Linear SVM                                    | Acc: 0.340 | FPR@90%R: 0.869 | R@10%FPR: 0.189\n",
      "  RBF SVM                                       | Acc: 0.315 | FPR@90%R: 0.863 | R@10%FPR: 0.156\n",
      "  Decision Tree                                 | Acc: 0.484 | FPR@90%R: 0.939 | R@10%FPR: 0.111\n",
      "  Random Forest                                 | Acc: 0.777 | FPR@90%R: 0.840 | R@10%FPR: 0.067\n",
      "  AdaBoost                                      | Acc: 0.769 | FPR@90%R: 0.869 | R@10%FPR: 0.033\n",
      "  Naive Bayes                                   | Acc: 0.553 | FPR@90%R: 0.850 | R@10%FPR: 0.156\n",
      "\n",
      "[24/34] Host: 972f622\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.741 | FPR@90%R: 0.906 | R@10%FPR: 0.050\n",
      "  Nearest Neighbors                             | Acc: 0.946 | FPR@90%R: 0.868 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.704 | FPR@90%R: 0.925 | R@10%FPR: 0.150\n",
      "  RBF SVM                                       | Acc: 0.551 | FPR@90%R: 0.927 | R@10%FPR: 0.150\n",
      "  Decision Tree                                 | Acc: 0.716 | FPR@90%R: 0.927 | R@10%FPR: 0.300\n",
      "  Random Forest                                 | Acc: 0.948 | FPR@90%R: 0.951 | R@10%FPR: 0.100\n",
      "  AdaBoost                                      | Acc: 0.914 | FPR@90%R: 0.699 | R@10%FPR: 0.300\n",
      "  Naive Bayes                                   | Acc: 0.931 | FPR@90%R: 0.904 | R@10%FPR: 0.300\n",
      "\n",
      "[25/34] Host: 64b750b\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.894 | FPR@90%R: 0.889 | R@10%FPR: 0.235\n",
      "  Nearest Neighbors                             | Acc: 0.894 | FPR@90%R: 0.611 | R@10%FPR: 0.294\n",
      "  Linear SVM                                    | Acc: 0.894 | FPR@90%R: 0.875 | R@10%FPR: 0.059\n",
      "  RBF SVM                                       | Acc: 0.733 | FPR@90%R: 0.625 | R@10%FPR: 0.294\n",
      "  Decision Tree                                 | Acc: 0.894 | FPR@90%R: 0.931 | R@10%FPR: 0.118\n",
      "  Random Forest                                 | Acc: 0.894 | FPR@90%R: 0.653 | R@10%FPR: 0.235\n",
      "  AdaBoost                                      | Acc: 0.894 | FPR@90%R: 0.931 | R@10%FPR: 0.118\n",
      "  Naive Bayes                                   | Acc: 0.894 | FPR@90%R: 0.931 | R@10%FPR: 0.118\n",
      "\n",
      "[26/34] Host: 575f518\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.754 | FPR@90%R: 0.938 | R@10%FPR: 0.036\n",
      "  Nearest Neighbors                             | Acc: 0.865 | FPR@90%R: 0.919 | R@10%FPR: 0.143\n",
      "  Linear SVM                                    | Acc: 0.742 | FPR@90%R: 0.830 | R@10%FPR: 0.071\n",
      "  RBF SVM                                       | Acc: 0.687 | FPR@90%R: 0.933 | R@10%FPR: 0.107\n",
      "  Decision Tree                                 | Acc: 0.847 | FPR@90%R: 0.919 | R@10%FPR: 0.143\n",
      "  Random Forest                                 | Acc: 0.920 | FPR@90%R: 0.935 | R@10%FPR: 0.179\n",
      "  AdaBoost                                      | Acc: 0.905 | FPR@90%R: 0.887 | R@10%FPR: 0.107\n",
      "  Naive Bayes                                   | Acc: 0.910 | FPR@90%R: 0.906 | R@10%FPR: 0.071\n",
      "\n",
      "[27/34] Host: 8445893\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.931 | FPR@90%R: 0.872 | R@10%FPR: 0.091\n",
      "  Nearest Neighbors                             | Acc: 0.931 | FPR@90%R: 0.376 | R@10%FPR: 0.818\n",
      "  Linear SVM                                    | Acc: 0.844 | FPR@90%R: 0.987 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.794 | FPR@90%R: 0.624 | R@10%FPR: 0.636\n",
      "  Decision Tree                                 | Acc: 0.906 | FPR@90%R: 0.369 | R@10%FPR: 0.818\n",
      "  Random Forest                                 | Acc: 0.931 | FPR@90%R: 0.356 | R@10%FPR: 0.182\n",
      "  AdaBoost                                      | Acc: 0.931 | FPR@90%R: 0.872 | R@10%FPR: 0.091\n",
      "  Naive Bayes                                   | Acc: 0.938 | FPR@90%R: 0.671 | R@10%FPR: 0.545\n",
      "\n",
      "[28/34] Host: 5c5004f\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.837 | FPR@90%R: 0.993 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.753 | FPR@90%R: 0.906 | R@10%FPR: 0.259\n",
      "  Linear SVM                                    | Acc: 0.608 | FPR@90%R: 0.906 | R@10%FPR: 0.074\n",
      "  RBF SVM                                       | Acc: 0.608 | FPR@90%R: 0.763 | R@10%FPR: 0.074\n",
      "  Decision Tree                                 | Acc: 0.416 | FPR@90%R: 0.978 | R@10%FPR: 0.037\n",
      "  Random Forest                                 | Acc: 0.837 | FPR@90%R: 0.863 | R@10%FPR: 0.111\n",
      "  AdaBoost                                      | Acc: 0.729 | FPR@90%R: 0.885 | R@10%FPR: 0.074\n",
      "  Naive Bayes                                   | Acc: 0.831 | FPR@90%R: 0.978 | R@10%FPR: 0.037\n",
      "\n",
      "[29/34] Host: 953d46d\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.386 | FPR@90%R: 0.835 | R@10%FPR: 0.060\n",
      "  Nearest Neighbors                             | Acc: 0.864 | FPR@90%R: 0.783 | R@10%FPR: 0.060\n",
      "  Linear SVM                                    | Acc: 0.303 | FPR@90%R: 0.942 | R@10%FPR: 0.060\n",
      "  RBF SVM                                       | Acc: 0.260 | FPR@90%R: 0.887 | R@10%FPR: 0.020\n",
      "  Decision Tree                                 | Acc: 0.677 | FPR@90%R: 0.827 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.869 | FPR@90%R: 0.815 | R@10%FPR: 0.160\n",
      "  AdaBoost                                      | Acc: 0.823 | FPR@90%R: 0.812 | R@10%FPR: 0.040\n",
      "  Naive Bayes                                   | Acc: 0.598 | FPR@90%R: 0.934 | R@10%FPR: 0.100\n",
      "\n",
      "[30/34] Host: 25b3303\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.637 | FPR@90%R: 0.753 | R@10%FPR: 0.062\n",
      "  Nearest Neighbors                             | Acc: 0.677 | FPR@90%R: 0.932 | R@10%FPR: 0.062\n",
      "  Linear SVM                                    | Acc: 0.590 | FPR@90%R: 0.806 | R@10%FPR: 0.062\n",
      "  RBF SVM                                       | Acc: 0.691 | FPR@90%R: 0.778 | R@10%FPR: 0.123\n",
      "  Decision Tree                                 | Acc: 0.654 | FPR@90%R: 0.938 | R@10%FPR: 0.111\n",
      "  Random Forest                                 | Acc: 0.743 | FPR@90%R: 0.886 | R@10%FPR: 0.099\n",
      "  AdaBoost                                      | Acc: 0.756 | FPR@90%R: 0.917 | R@10%FPR: 0.049\n",
      "  Naive Bayes                                   | Acc: 0.756 | FPR@90%R: 0.858 | R@10%FPR: 0.185\n",
      "\n",
      "[31/34] Host: 5bf17fc\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.975 | FPR@90%R: 0.172 | R@10%FPR: 0.667\n",
      "  Nearest Neighbors                             | Acc: 0.975 | FPR@90%R: 0.981 | R@10%FPR: 0.333\n",
      "  Linear SVM                                    | Acc: 0.975 | FPR@90%R: 0.115 | R@10%FPR: 0.667\n",
      "  RBF SVM                                       | Acc: 0.969 | FPR@90%R: 0.847 | R@10%FPR: 0.667\n",
      "  Decision Tree                                 | Acc: 0.812 | FPR@90%R: 0.994 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.981 | FPR@90%R: 0.968 | R@10%FPR: 0.667\n",
      "  AdaBoost                                      | Acc: 0.975 | FPR@90%R: 0.611 | R@10%FPR: 0.333\n",
      "  Naive Bayes                                   | Acc: 0.981 | FPR@90%R: 0.911 | R@10%FPR: 0.667\n",
      "\n",
      "[32/34] Host: 1a21874\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.905 | FPR@90%R: 0.524 | R@10%FPR: 0.667\n",
      "  Nearest Neighbors                             | Acc: 0.970 | FPR@90%R: 0.789 | R@10%FPR: 0.667\n",
      "  Linear SVM                                    | Acc: 0.905 | FPR@90%R: 0.355 | R@10%FPR: 0.667\n",
      "  RBF SVM                                       | Acc: 0.905 | FPR@90%R: 0.458 | R@10%FPR: 0.667\n",
      "  Decision Tree                                 | Acc: 0.982 | FPR@90%R: 0.976 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.982 | FPR@90%R: 0.940 | R@10%FPR: 0.333\n",
      "  AdaBoost                                      | Acc: 0.976 | FPR@90%R: 0.946 | R@10%FPR: 0.333\n",
      "  Naive Bayes                                   | Acc: 0.982 | FPR@90%R: 0.886 | R@10%FPR: 0.000\n",
      "\n",
      "[33/34] Host: 29129b6\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.646 | FPR@90%R: 0.861 | R@10%FPR: 0.084\n",
      "  Nearest Neighbors                             | Acc: 0.708 | FPR@90%R: 0.861 | R@10%FPR: 0.159\n",
      "  Linear SVM                                    | Acc: 0.579 | FPR@90%R: 0.874 | R@10%FPR: 0.103\n",
      "  RBF SVM                                       | Acc: 0.494 | FPR@90%R: 0.884 | R@10%FPR: 0.103\n",
      "  Decision Tree                                 | Acc: 0.549 | FPR@90%R: 0.861 | R@10%FPR: 0.121\n",
      "  Random Forest                                 | Acc: 0.733 | FPR@90%R: 0.891 | R@10%FPR: 0.093\n",
      "  AdaBoost                                      | Acc: 0.701 | FPR@90%R: 0.908 | R@10%FPR: 0.075\n",
      "  Naive Bayes                                   | Acc: 0.621 | FPR@90%R: 0.895 | R@10%FPR: 0.131\n",
      "\n",
      "[34/34] Host: 9dc32f2\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.505 | FPR@90%R: 0.896 | R@10%FPR: 0.130\n",
      "  Nearest Neighbors                             | Acc: 0.683 | FPR@90%R: 0.900 | R@10%FPR: 0.148\n",
      "  Linear SVM                                    | Acc: 0.626 | FPR@90%R: 0.889 | R@10%FPR: 0.070\n",
      "  RBF SVM                                       | Acc: 0.295 | FPR@90%R: 0.851 | R@10%FPR: 0.096\n",
      "  Decision Tree                                 | Acc: 0.369 | FPR@90%R: 0.934 | R@10%FPR: 0.148\n",
      "  Random Forest                                 | Acc: 0.705 | FPR@90%R: 0.889 | R@10%FPR: 0.148\n",
      "  AdaBoost                                      | Acc: 0.666 | FPR@90%R: 0.900 | R@10%FPR: 0.087\n",
      "  Naive Bayes                                   | Acc: 0.572 | FPR@90%R: 0.924 | R@10%FPR: 0.209\n",
      "\n",
      "Completed basic_ema_anomaly\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 24\n",
      "Hosts with anomalies in test: 24\n",
      "Hosts with anomalies in BOTH train and test: 24\n",
      "\n",
      "\n",
      "[1/24] Host: c073f39\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.653 | FPR@90%R: 0.957 | R@10%FPR: 0.267\n",
      "  Nearest Neighbors                             | Acc: 0.926 | FPR@90%R: 0.796 | R@10%FPR: 0.133\n",
      "  Linear SVM                                    | Acc: 0.695 | FPR@90%R: 0.971 | R@10%FPR: 0.133\n",
      "  RBF SVM                                       | Acc: 0.648 | FPR@90%R: 0.853 | R@10%FPR: 0.267\n",
      "  Decision Tree                                 | Acc: 0.811 | FPR@90%R: 0.922 | R@10%FPR: 0.067\n",
      "  Random Forest                                 | Acc: 0.926 | FPR@90%R: 0.767 | R@10%FPR: 0.033\n",
      "  AdaBoost                                      | Acc: 0.926 | FPR@90%R: 0.887 | R@10%FPR: 0.067\n",
      "  Naive Bayes                                   | Acc: 0.762 | FPR@90%R: 0.949 | R@10%FPR: 0.267\n",
      "\n",
      "[2/24] Host: b340432\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.563 | FPR@90%R: 0.919 | R@10%FPR: 0.104\n",
      "  Nearest Neighbors                             | Acc: 0.659 | FPR@90%R: 0.852 | R@10%FPR: 0.194\n",
      "  Linear SVM                                    | Acc: 0.607 | FPR@90%R: 0.893 | R@10%FPR: 0.134\n",
      "  RBF SVM                                       | Acc: 0.486 | FPR@90%R: 0.882 | R@10%FPR: 0.157\n",
      "  Decision Tree                                 | Acc: 0.644 | FPR@90%R: 0.945 | R@10%FPR: 0.082\n",
      "  Random Forest                                 | Acc: 0.662 | FPR@90%R: 0.889 | R@10%FPR: 0.127\n",
      "  AdaBoost                                      | Acc: 0.664 | FPR@90%R: 0.886 | R@10%FPR: 0.157\n",
      "  Naive Bayes                                   | Acc: 0.528 | FPR@90%R: 0.897 | R@10%FPR: 0.149\n",
      "\n",
      "[3/24] Host: 38b6bf0\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.663 | FPR@90%R: 0.900 | R@10%FPR: 0.033\n",
      "  Nearest Neighbors                             | Acc: 0.915 | FPR@90%R: 0.836 | R@10%FPR: 0.067\n",
      "  Linear SVM                                    | Acc: 0.783 | FPR@90%R: 0.558 | R@10%FPR: 0.100\n",
      "  RBF SVM                                       | Acc: 0.708 | FPR@90%R: 0.946 | R@10%FPR: 0.033\n",
      "  Decision Tree                                 | Acc: 0.791 | FPR@90%R: 0.714 | R@10%FPR: 0.033\n",
      "  Random Forest                                 | Acc: 0.923 | FPR@90%R: 0.933 | R@10%FPR: 0.033\n",
      "  AdaBoost                                      | Acc: 0.905 | FPR@90%R: 0.895 | R@10%FPR: 0.100\n",
      "  Naive Bayes                                   | Acc: 0.748 | FPR@90%R: 0.911 | R@10%FPR: 0.167\n",
      "\n",
      "[4/24] Host: 592a43c\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.929 | FPR@90%R: 0.660 | R@10%FPR: 0.167\n",
      "  Nearest Neighbors                             | Acc: 0.980 | FPR@90%R: 0.799 | R@10%FPR: 0.167\n",
      "  Linear SVM                                    | Acc: 0.922 | FPR@90%R: 0.670 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.939 | FPR@90%R: 0.740 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.959 | FPR@90%R: 0.993 | R@10%FPR: 0.167\n",
      "  Random Forest                                 | Acc: 0.980 | FPR@90%R: 0.951 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.956 | FPR@90%R: 0.951 | R@10%FPR: 0.167\n",
      "  Naive Bayes                                   | Acc: 0.935 | FPR@90%R: 0.955 | R@10%FPR: 0.000\n",
      "\n",
      "[5/24] Host: 43e847f\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.355 | FPR@90%R: 0.973 | R@10%FPR: 0.048\n",
      "  Nearest Neighbors                             | Acc: 0.895 | FPR@90%R: 0.918 | R@10%FPR: 0.143\n",
      "  Linear SVM                                    | Acc: 0.438 | FPR@90%R: 0.886 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.438 | FPR@90%R: 0.941 | R@10%FPR: 0.048\n",
      "  Decision Tree                                 | Acc: 0.333 | FPR@90%R: 0.937 | R@10%FPR: 0.048\n",
      "  Random Forest                                 | Acc: 0.920 | FPR@90%R: 0.965 | R@10%FPR: 0.048\n",
      "  AdaBoost                                      | Acc: 0.917 | FPR@90%R: 0.792 | R@10%FPR: 0.048\n",
      "  Naive Bayes                                   | Acc: 0.442 | FPR@90%R: 0.859 | R@10%FPR: 0.143\n",
      "\n",
      "[6/24] Host: dede9dc\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.817 | FPR@90%R: 0.990 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.995 | FPR@90%R: 0.363 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.870 | FPR@90%R: 0.332 | R@10%FPR: 0.500\n",
      "  RBF SVM                                       | Acc: 0.972 | FPR@90%R: 0.927 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.779 | FPR@90%R: 0.448 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.995 | FPR@90%R: 0.494 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.980 | FPR@90%R: 0.882 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.103 | FPR@90%R: 0.985 | R@10%FPR: 0.000\n",
      "\n",
      "[7/24] Host: b407ebe\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.786 | FPR@90%R: 0.856 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.987 | FPR@90%R: 0.765 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.814 | FPR@90%R: 0.966 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.843 | FPR@90%R: 0.708 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.874 | FPR@90%R: 0.765 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.987 | FPR@90%R: 0.862 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.982 | FPR@90%R: 0.888 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.853 | FPR@90%R: 0.916 | R@10%FPR: 0.200\n",
      "\n",
      "[8/24] Host: f8f4b44\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.422 | FPR@90%R: 0.913 | R@10%FPR: 0.111\n",
      "  Nearest Neighbors                             | Acc: 0.866 | FPR@90%R: 0.902 | R@10%FPR: 0.111\n",
      "  Linear SVM                                    | Acc: 0.258 | FPR@90%R: 0.932 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.213 | FPR@90%R: 0.935 | R@10%FPR: 0.139\n",
      "  Decision Tree                                 | Acc: 0.635 | FPR@90%R: 0.902 | R@10%FPR: 0.083\n",
      "  Random Forest                                 | Acc: 0.911 | FPR@90%R: 0.891 | R@10%FPR: 0.111\n",
      "  AdaBoost                                      | Acc: 0.888 | FPR@90%R: 0.869 | R@10%FPR: 0.083\n",
      "  Naive Bayes                                   | Acc: 0.841 | FPR@90%R: 0.943 | R@10%FPR: 0.083\n",
      "\n",
      "[9/24] Host: 9840de6\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.575 | FPR@90%R: 0.746 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.997 | FPR@90%R: 0.804 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.497 | FPR@90%R: 0.758 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.819 | FPR@90%R: 0.214 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.940 | FPR@90%R: 0.945 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.997 | FPR@90%R: 0.292 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.997 | FPR@90%R: 0.783 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.068 | FPR@90%R: 0.854 | R@10%FPR: 0.000\n",
      "\n",
      "[10/24] Host: 2620a05\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.242 | FPR@90%R: 0.928 | R@10%FPR: 0.326\n",
      "  Nearest Neighbors                             | Acc: 0.874 | FPR@90%R: 0.880 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.301 | FPR@90%R: 0.961 | R@10%FPR: 0.239\n",
      "  RBF SVM                                       | Acc: 0.281 | FPR@90%R: 0.950 | R@10%FPR: 0.217\n",
      "  Decision Tree                                 | Acc: 0.415 | FPR@90%R: 0.852 | R@10%FPR: 0.130\n",
      "  Random Forest                                 | Acc: 0.886 | FPR@90%R: 0.883 | R@10%FPR: 0.109\n",
      "  AdaBoost                                      | Acc: 0.840 | FPR@90%R: 0.769 | R@10%FPR: 0.174\n",
      "  Naive Bayes                                   | Acc: 0.862 | FPR@90%R: 0.955 | R@10%FPR: 0.152\n",
      "\n",
      "[11/24] Host: a2e0486\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.765 | FPR@90%R: 0.900 | R@10%FPR: 0.208\n",
      "  Nearest Neighbors                             | Acc: 0.941 | FPR@90%R: 0.801 | R@10%FPR: 0.042\n",
      "  Linear SVM                                    | Acc: 0.795 | FPR@90%R: 0.945 | R@10%FPR: 0.083\n",
      "  RBF SVM                                       | Acc: 0.511 | FPR@90%R: 0.955 | R@10%FPR: 0.083\n",
      "  Decision Tree                                 | Acc: 0.884 | FPR@90%R: 0.806 | R@10%FPR: 0.042\n",
      "  Random Forest                                 | Acc: 0.941 | FPR@90%R: 0.871 | R@10%FPR: 0.208\n",
      "  AdaBoost                                      | Acc: 0.941 | FPR@90%R: 0.869 | R@10%FPR: 0.083\n",
      "  Naive Bayes                                   | Acc: 0.435 | FPR@90%R: 0.882 | R@10%FPR: 0.125\n",
      "\n",
      "[12/24] Host: b2c53ee\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.651 | FPR@90%R: 0.950 | R@10%FPR: 0.049\n",
      "  Nearest Neighbors                             | Acc: 0.732 | FPR@90%R: 0.823 | R@10%FPR: 0.049\n",
      "  Linear SVM                                    | Acc: 0.761 | FPR@90%R: 0.923 | R@10%FPR: 0.085\n",
      "  RBF SVM                                       | Acc: 0.717 | FPR@90%R: 0.946 | R@10%FPR: 0.232\n",
      "  Decision Tree                                 | Acc: 0.714 | FPR@90%R: 0.923 | R@10%FPR: 0.098\n",
      "  Random Forest                                 | Acc: 0.777 | FPR@90%R: 0.930 | R@10%FPR: 0.171\n",
      "  AdaBoost                                      | Acc: 0.722 | FPR@90%R: 0.873 | R@10%FPR: 0.110\n",
      "  Naive Bayes                                   | Acc: 0.711 | FPR@90%R: 0.900 | R@10%FPR: 0.207\n",
      "\n",
      "[13/24] Host: 33fe84e\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.588 | FPR@90%R: 0.952 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.975 | FPR@90%R: 0.804 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.514 | FPR@90%R: 0.840 | R@10%FPR: 0.200\n",
      "  RBF SVM                                       | Acc: 0.881 | FPR@90%R: 0.893 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.878 | FPR@90%R: 0.949 | R@10%FPR: 0.100\n",
      "  Random Forest                                 | Acc: 0.975 | FPR@90%R: 0.850 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.975 | FPR@90%R: 0.893 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.241 | FPR@90%R: 0.947 | R@10%FPR: 0.000\n",
      "\n",
      "[14/24] Host: 24a22bf\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.809 | FPR@90%R: 0.989 | R@10%FPR: 0.074\n",
      "  Nearest Neighbors                             | Acc: 0.933 | FPR@90%R: 0.905 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.861 | FPR@90%R: 0.862 | R@10%FPR: 0.333\n",
      "  RBF SVM                                       | Acc: 0.611 | FPR@90%R: 0.966 | R@10%FPR: 0.111\n",
      "  Decision Tree                                 | Acc: 0.903 | FPR@90%R: 0.905 | R@10%FPR: 0.037\n",
      "  Random Forest                                 | Acc: 0.933 | FPR@90%R: 0.836 | R@10%FPR: 0.037\n",
      "  AdaBoost                                      | Acc: 0.933 | FPR@90%R: 0.952 | R@10%FPR: 0.037\n",
      "  Naive Bayes                                   | Acc: 0.723 | FPR@90%R: 0.989 | R@10%FPR: 0.037\n",
      "\n",
      "[15/24] Host: 6ca8355\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.673 | FPR@90%R: 0.956 | R@10%FPR: 0.075\n",
      "  Nearest Neighbors                             | Acc: 0.866 | FPR@90%R: 0.826 | R@10%FPR: 0.170\n",
      "  Linear SVM                                    | Acc: 0.647 | FPR@90%R: 0.951 | R@10%FPR: 0.075\n",
      "  RBF SVM                                       | Acc: 0.710 | FPR@90%R: 0.872 | R@10%FPR: 0.226\n",
      "  Decision Tree                                 | Acc: 0.673 | FPR@90%R: 0.863 | R@10%FPR: 0.057\n",
      "  Random Forest                                 | Acc: 0.866 | FPR@90%R: 0.904 | R@10%FPR: 0.057\n",
      "  AdaBoost                                      | Acc: 0.864 | FPR@90%R: 0.863 | R@10%FPR: 0.075\n",
      "  Naive Bayes                                   | Acc: 0.630 | FPR@90%R: 0.951 | R@10%FPR: 0.057\n",
      "\n",
      "[16/24] Host: 9ab8252\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.663 | FPR@90%R: 1.000 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.983 | FPR@90%R: 1.000 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.970 | FPR@90%R: 0.934 | R@10%FPR: 0.286\n",
      "  RBF SVM                                       | Acc: 0.983 | FPR@90%R: 0.997 | R@10%FPR: 0.143\n",
      "  Decision Tree                                 | Acc: 0.918 | FPR@90%R: 1.000 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.983 | FPR@90%R: 0.942 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.983 | FPR@90%R: 0.995 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.943 | FPR@90%R: 0.848 | R@10%FPR: 0.143\n",
      "\n",
      "[17/24] Host: da6d469\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.791 | FPR@90%R: 0.933 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.973 | FPR@90%R: 0.479 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.741 | FPR@90%R: 0.964 | R@10%FPR: 0.091\n",
      "  RBF SVM                                       | Acc: 0.633 | FPR@90%R: 0.608 | R@10%FPR: 0.273\n",
      "  Decision Tree                                 | Acc: 0.933 | FPR@90%R: 0.497 | R@10%FPR: 0.091\n",
      "  Random Forest                                 | Acc: 0.973 | FPR@90%R: 0.715 | R@10%FPR: 0.182\n",
      "  AdaBoost                                      | Acc: 0.973 | FPR@90%R: 0.846 | R@10%FPR: 0.091\n",
      "  Naive Bayes                                   | Acc: 0.277 | FPR@90%R: 0.969 | R@10%FPR: 0.091\n",
      "\n",
      "[18/24] Host: 7f6d63d\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.747 | FPR@90%R: 0.949 | R@10%FPR: 0.100\n",
      "  Nearest Neighbors                             | Acc: 0.970 | FPR@90%R: 0.817 | R@10%FPR: 0.200\n",
      "  Linear SVM                                    | Acc: 0.868 | FPR@90%R: 0.954 | R@10%FPR: 0.100\n",
      "  RBF SVM                                       | Acc: 0.859 | FPR@90%R: 0.926 | R@10%FPR: 0.100\n",
      "  Decision Tree                                 | Acc: 0.620 | FPR@90%R: 0.901 | R@10%FPR: 0.200\n",
      "  Random Forest                                 | Acc: 0.975 | FPR@90%R: 0.964 | R@10%FPR: 0.200\n",
      "  AdaBoost                                      | Acc: 0.955 | FPR@90%R: 0.832 | R@10%FPR: 0.200\n",
      "  Naive Bayes                                   | Acc: 0.938 | FPR@90%R: 0.873 | R@10%FPR: 0.000\n",
      "\n",
      "[19/24] Host: 972f622\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.775 | FPR@90%R: 0.899 | R@10%FPR: 0.235\n",
      "  Nearest Neighbors                             | Acc: 0.958 | FPR@90%R: 0.856 | R@10%FPR: 0.118\n",
      "  Linear SVM                                    | Acc: 0.706 | FPR@90%R: 0.889 | R@10%FPR: 0.176\n",
      "  RBF SVM                                       | Acc: 0.578 | FPR@90%R: 0.820 | R@10%FPR: 0.176\n",
      "  Decision Tree                                 | Acc: 0.837 | FPR@90%R: 0.871 | R@10%FPR: 0.353\n",
      "  Random Forest                                 | Acc: 0.958 | FPR@90%R: 0.680 | R@10%FPR: 0.235\n",
      "  AdaBoost                                      | Acc: 0.931 | FPR@90%R: 0.639 | R@10%FPR: 0.353\n",
      "  Naive Bayes                                   | Acc: 0.926 | FPR@90%R: 0.884 | R@10%FPR: 0.353\n",
      "\n",
      "[20/24] Host: 575f518\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.729 | FPR@90%R: 0.769 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.975 | FPR@90%R: 0.304 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.627 | FPR@90%R: 0.299 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.977 | FPR@90%R: 0.894 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.612 | FPR@90%R: 0.613 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.997 | FPR@90%R: 0.626 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.992 | FPR@90%R: 0.595 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.997 | FPR@90%R: 0.631 | R@10%FPR: 0.000\n",
      "\n",
      "[21/24] Host: 953d46d\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.596 | FPR@90%R: 0.930 | R@10%FPR: 0.045\n",
      "  Nearest Neighbors                             | Acc: 0.884 | FPR@90%R: 0.719 | R@10%FPR: 0.091\n",
      "  Linear SVM                                    | Acc: 0.404 | FPR@90%R: 0.917 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.439 | FPR@90%R: 0.965 | R@10%FPR: 0.045\n",
      "  Decision Tree                                 | Acc: 0.581 | FPR@90%R: 0.866 | R@10%FPR: 0.045\n",
      "  Random Forest                                 | Acc: 0.939 | FPR@90%R: 0.888 | R@10%FPR: 0.091\n",
      "  AdaBoost                                      | Acc: 0.907 | FPR@90%R: 0.751 | R@10%FPR: 0.045\n",
      "  Naive Bayes                                   | Acc: 0.821 | FPR@90%R: 0.944 | R@10%FPR: 0.045\n",
      "\n",
      "[22/24] Host: 25b3303\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.958 | FPR@90%R: 0.959 | R@10%FPR: 0.067\n",
      "  Nearest Neighbors                             | Acc: 0.906 | FPR@90%R: 0.897 | R@10%FPR: 0.133\n",
      "  Linear SVM                                    | Acc: 0.963 | FPR@90%R: 0.974 | R@10%FPR: 0.133\n",
      "  RBF SVM                                       | Acc: 0.933 | FPR@90%R: 0.882 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.731 | FPR@90%R: 0.897 | R@10%FPR: 0.200\n",
      "  Random Forest                                 | Acc: 0.963 | FPR@90%R: 0.769 | R@10%FPR: 0.133\n",
      "  AdaBoost                                      | Acc: 0.906 | FPR@90%R: 0.951 | R@10%FPR: 0.067\n",
      "  Naive Bayes                                   | Acc: 0.963 | FPR@90%R: 0.931 | R@10%FPR: 0.067\n",
      "\n",
      "[23/24] Host: 29129b6\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.781 | FPR@90%R: 0.913 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.805 | FPR@90%R: 0.957 | R@10%FPR: 0.013\n",
      "  Linear SVM                                    | Acc: 0.778 | FPR@90%R: 0.759 | R@10%FPR: 0.128\n",
      "  RBF SVM                                       | Acc: 0.748 | FPR@90%R: 0.796 | R@10%FPR: 0.115\n",
      "  Decision Tree                                 | Acc: 0.793 | FPR@90%R: 0.950 | R@10%FPR: 0.038\n",
      "  Random Forest                                 | Acc: 0.805 | FPR@90%R: 0.944 | R@10%FPR: 0.167\n",
      "  AdaBoost                                      | Acc: 0.805 | FPR@90%R: 0.854 | R@10%FPR: 0.026\n",
      "  Naive Bayes                                   | Acc: 0.623 | FPR@90%R: 0.929 | R@10%FPR: 0.051\n",
      "\n",
      "[24/24] Host: 9dc32f2\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.606 | FPR@90%R: 0.901 | R@10%FPR: 0.150\n",
      "  Nearest Neighbors                             | Acc: 0.733 | FPR@90%R: 0.849 | R@10%FPR: 0.200\n",
      "  Linear SVM                                    | Acc: 0.688 | FPR@90%R: 0.895 | R@10%FPR: 0.080\n",
      "  RBF SVM                                       | Acc: 0.656 | FPR@90%R: 0.921 | R@10%FPR: 0.290\n",
      "  Decision Tree                                 | Acc: 0.572 | FPR@90%R: 0.928 | R@10%FPR: 0.030\n",
      "  Random Forest                                 | Acc: 0.730 | FPR@90%R: 0.875 | R@10%FPR: 0.140\n",
      "  AdaBoost                                      | Acc: 0.743 | FPR@90%R: 0.911 | R@10%FPR: 0.100\n",
      "  Naive Bayes                                   | Acc: 0.629 | FPR@90%R: 0.898 | R@10%FPR: 0.170\n",
      "\n",
      "Completed dspot_anomaly\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 30\n",
      "Hosts with anomalies in test: 27\n",
      "Hosts with anomalies in BOTH train and test: 25\n",
      "\n",
      "\n",
      "[1/25] Host: 0f42441\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.831 | FPR@90%R: 1.000 | R@10%FPR: 0.545\n",
      "  Nearest Neighbors                             | Acc: 0.912 | FPR@90%R: 0.248 | R@10%FPR: 0.364\n",
      "  Linear SVM                                    | Acc: 0.844 | FPR@90%R: 0.403 | R@10%FPR: 0.455\n",
      "  RBF SVM                                       | Acc: 0.794 | FPR@90%R: 0.456 | R@10%FPR: 0.273\n",
      "  Decision Tree                                 | Acc: 0.844 | FPR@90%R: 0.973 | R@10%FPR: 0.182\n",
      "  Random Forest                                 | Acc: 0.900 | FPR@90%R: 0.993 | R@10%FPR: 0.273\n",
      "  AdaBoost                                      | Acc: 0.900 | FPR@90%R: 0.933 | R@10%FPR: 0.182\n",
      "  Naive Bayes                                   | Acc: 0.794 | FPR@90%R: 0.423 | R@10%FPR: 0.636\n",
      "\n",
      "[2/25] Host: c073f39\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.931 | FPR@90%R: 0.522 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.998 | FPR@90%R: 0.269 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.950 | FPR@90%R: 0.614 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.988 | FPR@90%R: 0.652 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.963 | FPR@90%R: 0.286 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.998 | FPR@90%R: 0.363 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.998 | FPR@90%R: 0.169 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.998 | FPR@90%R: 0.659 | R@10%FPR: 0.000\n",
      "\n",
      "[3/25] Host: b340432\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.773 | FPR@90%R: 0.860 | R@10%FPR: 0.250\n",
      "  Nearest Neighbors                             | Acc: 0.970 | FPR@90%R: 0.672 | R@10%FPR: 0.250\n",
      "  Linear SVM                                    | Acc: 0.627 | FPR@90%R: 0.863 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.719 | FPR@90%R: 0.840 | R@10%FPR: 0.167\n",
      "  Decision Tree                                 | Acc: 0.802 | FPR@90%R: 0.738 | R@10%FPR: 0.083\n",
      "  Random Forest                                 | Acc: 0.970 | FPR@90%R: 0.903 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.965 | FPR@90%R: 0.756 | R@10%FPR: 0.250\n",
      "  Naive Bayes                                   | Acc: 0.901 | FPR@90%R: 0.863 | R@10%FPR: 0.167\n",
      "\n",
      "[4/25] Host: 38b6bf0\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.611 | FPR@90%R: 0.951 | R@10%FPR: 0.067\n",
      "  Nearest Neighbors                             | Acc: 0.963 | FPR@90%R: 0.964 | R@10%FPR: 0.200\n",
      "  Linear SVM                                    | Acc: 0.536 | FPR@90%R: 0.922 | R@10%FPR: 0.200\n",
      "  RBF SVM                                       | Acc: 0.776 | FPR@90%R: 0.953 | R@10%FPR: 0.067\n",
      "  Decision Tree                                 | Acc: 0.758 | FPR@90%R: 0.845 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.963 | FPR@90%R: 0.894 | R@10%FPR: 0.200\n",
      "  AdaBoost                                      | Acc: 0.958 | FPR@90%R: 0.894 | R@10%FPR: 0.067\n",
      "  Naive Bayes                                   | Acc: 0.853 | FPR@90%R: 0.915 | R@10%FPR: 0.067\n",
      "\n",
      "[5/25] Host: dede9dc\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.885 | FPR@90%R: 0.065 | R@10%FPR: 1.000\n",
      "  Nearest Neighbors                             | Acc: 0.997 | FPR@90%R: 0.357 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.890 | FPR@90%R: 0.910 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.987 | FPR@90%R: 0.113 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.955 | FPR@90%R: 0.384 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.997 | FPR@90%R: 0.427 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.997 | FPR@90%R: 0.088 | R@10%FPR: 1.000\n",
      "  Naive Bayes                                   | Acc: 0.566 | FPR@90%R: 0.078 | R@10%FPR: 1.000\n",
      "\n",
      "[6/25] Host: b407ebe\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.786 | FPR@90%R: 0.856 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.987 | FPR@90%R: 0.765 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.814 | FPR@90%R: 0.966 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.843 | FPR@90%R: 0.708 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.874 | FPR@90%R: 0.765 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.987 | FPR@90%R: 0.802 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.982 | FPR@90%R: 0.888 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.853 | FPR@90%R: 0.916 | R@10%FPR: 0.200\n",
      "\n",
      "[7/25] Host: f8f4b44\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.665 | FPR@90%R: 0.729 | R@10%FPR: 0.250\n",
      "  Nearest Neighbors                             | Acc: 0.990 | FPR@90%R: 0.992 | R@10%FPR: 0.250\n",
      "  Linear SVM                                    | Acc: 0.581 | FPR@90%R: 0.995 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.608 | FPR@90%R: 0.985 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.799 | FPR@90%R: 0.962 | R@10%FPR: 0.250\n",
      "  Random Forest                                 | Acc: 0.990 | FPR@90%R: 0.885 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.988 | FPR@90%R: 0.544 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.958 | FPR@90%R: 0.571 | R@10%FPR: 0.250\n",
      "\n",
      "[8/25] Host: b5c8445\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.781 | FPR@90%R: 0.211 | R@10%FPR: 0.250\n",
      "  Nearest Neighbors                             | Acc: 0.880 | FPR@90%R: 0.544 | R@10%FPR: 0.417\n",
      "  Linear SVM                                    | Acc: 0.792 | FPR@90%R: 0.211 | R@10%FPR: 0.250\n",
      "  RBF SVM                                       | Acc: 0.787 | FPR@90%R: 0.994 | R@10%FPR: 0.333\n",
      "  Decision Tree                                 | Acc: 0.929 | FPR@90%R: 0.848 | R@10%FPR: 0.333\n",
      "  Random Forest                                 | Acc: 0.896 | FPR@90%R: 0.158 | R@10%FPR: 0.417\n",
      "  AdaBoost                                      | Acc: 0.929 | FPR@90%R: 0.187 | R@10%FPR: 0.750\n",
      "  Naive Bayes                                   | Acc: 0.852 | FPR@90%R: 0.994 | R@10%FPR: 0.333\n",
      "\n",
      "[9/25] Host: 9840de6\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.595 | FPR@90%R: 0.640 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.997 | FPR@90%R: 0.801 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.553 | FPR@90%R: 0.637 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.997 | FPR@90%R: 0.607 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.804 | FPR@90%R: 0.975 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.997 | FPR@90%R: 0.904 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.992 | FPR@90%R: 0.529 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.960 | FPR@90%R: 0.678 | R@10%FPR: 0.000\n",
      "\n",
      "[10/25] Host: d493afd\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.888 | FPR@90%R: 0.649 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.994 | FPR@90%R: 0.702 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.893 | FPR@90%R: 0.685 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.053 | FPR@90%R: 0.262 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.959 | FPR@90%R: 0.708 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.994 | FPR@90%R: 0.720 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.959 | FPR@90%R: 0.702 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.734 | FPR@90%R: 0.417 | R@10%FPR: 0.000\n",
      "\n",
      "[11/25] Host: 2620a05\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.580 | FPR@90%R: 0.943 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.993 | FPR@90%R: 0.535 | R@10%FPR: 0.333\n",
      "  Linear SVM                                    | Acc: 0.632 | FPR@90%R: 0.689 | R@10%FPR: 0.667\n",
      "  RBF SVM                                       | Acc: 0.464 | FPR@90%R: 0.774 | R@10%FPR: 0.333\n",
      "  Decision Tree                                 | Acc: 0.909 | FPR@90%R: 0.577 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.993 | FPR@90%R: 0.570 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.993 | FPR@90%R: 0.746 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.560 | FPR@90%R: 0.776 | R@10%FPR: 0.000\n",
      "\n",
      "[12/25] Host: a2e0486\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.770 | FPR@90%R: 0.859 | R@10%FPR: 0.200\n",
      "  Nearest Neighbors                             | Acc: 0.963 | FPR@90%R: 0.813 | R@10%FPR: 0.067\n",
      "  Linear SVM                                    | Acc: 0.773 | FPR@90%R: 0.823 | R@10%FPR: 0.067\n",
      "  RBF SVM                                       | Acc: 0.684 | FPR@90%R: 0.959 | R@10%FPR: 0.000\n",
      "  Decision Tree                                 | Acc: 0.919 | FPR@90%R: 0.869 | R@10%FPR: 0.067\n",
      "  Random Forest                                 | Acc: 0.963 | FPR@90%R: 0.736 | R@10%FPR: 0.200\n",
      "  AdaBoost                                      | Acc: 0.963 | FPR@90%R: 0.877 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.662 | FPR@90%R: 0.762 | R@10%FPR: 0.200\n",
      "\n",
      "[13/25] Host: b2c53ee\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.696 | FPR@90%R: 0.943 | R@10%FPR: 0.031\n",
      "  Nearest Neighbors                             | Acc: 0.916 | FPR@90%R: 0.903 | R@10%FPR: 0.031\n",
      "  Linear SVM                                    | Acc: 0.727 | FPR@90%R: 0.842 | R@10%FPR: 0.250\n",
      "  RBF SVM                                       | Acc: 0.535 | FPR@90%R: 0.768 | R@10%FPR: 0.031\n",
      "  Decision Tree                                 | Acc: 0.785 | FPR@90%R: 0.891 | R@10%FPR: 0.094\n",
      "  Random Forest                                 | Acc: 0.916 | FPR@90%R: 0.564 | R@10%FPR: 0.031\n",
      "  AdaBoost                                      | Acc: 0.916 | FPR@90%R: 0.871 | R@10%FPR: 0.094\n",
      "  Naive Bayes                                   | Acc: 0.533 | FPR@90%R: 0.977 | R@10%FPR: 0.031\n",
      "\n",
      "[14/25] Host: 33fe84e\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.546 | FPR@90%R: 0.840 | R@10%FPR: 0.095\n",
      "  Nearest Neighbors                             | Acc: 0.943 | FPR@90%R: 0.950 | R@10%FPR: 0.095\n",
      "  Linear SVM                                    | Acc: 0.211 | FPR@90%R: 0.783 | R@10%FPR: 0.048\n",
      "  RBF SVM                                       | Acc: 0.854 | FPR@90%R: 0.846 | R@10%FPR: 0.143\n",
      "  Decision Tree                                 | Acc: 0.811 | FPR@90%R: 0.924 | R@10%FPR: 0.048\n",
      "  Random Forest                                 | Acc: 0.948 | FPR@90%R: 0.908 | R@10%FPR: 0.143\n",
      "  AdaBoost                                      | Acc: 0.943 | FPR@90%R: 0.919 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.948 | FPR@90%R: 0.872 | R@10%FPR: 0.048\n",
      "\n",
      "[15/25] Host: ed86ea2\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.809 | FPR@90%R: 0.955 | R@10%FPR: 0.357\n",
      "  Nearest Neighbors                             | Acc: 0.858 | FPR@90%R: 0.983 | R@10%FPR: 0.429\n",
      "  Linear SVM                                    | Acc: 0.819 | FPR@90%R: 0.949 | R@10%FPR: 0.393\n",
      "  RBF SVM                                       | Acc: 0.725 | FPR@90%R: 0.562 | R@10%FPR: 0.429\n",
      "  Decision Tree                                 | Acc: 0.848 | FPR@90%R: 0.983 | R@10%FPR: 0.071\n",
      "  Random Forest                                 | Acc: 0.863 | FPR@90%R: 0.955 | R@10%FPR: 0.393\n",
      "  AdaBoost                                      | Acc: 0.848 | FPR@90%R: 0.960 | R@10%FPR: 0.071\n",
      "  Naive Bayes                                   | Acc: 0.799 | FPR@90%R: 0.966 | R@10%FPR: 0.250\n",
      "\n",
      "[16/25] Host: 6ca8355\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.824 | FPR@90%R: 0.957 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.940 | FPR@90%R: 0.820 | R@10%FPR: 0.125\n",
      "  Linear SVM                                    | Acc: 0.859 | FPR@90%R: 0.965 | R@10%FPR: 0.083\n",
      "  RBF SVM                                       | Acc: 0.768 | FPR@90%R: 0.906 | R@10%FPR: 0.083\n",
      "  Decision Tree                                 | Acc: 0.940 | FPR@90%R: 0.780 | R@10%FPR: 0.375\n",
      "  Random Forest                                 | Acc: 0.940 | FPR@90%R: 0.877 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.940 | FPR@90%R: 0.786 | R@10%FPR: 0.042\n",
      "  Naive Bayes                                   | Acc: 0.940 | FPR@90%R: 0.761 | R@10%FPR: 0.083\n",
      "\n",
      "[17/25] Host: da6d469\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.793 | FPR@90%R: 0.941 | R@10%FPR: 0.100\n",
      "  Nearest Neighbors                             | Acc: 0.975 | FPR@90%R: 0.473 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.845 | FPR@90%R: 0.951 | R@10%FPR: 0.100\n",
      "  RBF SVM                                       | Acc: 0.334 | FPR@90%R: 0.760 | R@10%FPR: 0.200\n",
      "  Decision Tree                                 | Acc: 0.958 | FPR@90%R: 0.478 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.975 | FPR@90%R: 0.714 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.958 | FPR@90%R: 0.458 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.975 | FPR@90%R: 0.473 | R@10%FPR: 0.000\n",
      "\n",
      "[18/25] Host: 7f6d63d\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.859 | FPR@90%R: 0.825 | R@10%FPR: 0.000\n",
      "  Nearest Neighbors                             | Acc: 0.993 | FPR@90%R: 0.915 | R@10%FPR: 0.000\n",
      "  Linear SVM                                    | Acc: 0.777 | FPR@90%R: 0.748 | R@10%FPR: 0.000\n",
      "  RBF SVM                                       | Acc: 0.953 | FPR@90%R: 0.890 | R@10%FPR: 0.333\n",
      "  Decision Tree                                 | Acc: 0.787 | FPR@90%R: 0.772 | R@10%FPR: 0.000\n",
      "  Random Forest                                 | Acc: 0.993 | FPR@90%R: 0.743 | R@10%FPR: 0.000\n",
      "  AdaBoost                                      | Acc: 0.990 | FPR@90%R: 0.932 | R@10%FPR: 0.000\n",
      "  Naive Bayes                                   | Acc: 0.968 | FPR@90%R: 0.748 | R@10%FPR: 0.000\n",
      "\n",
      "[19/25] Host: 972f622\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.775 | FPR@90%R: 0.899 | R@10%FPR: 0.235\n",
      "  Nearest Neighbors                             | Acc: 0.958 | FPR@90%R: 0.856 | R@10%FPR: 0.118\n",
      "  Linear SVM                                    | Acc: 0.706 | FPR@90%R: 0.889 | R@10%FPR: 0.176\n",
      "  RBF SVM                                       | Acc: 0.578 | FPR@90%R: 0.820 | R@10%FPR: 0.176\n",
      "  Decision Tree                                 | Acc: 0.837 | FPR@90%R: 0.871 | R@10%FPR: 0.353\n",
      "  Random Forest                                 | Acc: 0.958 | FPR@90%R: 0.791 | R@10%FPR: 0.294\n",
      "  AdaBoost                                      | Acc: 0.931 | FPR@90%R: 0.639 | R@10%FPR: 0.353\n",
      "  Naive Bayes                                   | Acc: 0.926 | FPR@90%R: 0.884 | R@10%FPR: 0.353\n",
      "\n",
      "[20/25] Host: 575f518\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.724 | FPR@90%R: 0.858 | R@10%FPR: 0.167\n",
      "  Nearest Neighbors                             | Acc: 0.985 | FPR@90%R: 0.382 | R@10%FPR: 0.500\n",
      "  Linear SVM                                    | Acc: 0.639 | FPR@90%R: 0.873 | R@10%FPR: 0.167\n",
      "  RBF SVM                                       | Acc: 0.887 | FPR@90%R: 0.880 | R@10%FPR: 0.500\n",
      "  Decision Tree                                 | Acc: 0.845 | FPR@90%R: 0.506 | R@10%FPR: 0.167\n",
      "  Random Forest                                 | Acc: 0.985 | FPR@90%R: 0.501 | R@10%FPR: 0.333\n",
      "  AdaBoost                                      | Acc: 0.985 | FPR@90%R: 0.885 | R@10%FPR: 0.167\n",
      "  Naive Bayes                                   | Acc: 0.912 | FPR@90%R: 0.753 | R@10%FPR: 0.333\n",
      "\n",
      "[21/25] Host: 5c5004f\n"
     ]
    }
   ],
   "source": [
    "# Define the three anomaly columns to evaluate\n",
    "anomaly_columns = ['basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n",
    "\n",
    "# Store results for each method\n",
    "all_results_by_method = {}\n",
    "\n",
    "# Columns to remove when creating features\n",
    "remove_cols = ['label', 'date', 'hostname']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANOMALY DETECTION METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Filter to hosts that have anomalies in both train and test for this method\n",
    "    train_hostnames_with_anomalies = train[train[label_col] == True]['hostname'].unique()\n",
    "    test_hostnames_with_anomalies = test[test[label_col] == True]['hostname'].unique()\n",
    "    hostnames_in_both = set(train_hostnames_with_anomalies).intersection(set(test_hostnames_with_anomalies))\n",
    "    \n",
    "    print(f\"Hosts with anomalies in train: {len(train_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in test: {len(test_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in BOTH train and test: {len(hostnames_in_both)}\\n\")\n",
    "    \n",
    "    if len(hostnames_in_both) == 0:\n",
    "        print(f\"WARNING: No hosts have anomalies in both train and test for {label_col}. Skipping.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Filter train and test to only these hosts\n",
    "    train_filtered = train[train['hostname'].isin(hostnames_in_both)]\n",
    "    test_filtered = test[test['hostname'].isin(hostnames_in_both)]\n",
    "    \n",
    "    # Evaluate models for each host\n",
    "    method_results = []\n",
    "    \n",
    "    for i, cur_hostname in enumerate(hostnames_in_both, 1):\n",
    "        print(f\"\\n[{i}/{len(hostnames_in_both)}] Host: {cur_hostname}\")\n",
    "        \n",
    "        # Create features using this label column\n",
    "        train_single_w_lookback = transform_single_df_to_features(train_filtered, cur_hostname, label_col=label_col)\n",
    "        test_single_w_lookback = transform_single_df_to_features(test_filtered, cur_hostname, label_col=label_col)\n",
    "        \n",
    "        # Prepare X and y\n",
    "        X_train = train_single_w_lookback.drop(columns=remove_cols)\n",
    "        X_test = test_single_w_lookback.drop(columns=remove_cols)\n",
    "        y_train = train_single_w_lookback[\"label\"].astype(int)\n",
    "        y_test = test_single_w_lookback[\"label\"].astype(int)\n",
    "        \n",
    "        # Evaluate models\n",
    "        hostname_results = evaluate_model_per_device(X_train, y_train, X_test, y_test, cur_hostname)\n",
    "        \n",
    "        method_results.extend(hostname_results)\n",
    "    \n",
    "    # Store results for this method\n",
    "    all_results_by_method[label_col] = pd.DataFrame(method_results)\n",
    "\n",
    "    print(f\"\\nCompleted {label_col}\\n\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f199ec",
   "metadata": {},
   "source": [
    "## 7. Results Summary\n",
    "\n",
    "Display aggregate statistics for each anomaly detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3b4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Key Metrics (averaged across devices):\n",
      "                                         accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                                \n",
      "AdaBoost                                   0.8345            0.8594            0.1400\n",
      "Decision Tree                              0.6737            0.8711            0.1137\n",
      "Linear Classifier (Logistic Regression)    0.6529            0.7972            0.1601\n",
      "Linear SVM                                 0.6037            0.8348            0.1532\n",
      "Naive Bayes                                0.7543            0.8415            0.2171\n",
      "Nearest Neighbors                          0.8400            0.8206            0.1879\n",
      "RBF SVM                                    0.5632            0.7943            0.1893\n",
      "Random Forest                              0.8683            0.8293            0.1530\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: Random Forest (0.8683)\n",
      "Best FPR at 90% Recall: RBF SVM (0.7943)\n",
      "Best Recall at 10% FPR: Naive Bayes (0.2171)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Key Metrics (averaged across devices):\n",
      "                                         accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                                \n",
      "AdaBoost                                   0.9035            0.8512            0.0826\n",
      "Decision Tree                              0.7429            0.8497            0.0792\n",
      "Linear Classifier (Logistic Regression)    0.6724            0.9101            0.0858\n",
      "Linear SVM                                 0.6879            0.8347            0.1338\n",
      "Naive Bayes                                0.6666            0.9083            0.1045\n",
      "Nearest Neighbors                          0.9054            0.7896            0.0762\n",
      "RBF SVM                                    0.6911            0.8557            0.1107\n",
      "Random Forest                              0.9168            0.8217            0.0867\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: Random Forest (0.9168)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.7896)\n",
      "Best Recall at 10% FPR: Linear SVM (0.1338)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Key Metrics (averaged across devices):\n",
      "                                         accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                                \n",
      "AdaBoost                                   0.9490            0.7297            0.1313\n",
      "Decision Tree                              0.8558            0.7710            0.0959\n",
      "Linear Classifier (Logistic Regression)    0.7606            0.7844            0.1637\n",
      "Linear SVM                                 0.7103            0.7836            0.1514\n",
      "Naive Bayes                                0.7861            0.7341            0.1991\n",
      "Nearest Neighbors                          0.9502            0.7163            0.1458\n",
      "RBF SVM                                    0.7261            0.7625            0.1467\n",
      "Random Forest                              0.9553            0.7326            0.1175\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: Random Forest (0.9553)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.7163)\n",
      "Best Recall at 10% FPR: Naive Bayes (0.1991)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Group by model and calculate mean metrics\n",
    "    grouped = results_df.groupby('model').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'fpr_at_90_recall': 'mean',\n",
    "        'recall_at_10_fpr': 'mean',\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"Key Metrics (averaged across devices):\")\n",
    "    print(grouped.to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Best Models:\")\n",
    "    print(\"-\"*80)\n",
    "    best_acc = grouped['accuracy'].idxmax()\n",
    "    best_fpr_90 = grouped['fpr_at_90_recall'].idxmin()  # Lower is better\n",
    "    best_recall_10 = grouped['recall_at_10_fpr'].idxmax()  # Higher is better\n",
    "    \n",
    "    print(f\"Best Accuracy: {best_acc} ({grouped.loc[best_acc, 'accuracy']:.4f})\")\n",
    "    print(f\"Best FPR at 90% Recall: {best_fpr_90} ({grouped.loc[best_fpr_90, 'fpr_at_90_recall']:.4f})\")\n",
    "    print(f\"Best Recall at 10% FPR: {best_recall_10} ({grouped.loc[best_recall_10, 'recall_at_10_fpr']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda46b0d",
   "metadata": {},
   "source": [
    "## 8. Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d255837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for basic_ema_anomaly to per_device_results_basic_ema_anomaly.csv\n",
      "Saved results for dspot_anomaly to per_device_results_dspot_anomaly.csv\n",
      "Saved results for tuned_dspot_anomaly to per_device_results_tuned_dspot_anomaly.csv\n",
      "\n",
      "All results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results for each method\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    filename = f\"per_device_results_{label_col}.csv\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved results for {label_col} to {filename}\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5b67c",
   "metadata": {},
   "source": [
    "## 9. Exploratory: Multi-Device Models\n",
    "\n",
    "Train models on ALL data combined (not split per device) and evaluate with the same metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5fd38",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook evaluated per-device ML models on three different anomaly detection methods:\n",
    "1. **basic_ema_anomaly**: Basic EMA-based detection\n",
    "2. **dspot_anomaly**: DSPOT detection\n",
    "3. **tuned_dspot_anomaly**: Tuned DSPOT detection\n",
    "\n",
    "For each method, we trained 8 different ML models per device and calculated:\n",
    "- Standard classification metrics (accuracy, F1, precision, recall, ROC-AUC)\n",
    "- **FPR at 90% Recall**: Answers \"how many false alarms to catch 90% of issues?\"\n",
    "- **Recall at 10% FPR**: Answers \"how many issues caught with 10% false alarm rate?\"\n",
    "\n",
    "The threshold-based metrics are particularly useful for understanding:\n",
    "- **Customers who want to catch as many anomalies as possible**: Look at FPR at 90% Recall\n",
    "- **Customers who want to minimize false alarms**: Look at Recall at 10% FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49059a4f",
   "metadata": {},
   "source": [
    "### Multi-Device Feature Engineering\n",
    "\n",
    "Create features from all devices combined for each anomaly detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4feabcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-device feature engineering function defined\n"
     ]
    }
   ],
   "source": [
    "def transform_multidevice_df_to_features(df, label_col='predictions'):\n",
    "    \"\"\"\n",
    "    Create features for all devices combined.\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataframe with multiple devices\n",
    "        label_col: Column name to use as labels\n",
    "    \"\"\"\n",
    "    hostnames = df[\"hostname\"].unique().tolist()\n",
    "    featured_dfs = []\n",
    "    \n",
    "    for cur_hostname in hostnames:\n",
    "        host_isolated = df[df['hostname'] == cur_hostname]\n",
    "        host_isolated = host_isolated.sort_values(by='date', ascending=True)\n",
    "        feature_df = get_feature_df(host_isolated, label_col=label_col, latency_to_use='ping_latency')\n",
    "        featured_dfs.append(feature_df)\n",
    "    \n",
    "    final_df = pd.concat(featured_dfs, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "print(\"Multi-device feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600fc8e",
   "metadata": {},
   "source": [
    "### Evaluate Multi-Device Models\n",
    "\n",
    "Train on all data combined and evaluate with the same metrics as per-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "546b4e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING MULTI-DEVICE MODELS (TRAINED ON ALL DATA COMBINED)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Train: 14548 samples, 1769 anomalies (12.2%)\n",
      "Test: 11071 samples, 1455 anomalies (13.1%)\n",
      "\n",
      "Results:\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.534 | FPR@90%R: 0.689 | R@10%FPR: 0.293\n",
      "  Nearest Neighbors                             | Acc: 0.838 | FPR@90%R: 0.880 | R@10%FPR: 0.179\n",
      "  Linear SVM                                    | Acc: 0.435 | FPR@90%R: 0.689 | R@10%FPR: 0.218\n",
      "  RBF SVM                                       | Acc: 0.551 | FPR@90%R: 0.747 | R@10%FPR: 0.188\n",
      "  Decision Tree                                 | Acc: 0.591 | FPR@90%R: 0.743 | R@10%FPR: 0.208\n",
      "  Random Forest                                 | Acc: 0.866 | FPR@90%R: 0.716 | R@10%FPR: 0.210\n",
      "  AdaBoost                                      | Acc: 0.868 | FPR@90%R: 0.709 | R@10%FPR: 0.240\n",
      "  Naive Bayes                                   | Acc: 0.737 | FPR@90%R: 0.703 | R@10%FPR: 0.277\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Train: 11255 samples, 779 anomalies (6.9%)\n",
      "Test: 9379 samples, 768 anomalies (8.2%)\n",
      "\n",
      "Results:\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.642 | FPR@90%R: 0.634 | R@10%FPR: 0.406\n",
      "  Nearest Neighbors                             | Acc: 0.904 | FPR@90%R: 0.774 | R@10%FPR: 0.197\n",
      "  Linear SVM                                    | Acc: 0.555 | FPR@90%R: 0.625 | R@10%FPR: 0.292\n",
      "  RBF SVM                                       | Acc: 0.631 | FPR@90%R: 0.815 | R@10%FPR: 0.254\n",
      "  Decision Tree                                 | Acc: 0.635 | FPR@90%R: 0.726 | R@10%FPR: 0.271\n",
      "  Random Forest                                 | Acc: 0.917 | FPR@90%R: 0.720 | R@10%FPR: 0.328\n",
      "  AdaBoost                                      | Acc: 0.918 | FPR@90%R: 0.753 | R@10%FPR: 0.324\n",
      "  Naive Bayes                                   | Acc: 0.831 | FPR@90%R: 0.619 | R@10%FPR: 0.401\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Train: 10852 samples, 355 anomalies (3.3%)\n",
      "Test: 8640 samples, 299 anomalies (3.5%)\n",
      "\n",
      "Results:\n",
      "  Linear Classifier (Logistic Regression)       | Acc: 0.756 | FPR@90%R: 0.814 | R@10%FPR: 0.468\n",
      "  Nearest Neighbors                             | Acc: 0.963 | FPR@90%R: 0.730 | R@10%FPR: 0.251\n",
      "  Linear SVM                                    | Acc: 0.743 | FPR@90%R: 0.805 | R@10%FPR: 0.247\n",
      "  RBF SVM                                       | Acc: 0.780 | FPR@90%R: 0.845 | R@10%FPR: 0.231\n",
      "  Decision Tree                                 | Acc: 0.777 | FPR@90%R: 0.961 | R@10%FPR: 0.321\n",
      "  Random Forest                                 | Acc: 0.965 | FPR@90%R: 0.803 | R@10%FPR: 0.301\n",
      "  AdaBoost                                      | Acc: 0.965 | FPR@90%R: 0.897 | R@10%FPR: 0.391\n",
      "  Naive Bayes                                   | Acc: 0.893 | FPR@90%R: 0.792 | R@10%FPR: 0.482\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Store multi-device results\n",
    "all_multidevice_results = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING MULTI-DEVICE MODELS (TRAINED ON ALL DATA COMBINED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MULTI-DEVICE MODEL FOR: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Use the same filtered train/test as per-device models\n",
    "    # Get hosts with anomalies in both train and test\n",
    "    train_hostnames_with_anomalies = train[train[label_col] == True]['hostname'].unique()\n",
    "    test_hostnames_with_anomalies = test[test[label_col] == True]['hostname'].unique()\n",
    "    hostnames_in_both = set(train_hostnames_with_anomalies).intersection(set(test_hostnames_with_anomalies))\n",
    "    \n",
    "    if len(hostnames_in_both) == 0:\n",
    "        print(f\"WARNING: No hosts have anomalies in both train and test for {label_col}. Skipping.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Filter to hosts with anomalies in both\n",
    "    train_filtered = train[train['hostname'].isin(hostnames_in_both)]\n",
    "    test_filtered = test[test['hostname'].isin(hostnames_in_both)]\n",
    "    \n",
    "    # Create features for ALL devices combined\n",
    "    train_multi_w_lookback = transform_multidevice_df_to_features(train_filtered, label_col=label_col)\n",
    "    test_multi_w_lookback = transform_multidevice_df_to_features(test_filtered, label_col=label_col)\n",
    "    \n",
    "    # Prepare X and y\n",
    "    X_train = train_multi_w_lookback.drop(columns=remove_cols)\n",
    "    X_test = test_multi_w_lookback.drop(columns=remove_cols)\n",
    "    y_train = train_multi_w_lookback[\"label\"].astype(int)\n",
    "    y_test = test_multi_w_lookback[\"label\"].astype(int)\n",
    "    \n",
    "    # Normalize features based on training data only (no leakage)\n",
    "    train_mean = X_train.mean()\n",
    "    train_std = X_train.std()\n",
    "    X_train_normalized = (X_train - train_mean) / train_std\n",
    "    X_test_normalized = (X_test - train_mean) / train_std  # Use train stats\n",
    "    \n",
    "    # Fill NaNs with 0 (from division by zero std)\n",
    "    X_train_normalized = X_train_normalized.fillna(0)\n",
    "    X_test_normalized = X_test_normalized.fillna(0)\n",
    "    \n",
    "    print(f\"Train: {len(X_train)} samples, {y_train.sum()} anomalies ({y_train.mean()*100:.1f}%)\")\n",
    "    print(f\"Test: {len(X_test)} samples, {y_test.sum()} anomalies ({y_test.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = []\n",
    "    \n",
    "    for model_name, clf in model_dict.items():\n",
    "        clf.fit(X_train_normalized, y_train)\n",
    "        y_pred = clf.predict(X_test_normalized)\n",
    "        \n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test_normalized)[:, 1]\n",
    "            has_proba = True\n",
    "        except:\n",
    "            y_proba = None\n",
    "            has_proba = False\n",
    "        \n",
    "        # Standard metrics\n",
    "        accuracy = clf.score(X_test_normalized, y_test)\n",
    "        f1_anomaly = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        roc_auc = -1\n",
    "        fpr_at_90_recall = -1\n",
    "        recall_at_10_fpr = -1\n",
    "        \n",
    "        if has_proba:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            fpr_at_90_recall, recall_at_10_fpr = calculate_threshold_metrics(y_test, y_proba)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_anomaly,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr_at_90_recall': fpr_at_90_recall,\n",
    "            'recall_at_10_fpr': recall_at_10_fpr,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            'caught_anomalies': tp,\n",
    "            'missed_anomalies': fn,\n",
    "            'false_alarms': fp,\n",
    "            'total_test_samples': len(y_test),\n",
    "            'total_anomalies': y_test.sum()\n",
    "        })\n",
    "    \n",
    "    all_multidevice_results[label_col] = pd.DataFrame(results)\n",
    "    \n",
    "    # Print results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults:\")\n",
    "    for _, row in results_df.iterrows():\n",
    "        print(f\"  {row['model']:45s} | Acc: {row['accuracy']:.3f} | FPR@90%R: {row['fpr_at_90_recall']:.3f} | R@10%FPR: {row['recall_at_10_fpr']:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-DEVICE EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68283cc",
   "metadata": {},
   "source": [
    "### Multi-Device Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27bc1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Key Metrics:\n",
      "                                  model  accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)  0.534188          0.689164          0.292784\n",
      "                      Nearest Neighbors  0.837684          0.880304          0.178694\n",
      "                             Linear SVM  0.434830          0.689060          0.217869\n",
      "                                RBF SVM  0.550628          0.747296          0.187629\n",
      "                          Decision Tree  0.591094          0.742720          0.208247\n",
      "                          Random Forest  0.865775          0.716202          0.210309\n",
      "                               AdaBoost  0.867943          0.709235          0.239863\n",
      "                            Naive Bayes  0.736609          0.702891          0.276976\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: AdaBoost (0.8679)\n",
      "Best FPR at 90% Recall: Linear SVM (0.6891)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.2928)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Key Metrics:\n",
      "                                  model  accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)  0.641859          0.634189          0.406250\n",
      "                      Nearest Neighbors  0.904361          0.774010          0.196615\n",
      "                             Linear SVM  0.555070          0.625363          0.291667\n",
      "                                RBF SVM  0.631411          0.815469          0.253906\n",
      "                          Decision Tree  0.635142          0.725584          0.270833\n",
      "                          Random Forest  0.917369          0.720358          0.328125\n",
      "                               AdaBoost  0.917688          0.752874          0.324219\n",
      "                            Naive Bayes  0.830899          0.618860          0.401042\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: AdaBoost (0.9177)\n",
      "Best FPR at 90% Recall: Naive Bayes (0.6189)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.4062)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Key Metrics:\n",
      "                                  model  accuracy  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)  0.755556          0.813811          0.468227\n",
      "                      Nearest Neighbors  0.962500          0.730488          0.250836\n",
      "                             Linear SVM  0.743403          0.805299          0.247492\n",
      "                                RBF SVM  0.779977          0.844623          0.230769\n",
      "                          Decision Tree  0.776968          0.960676          0.321070\n",
      "                          Random Forest  0.964815          0.803261          0.301003\n",
      "                               AdaBoost  0.965278          0.897255          0.391304\n",
      "                            Naive Bayes  0.892708          0.792471          0.481605\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Accuracy: AdaBoost (0.9653)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.7305)\n",
      "Best Recall at 10% FPR: Naive Bayes (0.4816)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-DEVICE MODEL RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col, results_df in all_multidevice_results.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col} (Multi-Device Model)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(\"Key Metrics:\")\n",
    "    print(results_df[['model', 'accuracy', 'fpr_at_90_recall', 'recall_at_10_fpr']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Best Models:\")\n",
    "    print(\"-\"*80)\n",
    "    best_acc_idx = results_df['accuracy'].idxmax()\n",
    "    best_fpr_90_idx = results_df['fpr_at_90_recall'].idxmin()\n",
    "    best_recall_10_idx = results_df['recall_at_10_fpr'].idxmax()\n",
    "    \n",
    "    print(f\"Best Accuracy: {results_df.loc[best_acc_idx, 'model']} ({results_df.loc[best_acc_idx, 'accuracy']:.4f})\")\n",
    "    print(f\"Best FPR at 90% Recall: {results_df.loc[best_fpr_90_idx, 'model']} ({results_df.loc[best_fpr_90_idx, 'fpr_at_90_recall']:.4f})\")\n",
    "    print(f\"Best Recall at 10% FPR: {results_df.loc[best_recall_10_idx, 'model']} ({results_df.loc[best_recall_10_idx, 'recall_at_10_fpr']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4183ef",
   "metadata": {},
   "source": [
    "### Save Multi-Device Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0613512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved multi-device results for basic_ema_anomaly to multidevice_results_basic_ema_anomaly.csv\n",
      "Saved multi-device results for dspot_anomaly to multidevice_results_dspot_anomaly.csv\n",
      "Saved multi-device results for tuned_dspot_anomaly to multidevice_results_tuned_dspot_anomaly.csv\n",
      "\n",
      "All multi-device results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save multi-device results\n",
    "for label_col, results_df in all_multidevice_results.items():\n",
    "    filename = f\"multidevice_results_{label_col}.csv\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved multi-device results for {label_col} to {filename}\")\n",
    "\n",
    "print(\"\\nAll multi-device results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8a444",
   "metadata": {},
   "source": [
    "### Comparison: Per-Device vs Multi-Device Models\n",
    "\n",
    "Compare average performance of per-device models with multi-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f8e834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: PER-DEVICE vs MULTI-DEVICE MODELS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Accuracy Comparison:\n",
      "                                  Model  Per-Device Acc  Multi-Device Acc\n",
      "                               AdaBoost          0.8345          0.867943\n",
      "                          Decision Tree          0.6737          0.591094\n",
      "Linear Classifier (Logistic Regression)          0.6529          0.534188\n",
      "                             Linear SVM          0.6037          0.434830\n",
      "                            Naive Bayes          0.7543          0.736609\n",
      "                      Nearest Neighbors          0.8400          0.837684\n",
      "                                RBF SVM          0.5632          0.550628\n",
      "                          Random Forest          0.8683          0.865775\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.8594               0.709235\n",
      "                          Decision Tree               0.8711               0.742720\n",
      "Linear Classifier (Logistic Regression)               0.7972               0.689164\n",
      "                             Linear SVM               0.8348               0.689060\n",
      "                            Naive Bayes               0.8415               0.702891\n",
      "                      Nearest Neighbors               0.8206               0.880304\n",
      "                                RBF SVM               0.7943               0.747296\n",
      "                          Random Forest               0.8293               0.716202\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.1400               0.239863\n",
      "                          Decision Tree               0.1137               0.208247\n",
      "Linear Classifier (Logistic Regression)               0.1601               0.292784\n",
      "                             Linear SVM               0.1532               0.217869\n",
      "                            Naive Bayes               0.2171               0.276976\n",
      "                      Nearest Neighbors               0.1879               0.178694\n",
      "                                RBF SVM               0.1893               0.187629\n",
      "                          Random Forest               0.1530               0.210309\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Accuracy Comparison:\n",
      "                                  Model  Per-Device Acc  Multi-Device Acc\n",
      "                               AdaBoost          0.9035          0.917688\n",
      "                          Decision Tree          0.7429          0.635142\n",
      "Linear Classifier (Logistic Regression)          0.6724          0.641859\n",
      "                             Linear SVM          0.6879          0.555070\n",
      "                            Naive Bayes          0.6666          0.830899\n",
      "                      Nearest Neighbors          0.9054          0.904361\n",
      "                                RBF SVM          0.6911          0.631411\n",
      "                          Random Forest          0.9168          0.917369\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.8512               0.752874\n",
      "                          Decision Tree               0.8497               0.725584\n",
      "Linear Classifier (Logistic Regression)               0.9101               0.634189\n",
      "                             Linear SVM               0.8347               0.625363\n",
      "                            Naive Bayes               0.9083               0.618860\n",
      "                      Nearest Neighbors               0.7896               0.774010\n",
      "                                RBF SVM               0.8557               0.815469\n",
      "                          Random Forest               0.8217               0.720358\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.0826               0.324219\n",
      "                          Decision Tree               0.0792               0.270833\n",
      "Linear Classifier (Logistic Regression)               0.0858               0.406250\n",
      "                             Linear SVM               0.1338               0.291667\n",
      "                            Naive Bayes               0.1045               0.401042\n",
      "                      Nearest Neighbors               0.0762               0.196615\n",
      "                                RBF SVM               0.1107               0.253906\n",
      "                          Random Forest               0.0867               0.328125\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Accuracy Comparison:\n",
      "                                  Model  Per-Device Acc  Multi-Device Acc\n",
      "                               AdaBoost          0.9490          0.965278\n",
      "                          Decision Tree          0.8558          0.776968\n",
      "Linear Classifier (Logistic Regression)          0.7606          0.755556\n",
      "                             Linear SVM          0.7103          0.743403\n",
      "                            Naive Bayes          0.7861          0.892708\n",
      "                      Nearest Neighbors          0.9502          0.962500\n",
      "                                RBF SVM          0.7261          0.779977\n",
      "                          Random Forest          0.9553          0.964815\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.7297               0.897255\n",
      "                          Decision Tree               0.7710               0.960676\n",
      "Linear Classifier (Logistic Regression)               0.7844               0.813811\n",
      "                             Linear SVM               0.7836               0.805299\n",
      "                            Naive Bayes               0.7341               0.792471\n",
      "                      Nearest Neighbors               0.7163               0.730488\n",
      "                                RBF SVM               0.7625               0.844623\n",
      "                          Random Forest               0.7326               0.803261\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.1313               0.391304\n",
      "                          Decision Tree               0.0959               0.321070\n",
      "Linear Classifier (Logistic Regression)               0.1637               0.468227\n",
      "                             Linear SVM               0.1514               0.247492\n",
      "                            Naive Bayes               0.1991               0.481605\n",
      "                      Nearest Neighbors               0.1458               0.250836\n",
      "                                RBF SVM               0.1467               0.230769\n",
      "                          Random Forest               0.1175               0.301003\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: PER-DEVICE vs MULTI-DEVICE MODELS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    if label_col not in all_results_by_method or label_col not in all_multidevice_results:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Per-device average\n",
    "    per_device_df = all_results_by_method[label_col]\n",
    "    per_device_avg = per_device_df.groupby('model').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'fpr_at_90_recall': 'mean',\n",
    "        'recall_at_10_fpr': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    # Multi-device\n",
    "    multi_device_df = all_multidevice_results[label_col].set_index('model')\n",
    "    \n",
    "    # Compare\n",
    "    comparison = pd.DataFrame({\n",
    "        'Model': per_device_avg.index,\n",
    "        'Per-Device Acc': per_device_avg['accuracy'].values,\n",
    "        'Multi-Device Acc': multi_device_df.loc[per_device_avg.index, 'accuracy'].values,\n",
    "        'Per-Device FPR@90%R': per_device_avg['fpr_at_90_recall'].values,\n",
    "        'Multi-Device FPR@90%R': multi_device_df.loc[per_device_avg.index, 'fpr_at_90_recall'].values,\n",
    "        'Per-Device R@10%FPR': per_device_avg['recall_at_10_fpr'].values,\n",
    "        'Multi-Device R@10%FPR': multi_device_df.loc[per_device_avg.index, 'recall_at_10_fpr'].values,\n",
    "    })\n",
    "    \n",
    "    print(\"Accuracy Comparison:\")\n",
    "    print(comparison[['Model', 'Per-Device Acc', 'Multi-Device Acc']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"FPR at 90% Recall Comparison (lower is better):\")\n",
    "    print(comparison[['Model', 'Per-Device FPR@90%R', 'Multi-Device FPR@90%R']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Recall at 10% FPR Comparison (higher is better):\")\n",
    "    print(comparison[['Model', 'Per-Device R@10%FPR', 'Multi-Device R@10%FPR']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0a54a-50e6-45f0-8359-a01842e080d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
