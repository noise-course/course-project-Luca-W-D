{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b85fb45",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date/time handling\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310a5de",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Using exact model dictionary from step2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d891842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 8 models\n"
     ]
    }
   ],
   "source": [
    "# Model dictionary with exact hyperparameters from step2.ipynb\n",
    "model_dict = {\n",
    "    \"Linear Classifier (Logistic Regression)\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", class_weight='balanced', probability=True),\n",
    "    \"RBF SVM\": SVC(kernel='rbf', class_weight='balanced', probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(model_dict)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6369d1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90ec95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28849 rows\n",
      "Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'hostname', 'date', 'ping_jitter', 'ping_latency', 'ping_low', 'ping_high', 'day', 'predictions', 'basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_data = pd.read_csv(\"clean_labeled.csv\")\n",
    "print(f\"Loaded {len(clean_data)} rows\")\n",
    "print(f\"Columns: {list(clean_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f84895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hosts with basic_ema_anomaly: 38\n",
      "Hosts with dspot_anomaly: 24\n",
      "Hosts with tuned_dspot_anomaly: 32\n",
      "Total hosts with ANY anomaly: 38\n",
      "\n",
      "Filtered to 28394 rows from 38 hosts\n"
     ]
    }
   ],
   "source": [
    "# Filter to hosts that have at least one anomaly in ANY detection method\n",
    "hosts_with_basic_anomaly = clean_data[clean_data['basic_ema_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_dspot_anomaly = clean_data[clean_data['dspot_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_tuned_dspot_anomaly = clean_data[clean_data['tuned_dspot_anomaly'] == True]['hostname'].unique()\n",
    "\n",
    "# Union of all hosts with anomalies\n",
    "hosts_with_any_anomaly = set(hosts_with_basic_anomaly) | set(hosts_with_dspot_anomaly) | set(hosts_with_tuned_dspot_anomaly)\n",
    "\n",
    "print(f\"Hosts with basic_ema_anomaly: {len(hosts_with_basic_anomaly)}\")\n",
    "print(f\"Hosts with dspot_anomaly: {len(hosts_with_dspot_anomaly)}\")\n",
    "print(f\"Hosts with tuned_dspot_anomaly: {len(hosts_with_tuned_dspot_anomaly)}\")\n",
    "print(f\"Total hosts with ANY anomaly: {len(hosts_with_any_anomaly)}\")\n",
    "\n",
    "# Filter dataframe to only these hosts\n",
    "df = clean_data[clean_data['hostname'].isin(hosts_with_any_anomaly)].copy()\n",
    "print(f\"\\nFiltered to {len(df)} rows from {len(hosts_with_any_anomaly)} hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eedf48",
   "metadata": {},
   "source": [
    "### Apply Time Filtering\n",
    "\n",
    "Remove gaps greater than 2 hours 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07670a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After time filtering: 19804 rows\n"
     ]
    }
   ],
   "source": [
    "# Time filtering: remove gaps > 2h 15min\n",
    "hostnames = df[\"hostname\"].unique().tolist()\n",
    "time_filtered_df = []\n",
    "\n",
    "for host in hostnames:\n",
    "    hostdf = df[df['hostname'] == host].copy()\n",
    "    hostdf[\"date\"] = pd.to_datetime(hostdf[\"date\"])\n",
    "    hostdf = hostdf.sort_values(by='date', ascending=True)\n",
    "    hostdf['time_diff'] = hostdf['date'] - (hostdf['date'].shift(1))\n",
    "    mask = ((hostdf['time_diff'] >= timedelta(hours=2, minutes=15)) | (hostdf['time_diff'].isna()))\n",
    "    filtered_host_df = hostdf[mask]\n",
    "    time_filtered_df.append(filtered_host_df)\n",
    "\n",
    "time_filtered_df = pd.concat(time_filtered_df, ignore_index=True)\n",
    "print(f\"After time filtering: {len(time_filtered_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e26cd1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a8f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 11525 rows\n",
      "Test set: 8279 rows\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "tdf = time_filtered_df\n",
    "\n",
    "start_a = pd.Timestamp(\"2025-04-16\")\n",
    "end_a   = pd.Timestamp(\"2025-06-20\")\n",
    "\n",
    "start_b = pd.Timestamp(\"2025-07-01\")\n",
    "end_b   = pd.Timestamp(\"2025-08-01\")\n",
    "\n",
    "mask_a = (tdf[\"date\"] >= start_a) & (tdf[\"date\"] <= end_a)\n",
    "mask_b = (tdf[\"date\"] >= start_b) & (tdf[\"date\"] <= end_b)\n",
    "\n",
    "train = tdf[mask_a].copy()\n",
    "test = tdf[mask_b].copy()\n",
    "\n",
    "print(f\"Train set: {len(train)} rows\")\n",
    "print(f\"Test set: {len(test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907ca4d",
   "metadata": {},
   "source": [
    "### Normalize Latency Values per Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa7fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete\n"
     ]
    }
   ],
   "source": [
    "# Train normalization - normalizing using Z-score for each hostname\n",
    "train[\"normalized_latency\"] = train.groupby(\"hostname\")[\"ping_latency\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "train[\"normalized_latency\"] = train[\"normalized_latency\"].fillna(0)\n",
    "train[\"normalized_latency\"] = train[\"normalized_latency\"] - train[\"normalized_latency\"].min()\n",
    "\n",
    "# Test normalization\n",
    "test[\"normalized_latency\"] = test.groupby(\"hostname\")[\"ping_latency\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "test[\"normalized_latency\"] = test[\"normalized_latency\"].fillna(0)\n",
    "test[\"normalized_latency\"] = test[\"normalized_latency\"] - test[\"normalized_latency\"].min()\n",
    "\n",
    "print(\"Normalization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d429b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Functions\n",
    "\n",
    "Modified to accept a `label_col` parameter to specify which anomaly column to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e34dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_lookback_features(lookback_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create lookback features for a window of data.\n",
    "    \n",
    "    Args:\n",
    "        lookback_df: DataFrame with historical data\n",
    "        label_col: Column name to use as labels (e.g., 'basic_ema_anomaly', 'dspot_anomaly')\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    lookback_df = lookback_df.reset_index(drop=True)\n",
    "\n",
    "    has_anomalies = lookback_df[label_col].any()\n",
    "    has_normal = (~lookback_df[label_col]).any()\n",
    "    \n",
    "    lookback_features = {\n",
    "        'anomaly_count': lookback_df[label_col].sum(),\n",
    "        'anomaly_rate': lookback_df[label_col].mean(),\n",
    "        'recent_anomaly_count': lookback_df[label_col].tail(3).sum(),\n",
    "        'datapoints_since_anomaly': ((len(lookback_df) - 1 - lookback_df[lookback_df[label_col] == True].index[-1]) if has_anomalies else -1),\n",
    "        'has_anomaly_history': float(has_anomalies),\n",
    "        'latency_during_anomalies': (lookback_df[lookback_df[label_col] == True][latency_to_use].mean() if has_anomalies else -1),\n",
    "        'latency_during_normal': (lookback_df[lookback_df[label_col] == False][latency_to_use].mean() if has_normal else -1),\n",
    "        'recent_latency_mean': lookback_df[latency_to_use].tail(3).mean(),\n",
    "        'baseline_latency_mean': lookback_df[latency_to_use].head(5).mean(),\n",
    "        'recent_vs_baseline': (lookback_df[latency_to_use].tail(3).mean() / lookback_df[latency_to_use].head(5).mean() if lookback_df[latency_to_use].head(5).mean() > 0 else 1.0),\n",
    "        'recent_latency_max': lookback_df[latency_to_use].tail(3).max(),\n",
    "        'latency_trend': (lookback_df[latency_to_use].iloc[-1] - lookback_df[latency_to_use].iloc[0]) / len(lookback_df),\n",
    "        'anomaly_clustering': lookback_df[label_col].rolling(3).sum().max() if len(lookback_df) >= 3 else 0,\n",
    "        'missing_points': lookback_df[latency_to_use].isna().sum(),\n",
    "        'completeness': 1 - lookback_df[latency_to_use].isna().mean()\n",
    "    }\n",
    "    return lookback_features\n",
    "\n",
    "\n",
    "def get_feature_df(og_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create a feature dataframe with lookback windows.\n",
    "    \n",
    "    Args:\n",
    "        og_df: Original dataframe sorted by date\n",
    "        label_col: Column name to use as labels\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    initial = create_lookback_features(og_df.iloc[0:10], label_col=label_col, latency_to_use=latency_to_use)\n",
    "    featured_df = pd.DataFrame(columns=list(initial.keys()) + ['label', 'date', 'hostname'])\n",
    "    TOL = pd.Timedelta(minutes=2)\n",
    "\n",
    "    for i, row in og_df.iloc[9:].iterrows():\n",
    "        end_time = og_df.loc[i, 'date']\n",
    "        start_time = end_time - pd.Timedelta(hours=30)\n",
    "        lookback_df = og_df[(og_df['date'] >= start_time + TOL) & (og_df['date'] < end_time - TOL)].copy()\n",
    "        if len(lookback_df) == 0:\n",
    "            continue\n",
    "        lookback_features = create_lookback_features(lookback_df, label_col=label_col, latency_to_use=latency_to_use)\n",
    "        label = og_df.loc[i, label_col]\n",
    "        hostname = og_df.loc[i, 'hostname']\n",
    "        row = {**lookback_features, 'label': label, 'date': end_time, 'hostname': hostname}\n",
    "        featured_df.loc[len(featured_df)] = row\n",
    "\n",
    "    return featured_df\n",
    "\n",
    "\n",
    "def transform_single_df_to_features(df, cur_hostname, label_col='predictions'):\n",
    "    \"\"\"\n",
    "    Transform a single device's data to features.\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataframe\n",
    "        cur_hostname: Hostname to filter by\n",
    "        label_col: Column name to use as labels\n",
    "    \"\"\"\n",
    "    host_isolated = df[df['hostname'] == cur_hostname]\n",
    "    host_isolated = host_isolated.sort_values(by='date', ascending=True)\n",
    "    return get_feature_df(host_isolated, label_col=label_col, latency_to_use='ping_latency')\n",
    "\n",
    "\n",
    "print(\"Feature engineering functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daceac9",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Functions\n",
    "\n",
    "Includes new threshold-based metrics:\n",
    "- **FPR at 90% Recall**: What false positive rate is needed to catch 90% of anomalies\n",
    "- **Recall at 10% FPR**: What percentage of anomalies are caught with 10% false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380eb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_threshold_metrics(y_test, y_proba):\n",
    "    \"\"\"\n",
    "    Calculate threshold-based metrics:\n",
    "    - FPR at 90% Recall: What FPR is needed to catch 90% of anomalies\n",
    "    - Recall at 10% FPR: What recall is achieved at 10% FPR\n",
    "    \n",
    "    Args:\n",
    "        y_test: True labels\n",
    "        y_proba: Predicted probabilities for positive class\n",
    "    \n",
    "    Returns:\n",
    "        fpr_at_90_recall: FPR when recall is 90%\n",
    "        recall_at_10_fpr: Recall when FPR is 10%\n",
    "    \"\"\"\n",
    "    # Sort by probability descending\n",
    "    sorted_indices = np.argsort(-y_proba)\n",
    "    y_test_sorted = y_test.iloc[sorted_indices].values if hasattr(y_test, 'iloc') else y_test[sorted_indices]\n",
    "    \n",
    "    total_positives = y_test_sorted.sum()\n",
    "    total_negatives = len(y_test_sorted) - total_positives\n",
    "    \n",
    "    # Edge case: no anomalies\n",
    "    if total_positives == 0:\n",
    "        return -1, -1\n",
    "    \n",
    "    # Calculate cumulative metrics\n",
    "    cumulative_tp = np.cumsum(y_test_sorted)\n",
    "    cumulative_fp = np.cumsum(1 - y_test_sorted)\n",
    "    \n",
    "    # Calculate recall and FPR at each threshold\n",
    "    recalls = cumulative_tp / total_positives\n",
    "    fprs = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)\n",
    "    \n",
    "    # FPR at 90% Recall\n",
    "    target_recall = 0.90\n",
    "    idx_90_recall = np.where(recalls >= target_recall)[0]\n",
    "    if len(idx_90_recall) > 0:\n",
    "        fpr_at_90_recall = fprs[idx_90_recall[0]]\n",
    "    else:\n",
    "        fpr_at_90_recall = 1.0  # Would need 100% FPR to reach 90% recall\n",
    "    \n",
    "    # Recall at 10% FPR\n",
    "    target_fpr = 0.10\n",
    "    idx_10_fpr = np.where(fprs <= target_fpr)[0]\n",
    "    if len(idx_10_fpr) > 0:\n",
    "        recall_at_10_fpr = recalls[idx_10_fpr[-1]]  # Last index where FPR <= 10%\n",
    "    else:\n",
    "        recall_at_10_fpr = 0.0  # Can't achieve any recall at 10% FPR\n",
    "    \n",
    "    return fpr_at_90_recall, recall_at_10_fpr\n",
    "\n",
    "\n",
    "def evaluate_model_per_device(X_train, y_train, X_test, y_test, hostname):\n",
    "    \"\"\"\n",
    "    Train all models and evaluate on test set for a single device.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training features and labels\n",
    "        X_test, y_test: Test features and labels\n",
    "        hostname: Device hostname\n",
    "    \n",
    "    Returns:\n",
    "        List of result dictionaries for each model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, clf in model_dict.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "            has_proba = True\n",
    "        except:\n",
    "            y_proba = None\n",
    "            has_proba = False\n",
    "        \n",
    "        # Standard metrics\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1_anomaly = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        roc_auc = -1\n",
    "        fpr_at_90_recall = -1\n",
    "        recall_at_10_fpr = -1\n",
    "        \n",
    "        if has_proba:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            fpr_at_90_recall, recall_at_10_fpr = calculate_threshold_metrics(y_test, y_proba)\n",
    "\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'hostname': hostname,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_anomaly,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr_at_90_recall': fpr_at_90_recall,\n",
    "            'recall_at_10_fpr': recall_at_10_fpr,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            'caught_anomalies': tp,\n",
    "            'missed_anomalies': fn,\n",
    "            'false_alarms': fp,\n",
    "            'total_test_samples': len(y_test),\n",
    "            'total_anomalies': y_test.sum()\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Model evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f7456",
   "metadata": {},
   "source": [
    "## 6. Main Evaluation Loop\n",
    "\n",
    "Iterate over all three anomaly detection methods and evaluate per-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d44c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 36\n",
      "Hosts with anomalies in test: 35\n",
      "Hosts with anomalies in BOTH train and test: 34\n",
      "\n",
      "[1/34] Evaluating models for hostname: 29129b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/34] Evaluating models for hostname: 972f622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/34] Evaluating models for hostname: 5bf17fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/34] Evaluating models for hostname: f8f4b44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/34] Evaluating models for hostname: dede9dc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/34] Evaluating models for hostname: 5c5004f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/34] Evaluating models for hostname: 64b750b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/34] Evaluating models for hostname: d493afd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/34] Evaluating models for hostname: 9dc32f2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/34] Evaluating models for hostname: 33fe84e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/34] Evaluating models for hostname: 24a22bf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/34] Evaluating models for hostname: a2e0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/34] Evaluating models for hostname: b2c53ee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/34] Evaluating models for hostname: ed86ea2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/34] Evaluating models for hostname: 2620a05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/34] Evaluating models for hostname: 43e847f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/34] Evaluating models for hostname: 0f42441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/34] Evaluating models for hostname: b340432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/34] Evaluating models for hostname: 953d46d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/34] Evaluating models for hostname: 592a43c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/34] Evaluating models for hostname: 25b3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/34] Evaluating models for hostname: 8445893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/34] Evaluating models for hostname: 9ab8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/34] Evaluating models for hostname: da6d469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/34] Evaluating models for hostname: 7f6d63d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/34] Evaluating models for hostname: c073f39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/34] Evaluating models for hostname: 6ca8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/34] Evaluating models for hostname: 1a21874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/34] Evaluating models for hostname: b407ebe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/34] Evaluating models for hostname: b5c8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/34] Evaluating models for hostname: 63598f8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/34] Evaluating models for hostname: 9840de6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/34] Evaluating models for hostname: 575f518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/34] Evaluating models for hostname: 38b6bf0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed evaluation for basic_ema_anomaly: 272 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 23\n",
      "Hosts with anomalies in test: 24\n",
      "Hosts with anomalies in BOTH train and test: 23\n",
      "\n",
      "[1/23] Evaluating models for hostname: 29129b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/23] Evaluating models for hostname: 972f622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/23] Evaluating models for hostname: f8f4b44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/23] Evaluating models for hostname: dede9dc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/23] Evaluating models for hostname: 9dc32f2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/23] Evaluating models for hostname: 33fe84e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/23] Evaluating models for hostname: 24a22bf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/23] Evaluating models for hostname: a2e0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/23] Evaluating models for hostname: b2c53ee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/23] Evaluating models for hostname: 2620a05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23] Evaluating models for hostname: 43e847f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/23] Evaluating models for hostname: b340432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/23] Evaluating models for hostname: 953d46d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/23] Evaluating models for hostname: 592a43c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/23] Evaluating models for hostname: 25b3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/23] Evaluating models for hostname: 9ab8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/23] Evaluating models for hostname: da6d469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/23] Evaluating models for hostname: 7f6d63d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/23] Evaluating models for hostname: c073f39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/23] Evaluating models for hostname: 6ca8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/23] Evaluating models for hostname: b407ebe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/23] Evaluating models for hostname: 575f518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/23] Evaluating models for hostname: 38b6bf0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed evaluation for dspot_anomaly: 184 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 29\n",
      "Hosts with anomalies in test: 24\n",
      "Hosts with anomalies in BOTH train and test: 22\n",
      "\n",
      "[1/22] Evaluating models for hostname: 29129b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/22] Evaluating models for hostname: 972f622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/22] Evaluating models for hostname: 5bf17fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/22] Evaluating models for hostname: f8f4b44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/22] Evaluating models for hostname: dede9dc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/22] Evaluating models for hostname: 5c5004f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/22] Evaluating models for hostname: 33fe84e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/22] Evaluating models for hostname: a2e0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/22] Evaluating models for hostname: ed86ea2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/22] Evaluating models for hostname: 2620a05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/22] Evaluating models for hostname: 0f42441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/22] Evaluating models for hostname: b340432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/22] Evaluating models for hostname: 953d46d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/22] Evaluating models for hostname: 25b3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/22] Evaluating models for hostname: da6d469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/22] Evaluating models for hostname: 7f6d63d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/22] Evaluating models for hostname: 6ca8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/22] Evaluating models for hostname: b407ebe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/22] Evaluating models for hostname: b5c8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/22] Evaluating models for hostname: 9840de6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/22] Evaluating models for hostname: 575f518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/22] Evaluating models for hostname: 38b6bf0\n",
      "\n",
      "Completed evaluation for tuned_dspot_anomaly: 176 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/miniconda3/envs/jupyter310/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the three anomaly columns to evaluate\n",
    "anomaly_columns = ['basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n",
    "\n",
    "# Store results for each method\n",
    "all_results_by_method = {}\n",
    "\n",
    "# Columns to remove when creating features\n",
    "remove_cols = ['label', 'date', 'hostname']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANOMALY DETECTION METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Filter to hosts that have anomalies in both train and test for this method\n",
    "    train_hostnames_with_anomalies = train[train[label_col] == True]['hostname'].unique()\n",
    "    test_hostnames_with_anomalies = test[test[label_col] == True]['hostname'].unique()\n",
    "    hostnames_in_both = set(train_hostnames_with_anomalies).intersection(set(test_hostnames_with_anomalies))\n",
    "    \n",
    "    print(f\"Hosts with anomalies in train: {len(train_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in test: {len(test_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in BOTH train and test: {len(hostnames_in_both)}\\n\")\n",
    "    \n",
    "    if len(hostnames_in_both) == 0:\n",
    "        print(f\"WARNING: No hosts have anomalies in both train and test for {label_col}. Skipping.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Filter train and test to only these hosts\n",
    "    train_filtered = train[train['hostname'].isin(hostnames_in_both)]\n",
    "    test_filtered = test[test['hostname'].isin(hostnames_in_both)]\n",
    "    \n",
    "    # Evaluate models for each host\n",
    "    method_results = []\n",
    "    \n",
    "    for i, cur_hostname in enumerate(hostnames_in_both, 1):\n",
    "        print(f\"[{i}/{len(hostnames_in_both)}] Evaluating models for hostname: {cur_hostname}\")\n",
    "        \n",
    "        # Create features using this label column\n",
    "        train_single_w_lookback = transform_single_df_to_features(train_filtered, cur_hostname, label_col=label_col)\n",
    "        test_single_w_lookback = transform_single_df_to_features(test_filtered, cur_hostname, label_col=label_col)\n",
    "        \n",
    "        # Prepare X and y\n",
    "        X_train = train_single_w_lookback.drop(columns=remove_cols)\n",
    "        X_test = test_single_w_lookback.drop(columns=remove_cols)\n",
    "        y_train = train_single_w_lookback[\"label\"].astype(int)\n",
    "        y_test = test_single_w_lookback[\"label\"].astype(int)\n",
    "        \n",
    "        # Evaluate models\n",
    "        hostname_results = evaluate_model_per_device(X_train, y_train, X_test, y_test, cur_hostname)\n",
    "        method_results.extend(hostname_results)\n",
    "    \n",
    "    # Store results for this method\n",
    "    all_results_by_method[label_col] = pd.DataFrame(method_results)\n",
    "    print(f\"\\nCompleted evaluation for {label_col}: {len(method_results)} total evaluations\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f199ec",
   "metadata": {},
   "source": [
    "## 7. Results Summary\n",
    "\n",
    "Display aggregate statistics for each anomaly detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3b4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.8394    0.0575     0.1023   \n",
      "Decision Tree                              0.6380    0.1480     0.1345   \n",
      "Linear Classifier (Logistic Regression)    0.6268    0.1921     0.1406   \n",
      "Linear SVM                                 0.6018    0.1968     0.1473   \n",
      "Naive Bayes                                0.7532    0.1723     0.1514   \n",
      "Nearest Neighbors                          0.8433    0.0651     0.1159   \n",
      "RBF SVM                                    0.5768    0.2134     0.1409   \n",
      "Random Forest                              0.8760    0.0203     0.0895   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0508   0.4779  \n",
      "Decision Tree                            0.3134   0.4757  \n",
      "Linear Classifier (Logistic Regression)  0.3935   0.4947  \n",
      "Linear SVM                               0.4229   0.5250  \n",
      "Naive Bayes                              0.2751   0.5139  \n",
      "Nearest Neighbors                        0.0586   0.5332  \n",
      "RBF SVM                                  0.5399   0.5485  \n",
      "Random Forest                            0.0126   0.5014  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.8999            0.1245\n",
      "Decision Tree                                      0.8484            0.0882\n",
      "Linear Classifier (Logistic Regression)            0.8520            0.1543\n",
      "Linear SVM                                         0.8355            0.1358\n",
      "Naive Bayes                                        0.8509            0.1623\n",
      "Nearest Neighbors                                  0.7856            0.1676\n",
      "RBF SVM                                            0.8236            0.1906\n",
      "Random Forest                                      0.8493            0.1582\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               70               799   \n",
      "Decision Tree                                         303               566   \n",
      "Linear Classifier (Logistic Regression)               412               457   \n",
      "Linear SVM                                            475               394   \n",
      "Naive Bayes                                           277               592   \n",
      "Nearest Neighbors                                      69               800   \n",
      "RBF SVM                                               542               327   \n",
      "Random Forest                                          11               858   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                          407              869  \n",
      "Decision Tree                                    2146              869  \n",
      "Linear Classifier (Logistic Regression)          2334              869  \n",
      "Linear SVM                                       2589              869  \n",
      "Naive Bayes                                      1282              869  \n",
      "Nearest Neighbors                                 378              869  \n",
      "RBF SVM                                          2837              869  \n",
      "Random Forest                                      70              869  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: RBF SVM (0.2134)\n",
      "Best Recall: RBF SVM (0.5399)\n",
      "Best Precision: Naive Bayes (0.1514)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.7856)\n",
      "Best Recall at 10% FPR: RBF SVM (0.1906)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.8960    0.0378     0.0431   \n",
      "Decision Tree                              0.7798    0.0947     0.0656   \n",
      "Linear Classifier (Logistic Regression)    0.6817    0.0955     0.0752   \n",
      "Linear SVM                                 0.6827    0.0896     0.0748   \n",
      "Naive Bayes                                0.6547    0.0825     0.0644   \n",
      "Nearest Neighbors                          0.8993    0.0315     0.0452   \n",
      "RBF SVM                                    0.5861    0.1024     0.0732   \n",
      "Random Forest                              0.9196    0.0197     0.1027   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0359   0.4931  \n",
      "Decision Tree                            0.2067   0.5115  \n",
      "Linear Classifier (Logistic Regression)  0.2300   0.4431  \n",
      "Linear SVM                               0.2623   0.4849  \n",
      "Naive Bayes                              0.2717   0.4609  \n",
      "Nearest Neighbors                        0.0294   0.4848  \n",
      "RBF SVM                                  0.3756   0.5476  \n",
      "Random Forest                            0.0115   0.4788  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.8314            0.0594\n",
      "Decision Tree                                      0.7758            0.1180\n",
      "Linear Classifier (Logistic Regression)            0.8775            0.0609\n",
      "Linear SVM                                         0.8151            0.1233\n",
      "Naive Bayes                                        0.8612            0.0513\n",
      "Nearest Neighbors                                  0.8110            0.1025\n",
      "RBF SVM                                            0.7913            0.1396\n",
      "Random Forest                                      0.8460            0.0911\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               37               379   \n",
      "Decision Tree                                         130               286   \n",
      "Linear Classifier (Logistic Regression)               133               283   \n",
      "Linear SVM                                            122               294   \n",
      "Naive Bayes                                           104               312   \n",
      "Nearest Neighbors                                      30               386   \n",
      "RBF SVM                                               193               223   \n",
      "Random Forest                                          10               406   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                          185              416  \n",
      "Decision Tree                                     886              416  \n",
      "Linear Classifier (Logistic Regression)          1430              416  \n",
      "Linear SVM                                       1414              416  \n",
      "Naive Bayes                                      1544              416  \n",
      "Nearest Neighbors                                 155              416  \n",
      "RBF SVM                                          2005              416  \n",
      "Random Forest                                      30              416  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: RBF SVM (0.1024)\n",
      "Best Recall: RBF SVM (0.3756)\n",
      "Best Precision: Random Forest (0.1027)\n",
      "Best FPR at 90% Recall: Decision Tree (0.7758)\n",
      "Best Recall at 10% FPR: RBF SVM (0.1396)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.9464    0.0496     0.0674   \n",
      "Decision Tree                              0.8721    0.0637     0.0487   \n",
      "Linear Classifier (Logistic Regression)    0.7700    0.1098     0.0795   \n",
      "Linear SVM                                 0.7226    0.0917     0.0746   \n",
      "Naive Bayes                                0.8109    0.0735     0.0644   \n",
      "Nearest Neighbors                          0.9562    0.0567     0.0716   \n",
      "RBF SVM                                    0.6490    0.0984     0.0660   \n",
      "Random Forest                              0.9595    0.0469     0.0538   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0499   0.4893  \n",
      "Decision Tree                            0.1250   0.4830  \n",
      "Linear Classifier (Logistic Regression)  0.3390   0.5210  \n",
      "Linear SVM                               0.3263   0.4788  \n",
      "Naive Bayes                              0.1655   0.4982  \n",
      "Nearest Neighbors                        0.0616   0.5235  \n",
      "RBF SVM                                  0.3709   0.5475  \n",
      "Random Forest                            0.0461   0.4889  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.7746            0.1458\n",
      "Decision Tree                                      0.7410            0.1713\n",
      "Linear Classifier (Logistic Regression)            0.7659            0.2350\n",
      "Linear SVM                                         0.8052            0.1732\n",
      "Naive Bayes                                        0.7257            0.2273\n",
      "Nearest Neighbors                                  0.6656            0.1974\n",
      "RBF SVM                                            0.7404            0.1393\n",
      "Random Forest                                      0.8085            0.0669\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               33               136   \n",
      "Decision Tree                                          48               121   \n",
      "Linear Classifier (Logistic Regression)                75                94   \n",
      "Linear SVM                                             72                97   \n",
      "Naive Bayes                                            53               116   \n",
      "Nearest Neighbors                                      41               128   \n",
      "RBF SVM                                                85                84   \n",
      "Random Forest                                          32               137   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                           97              169  \n",
      "Decision Tree                                     494              169  \n",
      "Linear Classifier (Logistic Regression)          1047              169  \n",
      "Linear SVM                                       1234              169  \n",
      "Naive Bayes                                       820              169  \n",
      "Nearest Neighbors                                  59              169  \n",
      "RBF SVM                                          1619              169  \n",
      "Random Forest                                      37              169  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: Linear Classifier (Logistic Regression) (0.1098)\n",
      "Best Recall: RBF SVM (0.3709)\n",
      "Best Precision: Linear Classifier (Logistic Regression) (0.0795)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.6656)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.2350)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Group by model and calculate mean metrics\n",
    "    grouped = results_df.groupby('model').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'f1_score': 'mean',\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'roc_auc': 'mean',\n",
    "        'fpr_at_90_recall': 'mean',\n",
    "        'recall_at_10_fpr': 'mean',\n",
    "        'caught_anomalies': 'sum',\n",
    "        'missed_anomalies': 'sum',\n",
    "        'false_alarms': 'sum',\n",
    "        'total_anomalies': 'sum'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"Standard Metrics:\")\n",
    "    print(grouped[['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Threshold-Based Metrics:\")\n",
    "    print(\"-\"*80)\n",
    "    threshold_metrics = grouped[['fpr_at_90_recall', 'recall_at_10_fpr']].copy()\n",
    "    print(threshold_metrics)\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\")\n",
    "    print(\"    (Lower is better - means fewer false alarms to catch most issues)\")\n",
    "    print(\"  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\")\n",
    "    print(\"    (Higher is better - means catching more issues with acceptable false alarm rate)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Anomaly Detection Stats:\")\n",
    "    print(\"-\"*80)\n",
    "    print(grouped[['caught_anomalies', 'missed_anomalies', 'false_alarms', 'total_anomalies']])\n",
    "    \n",
    "    # Best models\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Best Models:\")\n",
    "    print(\"-\"*80)\n",
    "    best_f1 = grouped['f1_score'].idxmax()\n",
    "    best_recall = grouped['recall'].idxmax()\n",
    "    best_precision = grouped['precision'].idxmax()\n",
    "    best_fpr_90 = grouped['fpr_at_90_recall'].idxmin()  # Lower is better\n",
    "    best_recall_10 = grouped['recall_at_10_fpr'].idxmax()  # Higher is better\n",
    "    \n",
    "    print(f\"Best F1 Score: {best_f1} ({grouped.loc[best_f1, 'f1_score']:.4f})\")\n",
    "    print(f\"Best Recall: {best_recall} ({grouped.loc[best_recall, 'recall']:.4f})\")\n",
    "    print(f\"Best Precision: {best_precision} ({grouped.loc[best_precision, 'precision']:.4f})\")\n",
    "    print(f\"Best FPR at 90% Recall: {best_fpr_90} ({grouped.loc[best_fpr_90, 'fpr_at_90_recall']:.4f})\")\n",
    "    print(f\"Best Recall at 10% FPR: {best_recall_10} ({grouped.loc[best_recall_10, 'recall_at_10_fpr']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda46b0d",
   "metadata": {},
   "source": [
    "## 8. Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d255837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for basic_ema_anomaly to per_device_results_basic_ema_anomaly.csv\n",
      "Saved results for dspot_anomaly to per_device_results_dspot_anomaly.csv\n",
      "Saved results for tuned_dspot_anomaly to per_device_results_tuned_dspot_anomaly.csv\n",
      "\n",
      "All results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results for each method\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    filename = f\"per_device_results_{label_col}.csv\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved results for {label_col} to {filename}\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5fd38",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook evaluated per-device ML models on three different anomaly detection methods:\n",
    "1. **basic_ema_anomaly**: Basic EMA-based detection\n",
    "2. **dspot_anomaly**: DSPOT detection\n",
    "3. **tuned_dspot_anomaly**: Tuned DSPOT detection\n",
    "\n",
    "For each method, we trained 8 different ML models per device and calculated:\n",
    "- Standard classification metrics (accuracy, F1, precision, recall, ROC-AUC)\n",
    "- **FPR at 90% Recall**: Answers \"how many false alarms to catch 90% of issues?\"\n",
    "- **Recall at 10% FPR**: Answers \"how many issues caught with 10% false alarm rate?\"\n",
    "\n",
    "The threshold-based metrics are particularly useful for understanding:\n",
    "- **Customers who want to catch as many anomalies as possible**: Look at FPR at 90% Recall\n",
    "- **Customers who want to minimize false alarms**: Look at Recall at 10% FPR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
