{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b85fb45",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f1e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date/time handling\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310a5de",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Using exact model dictionary from step2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d891842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 8 models\n"
     ]
    }
   ],
   "source": [
    "# Model dictionary with exact hyperparameters from step2.ipynb\n",
    "model_dict = {\n",
    "    \"Linear Classifier (Logistic Regression)\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", class_weight='balanced', probability=True),\n",
    "    \"RBF SVM\": SVC(kernel='rbf', class_weight='balanced', probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(model_dict)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6369d1",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90ec95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28849 rows\n",
      "Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'hostname', 'date', 'ping_jitter', 'ping_latency', 'ping_low', 'ping_high', 'day', 'predictions', 'basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_data = pd.read_csv(\"clean_labeled.csv\")\n",
    "print(f\"Loaded {len(clean_data)} rows\")\n",
    "print(f\"Columns: {list(clean_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0f84895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hosts with basic_ema_anomaly: 38\n",
      "Hosts with dspot_anomaly: 24\n",
      "Hosts with tuned_dspot_anomaly: 32\n",
      "Total hosts with ANY anomaly: 38\n",
      "\n",
      "Filtered to 28394 rows from 38 hosts\n"
     ]
    }
   ],
   "source": [
    "# Filter to hosts that have at least one anomaly in ANY detection method\n",
    "hosts_with_basic_anomaly = clean_data[clean_data['basic_ema_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_dspot_anomaly = clean_data[clean_data['dspot_anomaly'] == True]['hostname'].unique()\n",
    "hosts_with_tuned_dspot_anomaly = clean_data[clean_data['tuned_dspot_anomaly'] == True]['hostname'].unique()\n",
    "\n",
    "# Union of all hosts with anomalies\n",
    "hosts_with_any_anomaly = set(hosts_with_basic_anomaly) | set(hosts_with_dspot_anomaly) | set(hosts_with_tuned_dspot_anomaly)\n",
    "\n",
    "print(f\"Hosts with basic_ema_anomaly: {len(hosts_with_basic_anomaly)}\")\n",
    "print(f\"Hosts with dspot_anomaly: {len(hosts_with_dspot_anomaly)}\")\n",
    "print(f\"Hosts with tuned_dspot_anomaly: {len(hosts_with_tuned_dspot_anomaly)}\")\n",
    "print(f\"Total hosts with ANY anomaly: {len(hosts_with_any_anomaly)}\")\n",
    "\n",
    "# Filter dataframe to only these hosts\n",
    "df = clean_data[clean_data['hostname'].isin(hosts_with_any_anomaly)].copy()\n",
    "print(f\"\\nFiltered to {len(df)} rows from {len(hosts_with_any_anomaly)} hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e26cd1",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a8f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 11525 rows\n",
      "Test set: 8279 rows\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "tdf = time_filtered_df\n",
    "\n",
    "start_a = pd.Timestamp(\"2025-04-16\")\n",
    "end_a   = pd.Timestamp(\"2025-06-20\")\n",
    "\n",
    "start_b = pd.Timestamp(\"2025-07-01\")\n",
    "end_b   = pd.Timestamp(\"2025-08-01\")\n",
    "\n",
    "mask_a = (tdf[\"date\"] >= start_a) & (tdf[\"date\"] <= end_a)\n",
    "mask_b = (tdf[\"date\"] >= start_b) & (tdf[\"date\"] <= end_b)\n",
    "\n",
    "train = tdf[mask_a].copy()\n",
    "test = tdf[mask_b].copy()\n",
    "\n",
    "print(f\"Train set: {len(train)} rows\")\n",
    "print(f\"Test set: {len(test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907ca4d",
   "metadata": {},
   "source": [
    "### Normalize Latency Values per Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa7fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete\n"
     ]
    }
   ],
   "source": [
    "# Train normalization - normalizing using Z-score for each hostname\n",
    "train[\"normalized_latency\"] = train.groupby(\"hostname\")[\"ping_latency\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "train[\"normalized_latency\"] = train[\"normalized_latency\"].fillna(0)\n",
    "train[\"normalized_latency\"] = train[\"normalized_latency\"] - train[\"normalized_latency\"].min()\n",
    "\n",
    "# Test normalization\n",
    "test[\"normalized_latency\"] = test.groupby(\"hostname\")[\"ping_latency\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "test[\"normalized_latency\"] = test[\"normalized_latency\"].fillna(0)\n",
    "test[\"normalized_latency\"] = test[\"normalized_latency\"] - test[\"normalized_latency\"].min()\n",
    "\n",
    "print(\"Normalization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d429b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Functions\n",
    "\n",
    "Modified to accept a `label_col` parameter to specify which anomaly column to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75e34dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_lookback_features(lookback_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create lookback features for a window of data.\n",
    "    \n",
    "    Args:\n",
    "        lookback_df: DataFrame with historical data\n",
    "        label_col: Column name to use as labels (e.g., 'basic_ema_anomaly', 'dspot_anomaly')\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    lookback_df = lookback_df.reset_index(drop=True)\n",
    "\n",
    "    has_anomalies = lookback_df[label_col].any()\n",
    "    has_normal = (~lookback_df[label_col]).any()\n",
    "    \n",
    "    lookback_features = {\n",
    "        'anomaly_count': lookback_df[label_col].sum(),\n",
    "        'anomaly_rate': lookback_df[label_col].mean(),\n",
    "        'recent_anomaly_count': lookback_df[label_col].tail(3).sum(),\n",
    "        'datapoints_since_anomaly': ((len(lookback_df) - 1 - lookback_df[lookback_df[label_col] == True].index[-1]) if has_anomalies else -1),\n",
    "        'has_anomaly_history': float(has_anomalies),\n",
    "        'latency_during_anomalies': (lookback_df[lookback_df[label_col] == True][latency_to_use].mean() if has_anomalies else -1),\n",
    "        'latency_during_normal': (lookback_df[lookback_df[label_col] == False][latency_to_use].mean() if has_normal else -1),\n",
    "        'recent_latency_mean': lookback_df[latency_to_use].tail(3).mean(),\n",
    "        'baseline_latency_mean': lookback_df[latency_to_use].head(5).mean(),\n",
    "        'recent_vs_baseline': (lookback_df[latency_to_use].tail(3).mean() / lookback_df[latency_to_use].head(5).mean() if lookback_df[latency_to_use].head(5).mean() > 0 else 1.0),\n",
    "        'recent_latency_max': lookback_df[latency_to_use].tail(3).max(),\n",
    "        'latency_trend': (lookback_df[latency_to_use].iloc[-1] - lookback_df[latency_to_use].iloc[0]) / len(lookback_df),\n",
    "        'anomaly_clustering': lookback_df[label_col].rolling(3).sum().max() if len(lookback_df) >= 3 else 0,\n",
    "        'missing_points': lookback_df[latency_to_use].isna().sum(),\n",
    "        'completeness': 1 - lookback_df[latency_to_use].isna().mean()\n",
    "    }\n",
    "    return lookback_features\n",
    "\n",
    "\n",
    "def get_feature_df(og_df, label_col='predictions', latency_to_use='ping_latency'):\n",
    "    \"\"\"\n",
    "    Create a feature dataframe with lookback windows.\n",
    "    \n",
    "    Args:\n",
    "        og_df: Original dataframe sorted by date\n",
    "        label_col: Column name to use as labels\n",
    "        latency_to_use: Column name for latency values\n",
    "    \"\"\"\n",
    "    initial = create_lookback_features(og_df.iloc[0:10], label_col=label_col, latency_to_use=latency_to_use)\n",
    "    featured_df = pd.DataFrame(columns=list(initial.keys()) + ['label', 'date', 'hostname'])\n",
    "    TOL = pd.Timedelta(minutes=2)\n",
    "\n",
    "    for i, row in og_df.iloc[9:].iterrows():\n",
    "        end_time = og_df.loc[i, 'date']\n",
    "        start_time = end_time - pd.Timedelta(hours=30)\n",
    "        lookback_df = og_df[(og_df['date'] >= start_time + TOL) & (og_df['date'] < end_time - TOL)].copy()\n",
    "        if len(lookback_df) == 0:\n",
    "            continue\n",
    "        lookback_features = create_lookback_features(lookback_df, label_col=label_col, latency_to_use=latency_to_use)\n",
    "        label = og_df.loc[i, label_col]\n",
    "        hostname = og_df.loc[i, 'hostname']\n",
    "        row = {**lookback_features, 'label': label, 'date': end_time, 'hostname': hostname}\n",
    "        featured_df.loc[len(featured_df)] = row\n",
    "\n",
    "    return featured_df\n",
    "\n",
    "\n",
    "def transform_single_df_to_features(df, cur_hostname, label_col='predictions'):\n",
    "    \"\"\"\n",
    "    Transform a single device's data to features.\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataframe\n",
    "        cur_hostname: Hostname to filter by\n",
    "        label_col: Column name to use as labels\n",
    "    \"\"\"\n",
    "    host_isolated = df[df['hostname'] == cur_hostname]\n",
    "    host_isolated = host_isolated.sort_values(by='date', ascending=True)\n",
    "    return get_feature_df(host_isolated, label_col=label_col, latency_to_use='ping_latency')\n",
    "\n",
    "\n",
    "print(\"Feature engineering functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daceac9",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Functions\n",
    "\n",
    "Includes new threshold-based metrics:\n",
    "- **FPR at 90% Recall**: What false positive rate is needed to catch 90% of anomalies\n",
    "- **Recall at 10% FPR**: What percentage of anomalies are caught with 10% false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380eb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_threshold_metrics(y_test, y_proba):\n",
    "    \"\"\"\n",
    "    Calculate threshold-based metrics:\n",
    "    - FPR at 90% Recall: What FPR is needed to catch 90% of anomalies\n",
    "    - Recall at 10% FPR: What recall is achieved at 10% FPR\n",
    "    \n",
    "    Args:\n",
    "        y_test: True labels\n",
    "        y_proba: Predicted probabilities for positive class\n",
    "    \n",
    "    Returns:\n",
    "        fpr_at_90_recall: FPR when recall is 90%\n",
    "        recall_at_10_fpr: Recall when FPR is 10%\n",
    "    \"\"\"\n",
    "    # Sort by probability descending\n",
    "    sorted_indices = np.argsort(-y_proba)\n",
    "    y_test_sorted = y_test.iloc[sorted_indices].values if hasattr(y_test, 'iloc') else y_test[sorted_indices]\n",
    "    \n",
    "    total_positives = y_test_sorted.sum()\n",
    "    total_negatives = len(y_test_sorted) - total_positives\n",
    "    \n",
    "    # Edge case: no anomalies\n",
    "    if total_positives == 0:\n",
    "        return -1, -1\n",
    "    \n",
    "    # Calculate cumulative metrics\n",
    "    cumulative_tp = np.cumsum(y_test_sorted)\n",
    "    cumulative_fp = np.cumsum(1 - y_test_sorted)\n",
    "    \n",
    "    # Calculate recall and FPR at each threshold\n",
    "    recalls = cumulative_tp / total_positives\n",
    "    fprs = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)\n",
    "    \n",
    "    # FPR at 90% Recall\n",
    "    target_recall = 0.90\n",
    "    idx_90_recall = np.where(recalls >= target_recall)[0]\n",
    "    if len(idx_90_recall) > 0:\n",
    "        fpr_at_90_recall = fprs[idx_90_recall[0]]\n",
    "    else:\n",
    "        fpr_at_90_recall = 1.0  # Would need 100% FPR to reach 90% recall\n",
    "    \n",
    "    # Recall at 10% FPR\n",
    "    target_fpr = 0.10\n",
    "    idx_10_fpr = np.where(fprs <= target_fpr)[0]\n",
    "    if len(idx_10_fpr) > 0:\n",
    "        recall_at_10_fpr = recalls[idx_10_fpr[-1]]  # Last index where FPR <= 10%\n",
    "    else:\n",
    "        recall_at_10_fpr = 0.0  # Can't achieve any recall at 10% FPR\n",
    "    \n",
    "    return fpr_at_90_recall, recall_at_10_fpr\n",
    "\n",
    "\n",
    "def evaluate_model_per_device(X_train, y_train, X_test, y_test, hostname):\n",
    "    \"\"\"\n",
    "    Train all models and evaluate on test set for a single device.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training features and labels\n",
    "        X_test, y_test: Test features and labels\n",
    "        hostname: Device hostname\n",
    "    \n",
    "    Returns:\n",
    "        List of result dictionaries for each model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, clf in model_dict.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "            has_proba = True\n",
    "        except:\n",
    "            y_proba = None\n",
    "            has_proba = False\n",
    "        \n",
    "        # Standard metrics\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1_anomaly = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        roc_auc = -1\n",
    "        fpr_at_90_recall = -1\n",
    "        recall_at_10_fpr = -1\n",
    "        \n",
    "        if has_proba:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            fpr_at_90_recall, recall_at_10_fpr = calculate_threshold_metrics(y_test, y_proba)\n",
    "\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'hostname': hostname,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_anomaly,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr_at_90_recall': fpr_at_90_recall,\n",
    "            'recall_at_10_fpr': recall_at_10_fpr,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            'caught_anomalies': tp,\n",
    "            'missed_anomalies': fn,\n",
    "            'false_alarms': fp,\n",
    "            'total_test_samples': len(y_test),\n",
    "            'total_anomalies': y_test.sum()\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Model evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f7456",
   "metadata": {},
   "source": [
    "## 6. Main Evaluation Loop\n",
    "\n",
    "Iterate over all three anomaly detection methods and evaluate per-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7d44c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 36\n",
      "Hosts with anomalies in test: 35\n",
      "Hosts with anomalies in BOTH train and test: 34\n",
      "\n",
      "[1/34] Evaluating models for hostname: 29129b6\n",
      "[2/34] Evaluating models for hostname: 972f622\n",
      "[3/34] Evaluating models for hostname: 5bf17fc\n",
      "[4/34] Evaluating models for hostname: f8f4b44\n",
      "[5/34] Evaluating models for hostname: dede9dc\n",
      "[6/34] Evaluating models for hostname: 5c5004f\n",
      "[7/34] Evaluating models for hostname: 64b750b\n",
      "[8/34] Evaluating models for hostname: d493afd\n",
      "[9/34] Evaluating models for hostname: 9dc32f2\n",
      "[10/34] Evaluating models for hostname: 33fe84e\n",
      "[11/34] Evaluating models for hostname: 24a22bf\n",
      "[12/34] Evaluating models for hostname: a2e0486\n",
      "[13/34] Evaluating models for hostname: b2c53ee\n",
      "[14/34] Evaluating models for hostname: ed86ea2\n",
      "[15/34] Evaluating models for hostname: 2620a05\n",
      "[16/34] Evaluating models for hostname: 43e847f\n",
      "[17/34] Evaluating models for hostname: 0f42441\n",
      "[18/34] Evaluating models for hostname: b340432\n",
      "[19/34] Evaluating models for hostname: 953d46d\n",
      "[20/34] Evaluating models for hostname: 592a43c\n",
      "[21/34] Evaluating models for hostname: 25b3303\n",
      "[22/34] Evaluating models for hostname: 8445893\n",
      "[23/34] Evaluating models for hostname: 9ab8252\n",
      "[24/34] Evaluating models for hostname: da6d469\n",
      "[25/34] Evaluating models for hostname: 7f6d63d\n",
      "[26/34] Evaluating models for hostname: c073f39\n",
      "[27/34] Evaluating models for hostname: 6ca8355\n",
      "[28/34] Evaluating models for hostname: 1a21874\n",
      "[29/34] Evaluating models for hostname: b407ebe\n",
      "[30/34] Evaluating models for hostname: b5c8445\n",
      "[31/34] Evaluating models for hostname: 63598f8\n",
      "[32/34] Evaluating models for hostname: 9840de6\n",
      "[33/34] Evaluating models for hostname: 575f518\n",
      "[34/34] Evaluating models for hostname: 38b6bf0\n",
      "\n",
      "Completed evaluation for basic_ema_anomaly: 272 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 23\n",
      "Hosts with anomalies in test: 24\n",
      "Hosts with anomalies in BOTH train and test: 23\n",
      "\n",
      "[1/23] Evaluating models for hostname: 29129b6\n",
      "[2/23] Evaluating models for hostname: 972f622\n",
      "[3/23] Evaluating models for hostname: f8f4b44\n",
      "[4/23] Evaluating models for hostname: dede9dc\n",
      "[5/23] Evaluating models for hostname: 9dc32f2\n",
      "[6/23] Evaluating models for hostname: 33fe84e\n",
      "[7/23] Evaluating models for hostname: 24a22bf\n",
      "[8/23] Evaluating models for hostname: a2e0486\n",
      "[9/23] Evaluating models for hostname: b2c53ee\n",
      "[10/23] Evaluating models for hostname: 2620a05\n",
      "[11/23] Evaluating models for hostname: 43e847f\n",
      "[12/23] Evaluating models for hostname: b340432\n",
      "[13/23] Evaluating models for hostname: 953d46d\n",
      "[14/23] Evaluating models for hostname: 592a43c\n",
      "[15/23] Evaluating models for hostname: 25b3303\n",
      "[16/23] Evaluating models for hostname: 9ab8252\n",
      "[17/23] Evaluating models for hostname: da6d469\n",
      "[18/23] Evaluating models for hostname: 7f6d63d\n",
      "[19/23] Evaluating models for hostname: c073f39\n",
      "[20/23] Evaluating models for hostname: 6ca8355\n",
      "[21/23] Evaluating models for hostname: b407ebe\n",
      "[22/23] Evaluating models for hostname: 575f518\n",
      "[23/23] Evaluating models for hostname: 38b6bf0\n",
      "\n",
      "Completed evaluation for dspot_anomaly: 184 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Hosts with anomalies in train: 29\n",
      "Hosts with anomalies in test: 24\n",
      "Hosts with anomalies in BOTH train and test: 22\n",
      "\n",
      "[1/22] Evaluating models for hostname: 29129b6\n",
      "[2/22] Evaluating models for hostname: 972f622\n",
      "[3/22] Evaluating models for hostname: 5bf17fc\n",
      "[4/22] Evaluating models for hostname: f8f4b44\n",
      "[5/22] Evaluating models for hostname: dede9dc\n",
      "[6/22] Evaluating models for hostname: 5c5004f\n",
      "[7/22] Evaluating models for hostname: 33fe84e\n",
      "[8/22] Evaluating models for hostname: a2e0486\n",
      "[9/22] Evaluating models for hostname: ed86ea2\n",
      "[10/22] Evaluating models for hostname: 2620a05\n",
      "[11/22] Evaluating models for hostname: 0f42441\n",
      "[12/22] Evaluating models for hostname: b340432\n",
      "[13/22] Evaluating models for hostname: 953d46d\n",
      "[14/22] Evaluating models for hostname: 25b3303\n",
      "[15/22] Evaluating models for hostname: da6d469\n",
      "[16/22] Evaluating models for hostname: 7f6d63d\n",
      "[17/22] Evaluating models for hostname: 6ca8355\n",
      "[18/22] Evaluating models for hostname: b407ebe\n",
      "[19/22] Evaluating models for hostname: b5c8445\n",
      "[20/22] Evaluating models for hostname: 9840de6\n",
      "[21/22] Evaluating models for hostname: 575f518\n",
      "[22/22] Evaluating models for hostname: 38b6bf0\n",
      "\n",
      "Completed evaluation for tuned_dspot_anomaly: 176 total evaluations\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the three anomaly columns to evaluate\n",
    "anomaly_columns = ['basic_ema_anomaly', 'dspot_anomaly', 'tuned_dspot_anomaly']\n",
    "\n",
    "# Store results for each method\n",
    "all_results_by_method = {}\n",
    "\n",
    "# Columns to remove when creating features\n",
    "remove_cols = ['label', 'date', 'hostname']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING PER-DEVICE MODELS FOR EACH ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANOMALY DETECTION METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Filter to hosts that have anomalies in both train and test for this method\n",
    "    train_hostnames_with_anomalies = train[train[label_col] == True]['hostname'].unique()\n",
    "    test_hostnames_with_anomalies = test[test[label_col] == True]['hostname'].unique()\n",
    "    hostnames_in_both = set(train_hostnames_with_anomalies).intersection(set(test_hostnames_with_anomalies))\n",
    "    \n",
    "    print(f\"Hosts with anomalies in train: {len(train_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in test: {len(test_hostnames_with_anomalies)}\")\n",
    "    print(f\"Hosts with anomalies in BOTH train and test: {len(hostnames_in_both)}\\n\")\n",
    "    \n",
    "    if len(hostnames_in_both) == 0:\n",
    "        print(f\"WARNING: No hosts have anomalies in both train and test for {label_col}. Skipping.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Filter train and test to only these hosts\n",
    "    train_filtered = train[train['hostname'].isin(hostnames_in_both)]\n",
    "    test_filtered = test[test['hostname'].isin(hostnames_in_both)]\n",
    "    \n",
    "    # Evaluate models for each host\n",
    "    method_results = []\n",
    "    \n",
    "    for i, cur_hostname in enumerate(hostnames_in_both, 1):\n",
    "        print(f\"[{i}/{len(hostnames_in_both)}] Evaluating models for hostname: {cur_hostname}\")\n",
    "        \n",
    "        # Create features using this label column\n",
    "        train_single_w_lookback = transform_single_df_to_features(train_filtered, cur_hostname, label_col=label_col)\n",
    "        test_single_w_lookback = transform_single_df_to_features(test_filtered, cur_hostname, label_col=label_col)\n",
    "        \n",
    "        # Prepare X and y\n",
    "        X_train = train_single_w_lookback.drop(columns=remove_cols)\n",
    "        X_test = test_single_w_lookback.drop(columns=remove_cols)\n",
    "        y_train = train_single_w_lookback[\"label\"].astype(int)\n",
    "        y_test = test_single_w_lookback[\"label\"].astype(int)\n",
    "        \n",
    "        # Evaluate models\n",
    "        hostname_results = evaluate_model_per_device(X_train, y_train, X_test, y_test, cur_hostname)\n",
    "        method_results.extend(hostname_results)\n",
    "    \n",
    "    # Store results for this method\n",
    "    all_results_by_method[label_col] = pd.DataFrame(method_results)\n",
    "    print(f\"\\nCompleted evaluation for {label_col}: {len(method_results)} total evaluations\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f199ec",
   "metadata": {},
   "source": [
    "## 7. Results Summary\n",
    "\n",
    "Display aggregate statistics for each anomaly detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f3b4edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.8394    0.0575     0.1023   \n",
      "Decision Tree                              0.6380    0.1480     0.1345   \n",
      "Linear Classifier (Logistic Regression)    0.6268    0.1921     0.1406   \n",
      "Linear SVM                                 0.6018    0.1968     0.1473   \n",
      "Naive Bayes                                0.7532    0.1723     0.1514   \n",
      "Nearest Neighbors                          0.8433    0.0651     0.1159   \n",
      "RBF SVM                                    0.5768    0.2134     0.1409   \n",
      "Random Forest                              0.8753    0.0188     0.0665   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0508   0.4779  \n",
      "Decision Tree                            0.3134   0.4757  \n",
      "Linear Classifier (Logistic Regression)  0.3935   0.4947  \n",
      "Linear SVM                               0.4229   0.5173  \n",
      "Naive Bayes                              0.2751   0.5139  \n",
      "Nearest Neighbors                        0.0586   0.5332  \n",
      "RBF SVM                                  0.5399   0.5500  \n",
      "Random Forest                            0.0116   0.4843  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.8999            0.1245\n",
      "Decision Tree                                      0.8484            0.0882\n",
      "Linear Classifier (Logistic Regression)            0.8520            0.1543\n",
      "Linear SVM                                         0.8456            0.1284\n",
      "Naive Bayes                                        0.8509            0.1623\n",
      "Nearest Neighbors                                  0.7856            0.1676\n",
      "RBF SVM                                            0.8220            0.1932\n",
      "Random Forest                                      0.8688            0.1586\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               70               799   \n",
      "Decision Tree                                         303               566   \n",
      "Linear Classifier (Logistic Regression)               412               457   \n",
      "Linear SVM                                            475               394   \n",
      "Naive Bayes                                           277               592   \n",
      "Nearest Neighbors                                      69               800   \n",
      "RBF SVM                                               542               327   \n",
      "Random Forest                                          10               859   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                          407              869  \n",
      "Decision Tree                                    2146              869  \n",
      "Linear Classifier (Logistic Regression)          2334              869  \n",
      "Linear SVM                                       2589              869  \n",
      "Naive Bayes                                      1282              869  \n",
      "Nearest Neighbors                                 378              869  \n",
      "RBF SVM                                          2837              869  \n",
      "Random Forest                                      75              869  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: RBF SVM (0.2134)\n",
      "Best Recall: RBF SVM (0.5399)\n",
      "Best Precision: Naive Bayes (0.1514)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.7856)\n",
      "Best Recall at 10% FPR: RBF SVM (0.1932)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.8960    0.0378     0.0431   \n",
      "Decision Tree                              0.7798    0.0947     0.0656   \n",
      "Linear Classifier (Logistic Regression)    0.6817    0.0955     0.0752   \n",
      "Linear SVM                                 0.6827    0.0896     0.0748   \n",
      "Naive Bayes                                0.6547    0.0825     0.0644   \n",
      "Nearest Neighbors                          0.8993    0.0315     0.0452   \n",
      "RBF SVM                                    0.5861    0.1024     0.0732   \n",
      "Random Forest                              0.9202    0.0192     0.0801   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0359   0.4931  \n",
      "Decision Tree                            0.2067   0.5115  \n",
      "Linear Classifier (Logistic Regression)  0.2300   0.4431  \n",
      "Linear SVM                               0.2623   0.4683  \n",
      "Naive Bayes                              0.2717   0.4609  \n",
      "Nearest Neighbors                        0.0294   0.4848  \n",
      "RBF SVM                                  0.3756   0.5165  \n",
      "Random Forest                            0.0119   0.4998  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.8314            0.0594\n",
      "Decision Tree                                      0.7758            0.1180\n",
      "Linear Classifier (Logistic Regression)            0.8775            0.0609\n",
      "Linear SVM                                         0.8297            0.1061\n",
      "Naive Bayes                                        0.8612            0.0513\n",
      "Nearest Neighbors                                  0.8110            0.1025\n",
      "RBF SVM                                            0.8183            0.1165\n",
      "Random Forest                                      0.8095            0.0828\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               37               379   \n",
      "Decision Tree                                         130               286   \n",
      "Linear Classifier (Logistic Regression)               133               283   \n",
      "Linear SVM                                            122               294   \n",
      "Naive Bayes                                           104               312   \n",
      "Nearest Neighbors                                      30               386   \n",
      "RBF SVM                                               193               223   \n",
      "Random Forest                                          13               403   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                          185              416  \n",
      "Decision Tree                                     886              416  \n",
      "Linear Classifier (Logistic Regression)          1430              416  \n",
      "Linear SVM                                       1414              416  \n",
      "Naive Bayes                                      1544              416  \n",
      "Nearest Neighbors                                 155              416  \n",
      "RBF SVM                                          2005              416  \n",
      "Random Forest                                      30              416  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: RBF SVM (0.1024)\n",
      "Best Recall: RBF SVM (0.3756)\n",
      "Best Precision: Random Forest (0.0801)\n",
      "Best FPR at 90% Recall: Decision Tree (0.7758)\n",
      "Best Recall at 10% FPR: Decision Tree (0.1180)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                         accuracy  f1_score  precision  \\\n",
      "model                                                                    \n",
      "AdaBoost                                   0.9464    0.0496     0.0674   \n",
      "Decision Tree                              0.8721    0.0637     0.0487   \n",
      "Linear Classifier (Logistic Regression)    0.7700    0.1098     0.0795   \n",
      "Linear SVM                                 0.7226    0.0917     0.0746   \n",
      "Naive Bayes                                0.8109    0.0735     0.0644   \n",
      "Nearest Neighbors                          0.9562    0.0567     0.0716   \n",
      "RBF SVM                                    0.6490    0.0984     0.0660   \n",
      "Random Forest                              0.9600    0.0542     0.0997   \n",
      "\n",
      "                                         recall  roc_auc  \n",
      "model                                                     \n",
      "AdaBoost                                 0.0499   0.4893  \n",
      "Decision Tree                            0.1250   0.4830  \n",
      "Linear Classifier (Logistic Regression)  0.3390   0.5210  \n",
      "Linear SVM                               0.3263   0.4543  \n",
      "Naive Bayes                              0.1655   0.4982  \n",
      "Nearest Neighbors                        0.0616   0.5235  \n",
      "RBF SVM                                  0.3709   0.5759  \n",
      "Random Forest                            0.0499   0.4888  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         fpr_at_90_recall  recall_at_10_fpr\n",
      "model                                                                      \n",
      "AdaBoost                                           0.7746            0.1458\n",
      "Decision Tree                                      0.7410            0.1713\n",
      "Linear Classifier (Logistic Regression)            0.7659            0.2350\n",
      "Linear SVM                                         0.8294            0.1505\n",
      "Naive Bayes                                        0.7257            0.2273\n",
      "Nearest Neighbors                                  0.6656            0.1974\n",
      "RBF SVM                                            0.7121            0.1393\n",
      "Random Forest                                      0.7897            0.0955\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                         caught_anomalies  missed_anomalies  \\\n",
      "model                                                                         \n",
      "AdaBoost                                               33               136   \n",
      "Decision Tree                                          48               121   \n",
      "Linear Classifier (Logistic Regression)                75                94   \n",
      "Linear SVM                                             72                97   \n",
      "Naive Bayes                                            53               116   \n",
      "Nearest Neighbors                                      41               128   \n",
      "RBF SVM                                                85                84   \n",
      "Random Forest                                          33               136   \n",
      "\n",
      "                                         false_alarms  total_anomalies  \n",
      "model                                                                   \n",
      "AdaBoost                                           97              169  \n",
      "Decision Tree                                     494              169  \n",
      "Linear Classifier (Logistic Regression)          1047              169  \n",
      "Linear SVM                                       1234              169  \n",
      "Naive Bayes                                       820              169  \n",
      "Nearest Neighbors                                  59              169  \n",
      "RBF SVM                                          1619              169  \n",
      "Random Forest                                      36              169  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: Linear Classifier (Logistic Regression) (0.1098)\n",
      "Best Recall: RBF SVM (0.3709)\n",
      "Best Precision: Random Forest (0.0997)\n",
      "Best FPR at 90% Recall: Nearest Neighbors (0.6656)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.2350)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATE RESULTS BY ANOMALY DETECTION METHOD\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Group by model and calculate mean metrics\n",
    "    grouped = results_df.groupby('model').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'f1_score': 'mean',\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'roc_auc': 'mean',\n",
    "        'fpr_at_90_recall': 'mean',\n",
    "        'recall_at_10_fpr': 'mean',\n",
    "        'caught_anomalies': 'sum',\n",
    "        'missed_anomalies': 'sum',\n",
    "        'false_alarms': 'sum',\n",
    "        'total_anomalies': 'sum'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"Standard Metrics:\")\n",
    "    print(grouped[['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Threshold-Based Metrics:\")\n",
    "    print(\"-\"*80)\n",
    "    threshold_metrics = grouped[['fpr_at_90_recall', 'recall_at_10_fpr']].copy()\n",
    "    print(threshold_metrics)\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\")\n",
    "    print(\"    (Lower is better - means fewer false alarms to catch most issues)\")\n",
    "    print(\"  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\")\n",
    "    print(\"    (Higher is better - means catching more issues with acceptable false alarm rate)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Anomaly Detection Stats:\")\n",
    "    print(\"-\"*80)\n",
    "    print(grouped[['caught_anomalies', 'missed_anomalies', 'false_alarms', 'total_anomalies']])\n",
    "    \n",
    "    # Best models\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Best Models:\")\n",
    "    print(\"-\"*80)\n",
    "    best_f1 = grouped['f1_score'].idxmax()\n",
    "    best_recall = grouped['recall'].idxmax()\n",
    "    best_precision = grouped['precision'].idxmax()\n",
    "    best_fpr_90 = grouped['fpr_at_90_recall'].idxmin()  # Lower is better\n",
    "    best_recall_10 = grouped['recall_at_10_fpr'].idxmax()  # Higher is better\n",
    "    \n",
    "    print(f\"Best F1 Score: {best_f1} ({grouped.loc[best_f1, 'f1_score']:.4f})\")\n",
    "    print(f\"Best Recall: {best_recall} ({grouped.loc[best_recall, 'recall']:.4f})\")\n",
    "    print(f\"Best Precision: {best_precision} ({grouped.loc[best_precision, 'precision']:.4f})\")\n",
    "    print(f\"Best FPR at 90% Recall: {best_fpr_90} ({grouped.loc[best_fpr_90, 'fpr_at_90_recall']:.4f})\")\n",
    "    print(f\"Best Recall at 10% FPR: {best_recall_10} ({grouped.loc[best_recall_10, 'recall_at_10_fpr']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda46b0d",
   "metadata": {},
   "source": [
    "## 8. Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d255837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for basic_ema_anomaly to per_device_results_basic_ema_anomaly.csv\n",
      "Saved results for dspot_anomaly to per_device_results_dspot_anomaly.csv\n",
      "Saved results for tuned_dspot_anomaly to per_device_results_tuned_dspot_anomaly.csv\n",
      "\n",
      "All results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results for each method\n",
    "for label_col, results_df in all_results_by_method.items():\n",
    "    filename = f\"per_device_results_{label_col}.csv\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved results for {label_col} to {filename}\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5b67c",
   "metadata": {},
   "source": [
    "## 9. Exploratory: Multi-Device Models\n",
    "\n",
    "Train models on ALL data combined (not split per device) and evaluate with the same metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5fd38",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook evaluated per-device ML models on three different anomaly detection methods:\n",
    "1. **basic_ema_anomaly**: Basic EMA-based detection\n",
    "2. **dspot_anomaly**: DSPOT detection\n",
    "3. **tuned_dspot_anomaly**: Tuned DSPOT detection\n",
    "\n",
    "For each method, we trained 8 different ML models per device and calculated:\n",
    "- Standard classification metrics (accuracy, F1, precision, recall, ROC-AUC)\n",
    "- **FPR at 90% Recall**: Answers \"how many false alarms to catch 90% of issues?\"\n",
    "- **Recall at 10% FPR**: Answers \"how many issues caught with 10% false alarm rate?\"\n",
    "\n",
    "The threshold-based metrics are particularly useful for understanding:\n",
    "- **Customers who want to catch as many anomalies as possible**: Look at FPR at 90% Recall\n",
    "- **Customers who want to minimize false alarms**: Look at Recall at 10% FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49059a4f",
   "metadata": {},
   "source": [
    "### Multi-Device Feature Engineering\n",
    "\n",
    "Create features from all devices combined for each anomaly detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4feabcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-device feature engineering function defined\n"
     ]
    }
   ],
   "source": [
    "def transform_multidevice_df_to_features(df, label_col='predictions'):\n",
    "    \"\"\"\n",
    "    Create features for all devices combined.\n",
    "    \n",
    "    Args:\n",
    "        df: Full dataframe with multiple devices\n",
    "        label_col: Column name to use as labels\n",
    "    \"\"\"\n",
    "    hostnames = df[\"hostname\"].unique().tolist()\n",
    "    featured_dfs = []\n",
    "    \n",
    "    for cur_hostname in hostnames:\n",
    "        host_isolated = df[df['hostname'] == cur_hostname]\n",
    "        host_isolated = host_isolated.sort_values(by='date', ascending=True)\n",
    "        feature_df = get_feature_df(host_isolated, label_col=label_col, latency_to_use='normalized_latency')\n",
    "        featured_dfs.append(feature_df)\n",
    "    \n",
    "    final_df = pd.concat(featured_dfs, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "print(\"Multi-device feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600fc8e",
   "metadata": {},
   "source": [
    "### Evaluate Multi-Device Models\n",
    "\n",
    "Train on all data combined and evaluate with the same metrics as per-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "546b4e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING MULTI-DEVICE MODELS (TRAINED ON ALL DATA COMBINED)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "Creating features from 34 hosts...\n",
      "Train features: 10048 samples\n",
      "Test features: 7241 samples\n",
      "Train anomalies: 1091 / 10048 (10.86%)\n",
      "Test anomalies: 869 / 7241 (12.00%)\n",
      "  Training Linear Classifier (Logistic Regression)...\n",
      "  Training Nearest Neighbors...\n",
      "  Training Linear SVM...\n",
      "  Training RBF SVM...\n",
      "  Training Decision Tree...\n",
      "  Training Random Forest...\n",
      "  Training AdaBoost...\n",
      "  Training Naive Bayes...\n",
      "\n",
      "Completed multi-device evaluation for basic_ema_anomaly\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Creating features from 23 hosts...\n",
      "Train features: 6934 samples\n",
      "Test features: 5397 samples\n",
      "Train anomalies: 517 / 6934 (7.46%)\n",
      "Test anomalies: 416 / 5397 (7.71%)\n",
      "  Training Linear Classifier (Logistic Regression)...\n",
      "  Training Nearest Neighbors...\n",
      "  Training Linear SVM...\n",
      "  Training RBF SVM...\n",
      "  Training Decision Tree...\n",
      "  Training Random Forest...\n",
      "  Training AdaBoost...\n",
      "  Training Naive Bayes...\n",
      "\n",
      "Completed multi-device evaluation for dspot_anomaly\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL FOR: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "Creating features from 22 hosts...\n",
      "Train features: 6528 samples\n",
      "Test features: 4849 samples\n",
      "Train anomalies: 243 / 6528 (3.72%)\n",
      "Test anomalies: 169 / 4849 (3.49%)\n",
      "  Training Linear Classifier (Logistic Regression)...\n",
      "  Training Nearest Neighbors...\n",
      "  Training Linear SVM...\n",
      "  Training RBF SVM...\n",
      "  Training Decision Tree...\n",
      "  Training Random Forest...\n",
      "  Training AdaBoost...\n",
      "  Training Naive Bayes...\n",
      "\n",
      "Completed multi-device evaluation for tuned_dspot_anomaly\n",
      "\n",
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Store multi-device results\n",
    "all_multidevice_results = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING MULTI-DEVICE MODELS (TRAINED ON ALL DATA COMBINED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MULTI-DEVICE MODEL FOR: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Use the same filtered train/test as per-device models\n",
    "    # Get hosts with anomalies in both train and test\n",
    "    train_hostnames_with_anomalies = train[train[label_col] == True]['hostname'].unique()\n",
    "    test_hostnames_with_anomalies = test[test[label_col] == True]['hostname'].unique()\n",
    "    hostnames_in_both = set(train_hostnames_with_anomalies).intersection(set(test_hostnames_with_anomalies))\n",
    "    \n",
    "    if len(hostnames_in_both) == 0:\n",
    "        print(f\"WARNING: No hosts have anomalies in both train and test for {label_col}. Skipping.\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Filter to hosts with anomalies in both\n",
    "    train_filtered = train[train['hostname'].isin(hostnames_in_both)]\n",
    "    test_filtered = test[test['hostname'].isin(hostnames_in_both)]\n",
    "    \n",
    "    print(f\"Creating features from {len(hostnames_in_both)} hosts...\")\n",
    "    \n",
    "    # Create features for ALL devices combined\n",
    "    train_multi_w_lookback = transform_multidevice_df_to_features(train_filtered, label_col=label_col)\n",
    "    test_multi_w_lookback = transform_multidevice_df_to_features(test_filtered, label_col=label_col)\n",
    "    \n",
    "    print(f\"Train features: {len(train_multi_w_lookback)} samples\")\n",
    "    print(f\"Test features: {len(test_multi_w_lookback)} samples\")\n",
    "    \n",
    "    # Prepare X and y\n",
    "    X_train = train_multi_w_lookback.drop(columns=remove_cols)\n",
    "    X_test = test_multi_w_lookback.drop(columns=remove_cols)\n",
    "    y_train = train_multi_w_lookback[\"label\"].astype(int)\n",
    "    y_test = test_multi_w_lookback[\"label\"].astype(int)\n",
    "    \n",
    "    print(f\"Train anomalies: {y_train.sum()} / {len(y_train)} ({y_train.mean()*100:.2f}%)\")\n",
    "    print(f\"Test anomalies: {y_test.sum()} / {len(y_test)} ({y_test.mean()*100:.2f}%)\")\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = []\n",
    "    \n",
    "    for model_name, clf in model_dict.items():\n",
    "        print(f\"  Training {model_name}...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "            has_proba = True\n",
    "        except:\n",
    "            y_proba = None\n",
    "            has_proba = False\n",
    "        \n",
    "        # Standard metrics\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1_anomaly = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        roc_auc = -1\n",
    "        fpr_at_90_recall = -1\n",
    "        recall_at_10_fpr = -1\n",
    "        \n",
    "        if has_proba:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            fpr_at_90_recall, recall_at_10_fpr = calculate_threshold_metrics(y_test, y_proba)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_anomaly,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr_at_90_recall': fpr_at_90_recall,\n",
    "            'recall_at_10_fpr': recall_at_10_fpr,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'true_negatives': tn,\n",
    "            'false_negatives': fn,\n",
    "            'caught_anomalies': tp,\n",
    "            'missed_anomalies': fn,\n",
    "            'false_alarms': fp,\n",
    "            'total_test_samples': len(y_test),\n",
    "            'total_anomalies': y_test.sum()\n",
    "        })\n",
    "    \n",
    "    all_multidevice_results[label_col] = pd.DataFrame(results)\n",
    "    print(f\"\\nCompleted multi-device evaluation for {label_col}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-DEVICE EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68283cc",
   "metadata": {},
   "source": [
    "### Multi-Device Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27bc1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MULTI-DEVICE MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                  model  accuracy  f1_score  precision   recall  roc_auc\n",
      "Linear Classifier (Logistic Regression)  0.120011  0.214303   0.120011 1.000000 0.694433\n",
      "                      Nearest Neighbors  0.838420  0.077287   0.122807 0.056387 0.511250\n",
      "                             Linear SVM  0.532523  0.284809   0.174431 0.775604 0.633509\n",
      "                                RBF SVM  0.532523  0.284809   0.174431 0.775604 0.625580\n",
      "                          Decision Tree  0.410717  0.254151   0.149835 0.836594 0.632235\n",
      "                          Random Forest  0.879989  0.000000   0.000000 0.000000 0.550086\n",
      "                               AdaBoost  0.865212  0.122302   0.279835 0.078251 0.675231\n",
      "                            Naive Bayes  0.120011  0.214303   0.120011 1.000000 0.500000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)          0.678594          0.258918\n",
      "                      Nearest Neighbors          0.893597          0.110472\n",
      "                             Linear SVM          0.800691          0.158803\n",
      "                                RBF SVM          0.772599          0.107020\n",
      "                          Decision Tree          0.747175          0.230150\n",
      "                          Random Forest          0.815599          0.132336\n",
      "                               AdaBoost          0.739642          0.254315\n",
      "                            Naive Bayes          0.883867          0.121979\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  caught_anomalies  missed_anomalies  false_alarms  total_anomalies\n",
      "Linear Classifier (Logistic Regression)               869                 0          6372              869\n",
      "                      Nearest Neighbors                49               820           350              869\n",
      "                             Linear SVM               674               195          3190              869\n",
      "                                RBF SVM               674               195          3190              869\n",
      "                          Decision Tree               727               142          4125              869\n",
      "                          Random Forest                 0               869             0              869\n",
      "                               AdaBoost                68               801           175              869\n",
      "                            Naive Bayes               869                 0          6372              869\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: Linear SVM (0.2848)\n",
      "Best Recall: Linear Classifier (Logistic Regression) (1.0000)\n",
      "Best Precision: AdaBoost (0.2798)\n",
      "Best FPR at 90% Recall: Linear Classifier (Logistic Regression) (0.6786)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.2589)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                  model  accuracy  f1_score  precision   recall  roc_auc\n",
      "Linear Classifier (Logistic Regression)  0.519733  0.188986   0.108633 0.725962 0.683803\n",
      "                      Nearest Neighbors  0.922550  0.000000   0.000000 0.000000 0.500700\n",
      "                             Linear SVM  0.619233  0.212342   0.126311 0.665865 0.675375\n",
      "                                RBF SVM  0.619233  0.212342   0.126311 0.665865 0.594845\n",
      "                          Decision Tree  0.918844  0.039474   0.225000 0.021635 0.399814\n",
      "                          Random Forest  0.922920  0.000000   0.000000 0.000000 0.585112\n",
      "                               AdaBoost  0.922920  0.000000   0.000000 0.000000 0.568610\n",
      "                            Naive Bayes  0.077080  0.143127   0.077080 1.000000 0.500000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)          0.746637          0.300481\n",
      "                      Nearest Neighbors          0.918691          0.057692\n",
      "                             Linear SVM          0.797029          0.276442\n",
      "                                RBF SVM          0.847019          0.098558\n",
      "                          Decision Tree          0.936960          0.079327\n",
      "                          Random Forest          0.825939          0.149038\n",
      "                               AdaBoost          0.897209          0.211538\n",
      "                            Naive Bayes          0.918691          0.057692\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  caught_anomalies  missed_anomalies  false_alarms  total_anomalies\n",
      "Linear Classifier (Logistic Regression)               302               114          2478              416\n",
      "                      Nearest Neighbors                 0               416             2              416\n",
      "                             Linear SVM               277               139          1916              416\n",
      "                                RBF SVM               277               139          1916              416\n",
      "                          Decision Tree                 9               407            31              416\n",
      "                          Random Forest                 0               416             0              416\n",
      "                               AdaBoost                 0               416             0              416\n",
      "                            Naive Bayes               416                 0          4981              416\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: Linear SVM (0.2123)\n",
      "Best Recall: Naive Bayes (1.0000)\n",
      "Best Precision: Decision Tree (0.2250)\n",
      "Best FPR at 90% Recall: Linear Classifier (Logistic Regression) (0.7466)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.3005)\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly (Multi-Device Model)\n",
      "================================================================================\n",
      "\n",
      "Standard Metrics:\n",
      "                                  model  accuracy  f1_score  precision   recall  roc_auc\n",
      "Linear Classifier (Logistic Regression)  0.034853  0.067358   0.034853 1.000000 0.710076\n",
      "                      Nearest Neighbors  0.965354  0.023256   0.666667 0.011834 0.444810\n",
      "                             Linear SVM  0.814188  0.163417   0.096916 0.520710 0.678553\n",
      "                                RBF SVM  0.814188  0.161860   0.096026 0.514793 0.685382\n",
      "                          Decision Tree  0.786348  0.056466   0.033369 0.183432 0.500719\n",
      "                          Random Forest  0.964941  0.000000   0.000000 0.000000 0.637193\n",
      "                               AdaBoost  0.965147  0.055866   0.500000 0.029586 0.656563\n",
      "                            Naive Bayes  0.034853  0.067358   0.034853 1.000000 0.500000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Threshold-Based Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  fpr_at_90_recall  recall_at_10_fpr\n",
      "Linear Classifier (Logistic Regression)          0.767735          0.437870\n",
      "                      Nearest Neighbors          0.951709          0.100592\n",
      "                             Linear SVM          0.763889          0.230769\n",
      "                                RBF SVM          0.780983          0.177515\n",
      "                          Decision Tree          0.994017          0.136095\n",
      "                          Random Forest          0.796581          0.242604\n",
      "                               AdaBoost          0.827991          0.378698\n",
      "                            Naive Bayes          0.900214          0.059172\n",
      "\n",
      "Interpretation:\n",
      "  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\n",
      "    (Lower is better - means fewer false alarms to catch most issues)\n",
      "  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\n",
      "    (Higher is better - means catching more issues with acceptable false alarm rate)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Anomaly Detection Stats:\n",
      "--------------------------------------------------------------------------------\n",
      "                                  model  caught_anomalies  missed_anomalies  false_alarms  total_anomalies\n",
      "Linear Classifier (Logistic Regression)               169                 0          4680              169\n",
      "                      Nearest Neighbors                 2               167             1              169\n",
      "                             Linear SVM                88                81           820              169\n",
      "                                RBF SVM                87                82           819              169\n",
      "                          Decision Tree                31               138           898              169\n",
      "                          Random Forest                 0               169             1              169\n",
      "                               AdaBoost                 5               164             5              169\n",
      "                            Naive Bayes               169                 0          4680              169\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Models:\n",
      "--------------------------------------------------------------------------------\n",
      "Best F1 Score: Linear SVM (0.1634)\n",
      "Best Recall: Linear Classifier (Logistic Regression) (1.0000)\n",
      "Best Precision: Nearest Neighbors (0.6667)\n",
      "Best FPR at 90% Recall: Linear SVM (0.7639)\n",
      "Best Recall at 10% FPR: Linear Classifier (Logistic Regression) (0.4379)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTI-DEVICE MODEL RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col, results_df in all_multidevice_results.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col} (Multi-Device Model)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Display all results (no grouping since it's one model per type)\n",
    "    print(\"Standard Metrics:\")\n",
    "    print(results_df[['model', 'accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Threshold-Based Metrics:\")\n",
    "    print(\"-\"*80)\n",
    "    print(results_df[['model', 'fpr_at_90_recall', 'recall_at_10_fpr']].to_string(index=False))\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  - FPR at 90% Recall: False positive rate needed to catch 90% of anomalies\")\n",
    "    print(\"    (Lower is better - means fewer false alarms to catch most issues)\")\n",
    "    print(\"  - Recall at 10% FPR: Percentage of anomalies caught at 10% false positive rate\")\n",
    "    print(\"    (Higher is better - means catching more issues with acceptable false alarm rate)\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Anomaly Detection Stats:\")\n",
    "    print(\"-\"*80)\n",
    "    print(results_df[['model', 'caught_anomalies', 'missed_anomalies', 'false_alarms', 'total_anomalies']].to_string(index=False))\n",
    "    \n",
    "    # Best models\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Best Models:\")\n",
    "    print(\"-\"*80)\n",
    "    best_f1_idx = results_df['f1_score'].idxmax()\n",
    "    best_recall_idx = results_df['recall'].idxmax()\n",
    "    best_precision_idx = results_df['precision'].idxmax()\n",
    "    best_fpr_90_idx = results_df['fpr_at_90_recall'].idxmin()\n",
    "    best_recall_10_idx = results_df['recall_at_10_fpr'].idxmax()\n",
    "    \n",
    "    print(f\"Best F1 Score: {results_df.loc[best_f1_idx, 'model']} ({results_df.loc[best_f1_idx, 'f1_score']:.4f})\")\n",
    "    print(f\"Best Recall: {results_df.loc[best_recall_idx, 'model']} ({results_df.loc[best_recall_idx, 'recall']:.4f})\")\n",
    "    print(f\"Best Precision: {results_df.loc[best_precision_idx, 'model']} ({results_df.loc[best_precision_idx, 'precision']:.4f})\")\n",
    "    print(f\"Best FPR at 90% Recall: {results_df.loc[best_fpr_90_idx, 'model']} ({results_df.loc[best_fpr_90_idx, 'fpr_at_90_recall']:.4f})\")\n",
    "    print(f\"Best Recall at 10% FPR: {results_df.loc[best_recall_10_idx, 'model']} ({results_df.loc[best_recall_10_idx, 'recall_at_10_fpr']:.4f})\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4183ef",
   "metadata": {},
   "source": [
    "### Save Multi-Device Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0613512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved multi-device results for basic_ema_anomaly to multidevice_results_basic_ema_anomaly.csv\n",
      "Saved multi-device results for dspot_anomaly to multidevice_results_dspot_anomaly.csv\n",
      "Saved multi-device results for tuned_dspot_anomaly to multidevice_results_tuned_dspot_anomaly.csv\n",
      "\n",
      "All multi-device results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save multi-device results\n",
    "for label_col, results_df in all_multidevice_results.items():\n",
    "    filename = f\"multidevice_results_{label_col}.csv\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved multi-device results for {label_col} to {filename}\")\n",
    "\n",
    "print(\"\\nAll multi-device results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8a444",
   "metadata": {},
   "source": [
    "### Comparison: Per-Device vs Multi-Device Models\n",
    "\n",
    "Compare average performance of per-device models with multi-device models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f8e834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: PER-DEVICE vs MULTI-DEVICE MODELS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: basic_ema_anomaly\n",
      "================================================================================\n",
      "\n",
      "F1 Score Comparison:\n",
      "                                  Model  Per-Device F1  Multi-Device F1\n",
      "                               AdaBoost         0.0575         0.122302\n",
      "                          Decision Tree         0.1480         0.254151\n",
      "Linear Classifier (Logistic Regression)         0.1921         0.214303\n",
      "                             Linear SVM         0.1968         0.284809\n",
      "                            Naive Bayes         0.1723         0.214303\n",
      "                      Nearest Neighbors         0.0651         0.077287\n",
      "                                RBF SVM         0.2134         0.284809\n",
      "                          Random Forest         0.0188         0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall Comparison:\n",
      "                                  Model  Per-Device Recall  Multi-Device Recall\n",
      "                               AdaBoost             0.0508             0.078251\n",
      "                          Decision Tree             0.3134             0.836594\n",
      "Linear Classifier (Logistic Regression)             0.3935             1.000000\n",
      "                             Linear SVM             0.4229             0.775604\n",
      "                            Naive Bayes             0.2751             1.000000\n",
      "                      Nearest Neighbors             0.0586             0.056387\n",
      "                                RBF SVM             0.5399             0.775604\n",
      "                          Random Forest             0.0116             0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision Comparison:\n",
      "                                  Model  Per-Device Precision  Multi-Device Precision\n",
      "                               AdaBoost                0.1023                0.279835\n",
      "                          Decision Tree                0.1345                0.149835\n",
      "Linear Classifier (Logistic Regression)                0.1406                0.120011\n",
      "                             Linear SVM                0.1473                0.174431\n",
      "                            Naive Bayes                0.1514                0.120011\n",
      "                      Nearest Neighbors                0.1159                0.122807\n",
      "                                RBF SVM                0.1409                0.174431\n",
      "                          Random Forest                0.0665                0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.8999               0.739642\n",
      "                          Decision Tree               0.8484               0.747175\n",
      "Linear Classifier (Logistic Regression)               0.8520               0.678594\n",
      "                             Linear SVM               0.8456               0.800691\n",
      "                            Naive Bayes               0.8509               0.883867\n",
      "                      Nearest Neighbors               0.7856               0.893597\n",
      "                                RBF SVM               0.8220               0.772599\n",
      "                          Random Forest               0.8688               0.815599\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.1245               0.254315\n",
      "                          Decision Tree               0.0882               0.230150\n",
      "Linear Classifier (Logistic Regression)               0.1543               0.258918\n",
      "                             Linear SVM               0.1284               0.158803\n",
      "                            Naive Bayes               0.1623               0.121979\n",
      "                      Nearest Neighbors               0.1676               0.110472\n",
      "                                RBF SVM               0.1932               0.107020\n",
      "                          Random Forest               0.1586               0.132336\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "F1 Score Comparison:\n",
      "                                  Model  Per-Device F1  Multi-Device F1\n",
      "                               AdaBoost         0.0378         0.000000\n",
      "                          Decision Tree         0.0947         0.039474\n",
      "Linear Classifier (Logistic Regression)         0.0955         0.188986\n",
      "                             Linear SVM         0.0896         0.212342\n",
      "                            Naive Bayes         0.0825         0.143127\n",
      "                      Nearest Neighbors         0.0315         0.000000\n",
      "                                RBF SVM         0.1024         0.212342\n",
      "                          Random Forest         0.0192         0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall Comparison:\n",
      "                                  Model  Per-Device Recall  Multi-Device Recall\n",
      "                               AdaBoost             0.0359             0.000000\n",
      "                          Decision Tree             0.2067             0.021635\n",
      "Linear Classifier (Logistic Regression)             0.2300             0.725962\n",
      "                             Linear SVM             0.2623             0.665865\n",
      "                            Naive Bayes             0.2717             1.000000\n",
      "                      Nearest Neighbors             0.0294             0.000000\n",
      "                                RBF SVM             0.3756             0.665865\n",
      "                          Random Forest             0.0119             0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision Comparison:\n",
      "                                  Model  Per-Device Precision  Multi-Device Precision\n",
      "                               AdaBoost                0.0431                0.000000\n",
      "                          Decision Tree                0.0656                0.225000\n",
      "Linear Classifier (Logistic Regression)                0.0752                0.108633\n",
      "                             Linear SVM                0.0748                0.126311\n",
      "                            Naive Bayes                0.0644                0.077080\n",
      "                      Nearest Neighbors                0.0452                0.000000\n",
      "                                RBF SVM                0.0732                0.126311\n",
      "                          Random Forest                0.0801                0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.8314               0.897209\n",
      "                          Decision Tree               0.7758               0.936960\n",
      "Linear Classifier (Logistic Regression)               0.8775               0.746637\n",
      "                             Linear SVM               0.8297               0.797029\n",
      "                            Naive Bayes               0.8612               0.918691\n",
      "                      Nearest Neighbors               0.8110               0.918691\n",
      "                                RBF SVM               0.8183               0.847019\n",
      "                          Random Forest               0.8095               0.825939\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.0594               0.211538\n",
      "                          Decision Tree               0.1180               0.079327\n",
      "Linear Classifier (Logistic Regression)               0.0609               0.300481\n",
      "                             Linear SVM               0.1061               0.276442\n",
      "                            Naive Bayes               0.0513               0.057692\n",
      "                      Nearest Neighbors               0.1025               0.057692\n",
      "                                RBF SVM               0.1165               0.098558\n",
      "                          Random Forest               0.0828               0.149038\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "METHOD: tuned_dspot_anomaly\n",
      "================================================================================\n",
      "\n",
      "F1 Score Comparison:\n",
      "                                  Model  Per-Device F1  Multi-Device F1\n",
      "                               AdaBoost         0.0496         0.055866\n",
      "                          Decision Tree         0.0637         0.056466\n",
      "Linear Classifier (Logistic Regression)         0.1098         0.067358\n",
      "                             Linear SVM         0.0917         0.163417\n",
      "                            Naive Bayes         0.0735         0.067358\n",
      "                      Nearest Neighbors         0.0567         0.023256\n",
      "                                RBF SVM         0.0984         0.161860\n",
      "                          Random Forest         0.0542         0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall Comparison:\n",
      "                                  Model  Per-Device Recall  Multi-Device Recall\n",
      "                               AdaBoost             0.0499             0.029586\n",
      "                          Decision Tree             0.1250             0.183432\n",
      "Linear Classifier (Logistic Regression)             0.3390             1.000000\n",
      "                             Linear SVM             0.3263             0.520710\n",
      "                            Naive Bayes             0.1655             1.000000\n",
      "                      Nearest Neighbors             0.0616             0.011834\n",
      "                                RBF SVM             0.3709             0.514793\n",
      "                          Random Forest             0.0499             0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision Comparison:\n",
      "                                  Model  Per-Device Precision  Multi-Device Precision\n",
      "                               AdaBoost                0.0674                0.500000\n",
      "                          Decision Tree                0.0487                0.033369\n",
      "Linear Classifier (Logistic Regression)                0.0795                0.034853\n",
      "                             Linear SVM                0.0746                0.096916\n",
      "                            Naive Bayes                0.0644                0.034853\n",
      "                      Nearest Neighbors                0.0716                0.666667\n",
      "                                RBF SVM                0.0660                0.096026\n",
      "                          Random Forest                0.0997                0.000000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FPR at 90% Recall Comparison (lower is better):\n",
      "                                  Model  Per-Device FPR@90%R  Multi-Device FPR@90%R\n",
      "                               AdaBoost               0.7746               0.827991\n",
      "                          Decision Tree               0.7410               0.994017\n",
      "Linear Classifier (Logistic Regression)               0.7659               0.767735\n",
      "                             Linear SVM               0.8294               0.763889\n",
      "                            Naive Bayes               0.7257               0.900214\n",
      "                      Nearest Neighbors               0.6656               0.951709\n",
      "                                RBF SVM               0.7121               0.780983\n",
      "                          Random Forest               0.7897               0.796581\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Recall at 10% FPR Comparison (higher is better):\n",
      "                                  Model  Per-Device R@10%FPR  Multi-Device R@10%FPR\n",
      "                               AdaBoost               0.1458               0.378698\n",
      "                          Decision Tree               0.1713               0.136095\n",
      "Linear Classifier (Logistic Regression)               0.2350               0.437870\n",
      "                             Linear SVM               0.1505               0.230769\n",
      "                            Naive Bayes               0.2273               0.059172\n",
      "                      Nearest Neighbors               0.1974               0.100592\n",
      "                                RBF SVM               0.1393               0.177515\n",
      "                          Random Forest               0.0955               0.242604\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: PER-DEVICE vs MULTI-DEVICE MODELS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for label_col in anomaly_columns:\n",
    "    if label_col not in all_results_by_method or label_col not in all_multidevice_results:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METHOD: {label_col}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Per-device average\n",
    "    per_device_df = all_results_by_method[label_col]\n",
    "    per_device_avg = per_device_df.groupby('model').agg({\n",
    "        'accuracy': 'mean',\n",
    "        'f1_score': 'mean',\n",
    "        'precision': 'mean',\n",
    "        'recall': 'mean',\n",
    "        'roc_auc': 'mean',\n",
    "        'fpr_at_90_recall': 'mean',\n",
    "        'recall_at_10_fpr': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    # Multi-device\n",
    "    multi_device_df = all_multidevice_results[label_col].set_index('model')\n",
    "    \n",
    "    # Compare\n",
    "    comparison = pd.DataFrame({\n",
    "        'Model': per_device_avg.index,\n",
    "        'Per-Device F1': per_device_avg['f1_score'].values,\n",
    "        'Multi-Device F1': multi_device_df.loc[per_device_avg.index, 'f1_score'].values,\n",
    "        'Per-Device Recall': per_device_avg['recall'].values,\n",
    "        'Multi-Device Recall': multi_device_df.loc[per_device_avg.index, 'recall'].values,\n",
    "        'Per-Device Precision': per_device_avg['precision'].values,\n",
    "        'Multi-Device Precision': multi_device_df.loc[per_device_avg.index, 'precision'].values,\n",
    "        'Per-Device FPR@90%R': per_device_avg['fpr_at_90_recall'].values,\n",
    "        'Multi-Device FPR@90%R': multi_device_df.loc[per_device_avg.index, 'fpr_at_90_recall'].values,\n",
    "        'Per-Device R@10%FPR': per_device_avg['recall_at_10_fpr'].values,\n",
    "        'Multi-Device R@10%FPR': multi_device_df.loc[per_device_avg.index, 'recall_at_10_fpr'].values,\n",
    "    })\n",
    "    \n",
    "    print(\"F1 Score Comparison:\")\n",
    "    print(comparison[['Model', 'Per-Device F1', 'Multi-Device F1']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Recall Comparison:\")\n",
    "    print(comparison[['Model', 'Per-Device Recall', 'Multi-Device Recall']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Precision Comparison:\")\n",
    "    print(comparison[['Model', 'Per-Device Precision', 'Multi-Device Precision']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"FPR at 90% Recall Comparison (lower is better):\")\n",
    "    print(comparison[['Model', 'Per-Device FPR@90%R', 'Multi-Device FPR@90%R']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Recall at 10% FPR Comparison (higher is better):\")\n",
    "    print(comparison[['Model', 'Per-Device R@10%FPR', 'Multi-Device R@10%FPR']].to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0a54a-50e6-45f0-8359-a01842e080d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
